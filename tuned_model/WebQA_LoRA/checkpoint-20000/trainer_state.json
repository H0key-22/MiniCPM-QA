{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.7250580046403712,
  "eval_steps": 500,
  "global_step": 20000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0003625290023201856,
      "grad_norm": 0.0,
      "learning_rate": 5e-06,
      "loss": 2.7173,
      "step": 10
    },
    {
      "epoch": 0.0007250580046403712,
      "grad_norm": 0.0,
      "learning_rate": 1e-05,
      "loss": 1.1848,
      "step": 20
    },
    {
      "epoch": 0.0010875870069605568,
      "grad_norm": 95.81262740532951,
      "learning_rate": 1.5e-05,
      "loss": 3.3415,
      "step": 30
    },
    {
      "epoch": 0.0014501160092807424,
      "grad_norm": 0.0,
      "learning_rate": 2e-05,
      "loss": 0.5814,
      "step": 40
    },
    {
      "epoch": 0.001812645011600928,
      "grad_norm": 0.0,
      "learning_rate": 2.5e-05,
      "loss": 2.3638,
      "step": 50
    },
    {
      "epoch": 0.0021751740139211136,
      "grad_norm": 2.8500862376232843,
      "learning_rate": 3e-05,
      "loss": 0.081,
      "step": 60
    },
    {
      "epoch": 0.002537703016241299,
      "grad_norm": 0.0,
      "learning_rate": 3.5e-05,
      "loss": 0.6426,
      "step": 70
    },
    {
      "epoch": 0.002900232018561485,
      "grad_norm": 0.0,
      "learning_rate": 4e-05,
      "loss": 0.5266,
      "step": 80
    },
    {
      "epoch": 0.0032627610208816704,
      "grad_norm": 0.0,
      "learning_rate": 4.5e-05,
      "loss": 0.1226,
      "step": 90
    },
    {
      "epoch": 0.003625290023201856,
      "grad_norm": 3.0601345970122056,
      "learning_rate": 5e-05,
      "loss": 0.9432,
      "step": 100
    },
    {
      "epoch": 0.003987819025522042,
      "grad_norm": 28.07917055997092,
      "learning_rate": 4.99748743718593e-05,
      "loss": 0.6053,
      "step": 110
    },
    {
      "epoch": 0.004350348027842227,
      "grad_norm": 29.01911769669318,
      "learning_rate": 4.9949748743718596e-05,
      "loss": 1.781,
      "step": 120
    },
    {
      "epoch": 0.004712877030162413,
      "grad_norm": 45.365370556219695,
      "learning_rate": 4.992462311557789e-05,
      "loss": 0.4174,
      "step": 130
    },
    {
      "epoch": 0.005075406032482598,
      "grad_norm": 26.13021871470128,
      "learning_rate": 4.989949748743719e-05,
      "loss": 2.2856,
      "step": 140
    },
    {
      "epoch": 0.005437935034802784,
      "grad_norm": 0.0,
      "learning_rate": 4.9874371859296486e-05,
      "loss": 1.0362,
      "step": 150
    },
    {
      "epoch": 0.00580046403712297,
      "grad_norm": 17.175224664765125,
      "learning_rate": 4.984924623115578e-05,
      "loss": 0.105,
      "step": 160
    },
    {
      "epoch": 0.006162993039443156,
      "grad_norm": 7.755882245858372,
      "learning_rate": 4.982412060301508e-05,
      "loss": 0.1751,
      "step": 170
    },
    {
      "epoch": 0.006525522041763341,
      "grad_norm": 0.0,
      "learning_rate": 4.9798994974874375e-05,
      "loss": 0.3581,
      "step": 180
    },
    {
      "epoch": 0.006888051044083527,
      "grad_norm": 41.42427084263222,
      "learning_rate": 4.977386934673367e-05,
      "loss": 0.6429,
      "step": 190
    },
    {
      "epoch": 0.007250580046403712,
      "grad_norm": 0.0,
      "learning_rate": 4.974874371859297e-05,
      "loss": 0.3012,
      "step": 200
    },
    {
      "epoch": 0.007613109048723898,
      "grad_norm": 0.0,
      "learning_rate": 4.9723618090452265e-05,
      "loss": 0.3321,
      "step": 210
    },
    {
      "epoch": 0.007975638051044084,
      "grad_norm": 4.578769677505471,
      "learning_rate": 4.9698492462311555e-05,
      "loss": 1.8919,
      "step": 220
    },
    {
      "epoch": 0.008338167053364268,
      "grad_norm": 34.96717908669857,
      "learning_rate": 4.967336683417086e-05,
      "loss": 0.5397,
      "step": 230
    },
    {
      "epoch": 0.008700696055684454,
      "grad_norm": 0.13876205520840376,
      "learning_rate": 4.9648241206030155e-05,
      "loss": 0.4009,
      "step": 240
    },
    {
      "epoch": 0.00906322505800464,
      "grad_norm": 0.0,
      "learning_rate": 4.962311557788945e-05,
      "loss": 0.4186,
      "step": 250
    },
    {
      "epoch": 0.009425754060324826,
      "grad_norm": 5.041978285225604,
      "learning_rate": 4.959798994974875e-05,
      "loss": 1.1136,
      "step": 260
    },
    {
      "epoch": 0.00978828306264501,
      "grad_norm": 0.0,
      "learning_rate": 4.9572864321608045e-05,
      "loss": 0.9576,
      "step": 270
    },
    {
      "epoch": 0.010150812064965197,
      "grad_norm": 0.0,
      "learning_rate": 4.954773869346734e-05,
      "loss": 0.4198,
      "step": 280
    },
    {
      "epoch": 0.010513341067285383,
      "grad_norm": 0.0,
      "learning_rate": 4.952261306532663e-05,
      "loss": 0.6978,
      "step": 290
    },
    {
      "epoch": 0.010875870069605569,
      "grad_norm": 0.0,
      "learning_rate": 4.949748743718593e-05,
      "loss": 0.3487,
      "step": 300
    },
    {
      "epoch": 0.011238399071925755,
      "grad_norm": 36.41359736749704,
      "learning_rate": 4.947236180904523e-05,
      "loss": 0.7593,
      "step": 310
    },
    {
      "epoch": 0.01160092807424594,
      "grad_norm": 0.0,
      "learning_rate": 4.944723618090453e-05,
      "loss": 1.0317,
      "step": 320
    },
    {
      "epoch": 0.011963457076566125,
      "grad_norm": 0.0,
      "learning_rate": 4.9422110552763825e-05,
      "loss": 1.2948,
      "step": 330
    },
    {
      "epoch": 0.012325986078886311,
      "grad_norm": 2.8627471217466707,
      "learning_rate": 4.939698492462312e-05,
      "loss": 0.38,
      "step": 340
    },
    {
      "epoch": 0.012688515081206497,
      "grad_norm": 14.576019429433625,
      "learning_rate": 4.937185929648241e-05,
      "loss": 0.3835,
      "step": 350
    },
    {
      "epoch": 0.013051044083526682,
      "grad_norm": 0.0,
      "learning_rate": 4.934673366834171e-05,
      "loss": 0.2351,
      "step": 360
    },
    {
      "epoch": 0.013413573085846868,
      "grad_norm": 0.0,
      "learning_rate": 4.9321608040201004e-05,
      "loss": 1.7618,
      "step": 370
    },
    {
      "epoch": 0.013776102088167054,
      "grad_norm": 0.0,
      "learning_rate": 4.92964824120603e-05,
      "loss": 0.651,
      "step": 380
    },
    {
      "epoch": 0.01413863109048724,
      "grad_norm": 0.0,
      "learning_rate": 4.92713567839196e-05,
      "loss": 0.0742,
      "step": 390
    },
    {
      "epoch": 0.014501160092807424,
      "grad_norm": 46.748574301455974,
      "learning_rate": 4.92462311557789e-05,
      "loss": 0.1073,
      "step": 400
    },
    {
      "epoch": 0.01486368909512761,
      "grad_norm": 0.0,
      "learning_rate": 4.92211055276382e-05,
      "loss": 0.3947,
      "step": 410
    },
    {
      "epoch": 0.015226218097447796,
      "grad_norm": 34.382660723080136,
      "learning_rate": 4.919597989949749e-05,
      "loss": 0.7063,
      "step": 420
    },
    {
      "epoch": 0.015588747099767982,
      "grad_norm": 22.762146107301838,
      "learning_rate": 4.9170854271356784e-05,
      "loss": 0.1856,
      "step": 430
    },
    {
      "epoch": 0.015951276102088168,
      "grad_norm": 0.0,
      "learning_rate": 4.914572864321608e-05,
      "loss": 0.6066,
      "step": 440
    },
    {
      "epoch": 0.016313805104408354,
      "grad_norm": 19.81680703505116,
      "learning_rate": 4.912060301507538e-05,
      "loss": 0.1011,
      "step": 450
    },
    {
      "epoch": 0.016676334106728537,
      "grad_norm": 0.0,
      "learning_rate": 4.9095477386934674e-05,
      "loss": 0.7513,
      "step": 460
    },
    {
      "epoch": 0.017038863109048723,
      "grad_norm": 0.0,
      "learning_rate": 4.907035175879397e-05,
      "loss": 1.7293,
      "step": 470
    },
    {
      "epoch": 0.01740139211136891,
      "grad_norm": 0.0,
      "learning_rate": 4.9045226130653274e-05,
      "loss": 0.7777,
      "step": 480
    },
    {
      "epoch": 0.017763921113689095,
      "grad_norm": 0.0,
      "learning_rate": 4.9020100502512564e-05,
      "loss": 0.0,
      "step": 490
    },
    {
      "epoch": 0.01812645011600928,
      "grad_norm": 0.0,
      "learning_rate": 4.899497487437186e-05,
      "loss": 0.485,
      "step": 500
    },
    {
      "epoch": 0.01812645011600928,
      "eval_loss": NaN,
      "eval_runtime": 84.8643,
      "eval_samples_per_second": 7.506,
      "eval_steps_per_second": 1.261,
      "step": 500
    },
    {
      "epoch": 0.018488979118329467,
      "grad_norm": 0.0,
      "learning_rate": 4.896984924623116e-05,
      "loss": 0.4706,
      "step": 510
    },
    {
      "epoch": 0.018851508120649653,
      "grad_norm": 0.0,
      "learning_rate": 4.8944723618090454e-05,
      "loss": 0.1618,
      "step": 520
    },
    {
      "epoch": 0.01921403712296984,
      "grad_norm": 0.0,
      "learning_rate": 4.891959798994975e-05,
      "loss": 0.0212,
      "step": 530
    },
    {
      "epoch": 0.01957656612529002,
      "grad_norm": 0.0,
      "learning_rate": 4.889447236180905e-05,
      "loss": 0.6824,
      "step": 540
    },
    {
      "epoch": 0.019939095127610208,
      "grad_norm": 0.0,
      "learning_rate": 4.8869346733668344e-05,
      "loss": 0.0015,
      "step": 550
    },
    {
      "epoch": 0.020301624129930394,
      "grad_norm": 62.71987106621393,
      "learning_rate": 4.884422110552764e-05,
      "loss": 0.2789,
      "step": 560
    },
    {
      "epoch": 0.02066415313225058,
      "grad_norm": 1.0812592765101465,
      "learning_rate": 4.881909547738694e-05,
      "loss": 1.0033,
      "step": 570
    },
    {
      "epoch": 0.021026682134570766,
      "grad_norm": 78.80692387093916,
      "learning_rate": 4.8793969849246233e-05,
      "loss": 1.2549,
      "step": 580
    },
    {
      "epoch": 0.02138921113689095,
      "grad_norm": 42.49743644612211,
      "learning_rate": 4.876884422110553e-05,
      "loss": 0.3689,
      "step": 590
    },
    {
      "epoch": 0.021751740139211138,
      "grad_norm": 0.0,
      "learning_rate": 4.874371859296483e-05,
      "loss": 0.3424,
      "step": 600
    },
    {
      "epoch": 0.022114269141531324,
      "grad_norm": 0.0,
      "learning_rate": 4.871859296482412e-05,
      "loss": 0.5227,
      "step": 610
    },
    {
      "epoch": 0.02247679814385151,
      "grad_norm": 0.0,
      "learning_rate": 4.869346733668342e-05,
      "loss": 0.3168,
      "step": 620
    },
    {
      "epoch": 0.022839327146171692,
      "grad_norm": 0.0,
      "learning_rate": 4.8668341708542717e-05,
      "loss": 0.7214,
      "step": 630
    },
    {
      "epoch": 0.02320185614849188,
      "grad_norm": 0.0,
      "learning_rate": 4.864321608040201e-05,
      "loss": 0.4125,
      "step": 640
    },
    {
      "epoch": 0.023564385150812064,
      "grad_norm": 0.0,
      "learning_rate": 4.861809045226131e-05,
      "loss": 1.5209,
      "step": 650
    },
    {
      "epoch": 0.02392691415313225,
      "grad_norm": 0.3079077544210917,
      "learning_rate": 4.8592964824120606e-05,
      "loss": 0.5947,
      "step": 660
    },
    {
      "epoch": 0.024289443155452436,
      "grad_norm": 0.19788722501078668,
      "learning_rate": 4.85678391959799e-05,
      "loss": 0.1281,
      "step": 670
    },
    {
      "epoch": 0.024651972157772623,
      "grad_norm": 2.9583398702486554,
      "learning_rate": 4.85427135678392e-05,
      "loss": 0.8362,
      "step": 680
    },
    {
      "epoch": 0.02501450116009281,
      "grad_norm": 36.21033491273158,
      "learning_rate": 4.8517587939698496e-05,
      "loss": 0.784,
      "step": 690
    },
    {
      "epoch": 0.025377030162412995,
      "grad_norm": 0.0,
      "learning_rate": 4.849246231155779e-05,
      "loss": 0.0033,
      "step": 700
    },
    {
      "epoch": 0.025739559164733177,
      "grad_norm": 55.63942272640978,
      "learning_rate": 4.846733668341709e-05,
      "loss": 0.9308,
      "step": 710
    },
    {
      "epoch": 0.026102088167053363,
      "grad_norm": 0.0,
      "learning_rate": 4.844221105527638e-05,
      "loss": 0.0086,
      "step": 720
    },
    {
      "epoch": 0.02646461716937355,
      "grad_norm": 0.0,
      "learning_rate": 4.841708542713568e-05,
      "loss": 0.3909,
      "step": 730
    },
    {
      "epoch": 0.026827146171693735,
      "grad_norm": 1.469657698630674,
      "learning_rate": 4.839195979899498e-05,
      "loss": 0.8298,
      "step": 740
    },
    {
      "epoch": 0.02718967517401392,
      "grad_norm": 0.0,
      "learning_rate": 4.8366834170854276e-05,
      "loss": 0.0738,
      "step": 750
    },
    {
      "epoch": 0.027552204176334107,
      "grad_norm": 0.32376137610372563,
      "learning_rate": 4.834170854271357e-05,
      "loss": 0.0626,
      "step": 760
    },
    {
      "epoch": 0.027914733178654293,
      "grad_norm": 0.0,
      "learning_rate": 4.831658291457287e-05,
      "loss": 1.7923,
      "step": 770
    },
    {
      "epoch": 0.02827726218097448,
      "grad_norm": 0.0,
      "learning_rate": 4.829145728643216e-05,
      "loss": 0.2619,
      "step": 780
    },
    {
      "epoch": 0.028639791183294662,
      "grad_norm": 22.016403325267717,
      "learning_rate": 4.8266331658291456e-05,
      "loss": 1.0506,
      "step": 790
    },
    {
      "epoch": 0.029002320185614848,
      "grad_norm": 0.0,
      "learning_rate": 4.824120603015075e-05,
      "loss": 1.2122,
      "step": 800
    },
    {
      "epoch": 0.029364849187935034,
      "grad_norm": 5.595594901058593,
      "learning_rate": 4.821608040201005e-05,
      "loss": 0.3829,
      "step": 810
    },
    {
      "epoch": 0.02972737819025522,
      "grad_norm": 0.0,
      "learning_rate": 4.819095477386935e-05,
      "loss": 1.1433,
      "step": 820
    },
    {
      "epoch": 0.030089907192575406,
      "grad_norm": 1.0537450464930918,
      "learning_rate": 4.816582914572865e-05,
      "loss": 0.4536,
      "step": 830
    },
    {
      "epoch": 0.030452436194895592,
      "grad_norm": 0.0,
      "learning_rate": 4.8140703517587946e-05,
      "loss": 0.221,
      "step": 840
    },
    {
      "epoch": 0.030814965197215778,
      "grad_norm": 4.051019733291434,
      "learning_rate": 4.8115577889447235e-05,
      "loss": 0.1204,
      "step": 850
    },
    {
      "epoch": 0.031177494199535964,
      "grad_norm": 12.5106192685423,
      "learning_rate": 4.809045226130653e-05,
      "loss": 0.2562,
      "step": 860
    },
    {
      "epoch": 0.03154002320185615,
      "grad_norm": 0.0,
      "learning_rate": 4.806532663316583e-05,
      "loss": 0.2349,
      "step": 870
    },
    {
      "epoch": 0.031902552204176336,
      "grad_norm": 0.0,
      "learning_rate": 4.8040201005025125e-05,
      "loss": 0.8168,
      "step": 880
    },
    {
      "epoch": 0.03226508120649652,
      "grad_norm": 0.0,
      "learning_rate": 4.801507537688442e-05,
      "loss": 0.0012,
      "step": 890
    },
    {
      "epoch": 0.03262761020881671,
      "grad_norm": 0.0,
      "learning_rate": 4.7989949748743725e-05,
      "loss": 0.2983,
      "step": 900
    },
    {
      "epoch": 0.032990139211136894,
      "grad_norm": 0.0,
      "learning_rate": 4.796482412060302e-05,
      "loss": 0.9982,
      "step": 910
    },
    {
      "epoch": 0.03335266821345707,
      "grad_norm": 14.925329381736281,
      "learning_rate": 4.793969849246231e-05,
      "loss": 0.6699,
      "step": 920
    },
    {
      "epoch": 0.03371519721577726,
      "grad_norm": 0.8159299492313126,
      "learning_rate": 4.791457286432161e-05,
      "loss": 0.3664,
      "step": 930
    },
    {
      "epoch": 0.034077726218097446,
      "grad_norm": 23.583792134956663,
      "learning_rate": 4.7889447236180905e-05,
      "loss": 0.2038,
      "step": 940
    },
    {
      "epoch": 0.03444025522041763,
      "grad_norm": 0.0,
      "learning_rate": 4.78643216080402e-05,
      "loss": 1.0369,
      "step": 950
    },
    {
      "epoch": 0.03480278422273782,
      "grad_norm": 29.66993518211554,
      "learning_rate": 4.78391959798995e-05,
      "loss": 0.8779,
      "step": 960
    },
    {
      "epoch": 0.035165313225058004,
      "grad_norm": 0.0,
      "learning_rate": 4.7814070351758795e-05,
      "loss": 0.5108,
      "step": 970
    },
    {
      "epoch": 0.03552784222737819,
      "grad_norm": 17.639225406724037,
      "learning_rate": 4.77889447236181e-05,
      "loss": 0.2083,
      "step": 980
    },
    {
      "epoch": 0.035890371229698376,
      "grad_norm": 31.565503995350188,
      "learning_rate": 4.776381909547739e-05,
      "loss": 0.8953,
      "step": 990
    },
    {
      "epoch": 0.03625290023201856,
      "grad_norm": 0.0,
      "learning_rate": 4.7738693467336685e-05,
      "loss": 0.8245,
      "step": 1000
    },
    {
      "epoch": 0.03625290023201856,
      "eval_loss": NaN,
      "eval_runtime": 66.7252,
      "eval_samples_per_second": 9.547,
      "eval_steps_per_second": 1.604,
      "step": 1000
    },
    {
      "epoch": 0.03661542923433875,
      "grad_norm": 0.0,
      "learning_rate": 4.771356783919598e-05,
      "loss": 0.3011,
      "step": 1010
    },
    {
      "epoch": 0.036977958236658934,
      "grad_norm": 0.0,
      "learning_rate": 4.768844221105528e-05,
      "loss": 0.1572,
      "step": 1020
    },
    {
      "epoch": 0.03734048723897912,
      "grad_norm": 0.0,
      "learning_rate": 4.7663316582914575e-05,
      "loss": 0.6697,
      "step": 1030
    },
    {
      "epoch": 0.037703016241299306,
      "grad_norm": 0.0,
      "learning_rate": 4.763819095477387e-05,
      "loss": 0.0728,
      "step": 1040
    },
    {
      "epoch": 0.03806554524361949,
      "grad_norm": 0.0,
      "learning_rate": 4.761306532663317e-05,
      "loss": 0.5089,
      "step": 1050
    },
    {
      "epoch": 0.03842807424593968,
      "grad_norm": 23.98494120870752,
      "learning_rate": 4.7587939698492464e-05,
      "loss": 0.5855,
      "step": 1060
    },
    {
      "epoch": 0.038790603248259864,
      "grad_norm": 0.0,
      "learning_rate": 4.756281407035176e-05,
      "loss": 0.25,
      "step": 1070
    },
    {
      "epoch": 0.03915313225058004,
      "grad_norm": 18.565625887634635,
      "learning_rate": 4.753768844221106e-05,
      "loss": 0.3611,
      "step": 1080
    },
    {
      "epoch": 0.03951566125290023,
      "grad_norm": 0.0,
      "learning_rate": 4.7512562814070354e-05,
      "loss": 0.2103,
      "step": 1090
    },
    {
      "epoch": 0.039878190255220415,
      "grad_norm": 0.0,
      "learning_rate": 4.748743718592965e-05,
      "loss": 1.1294,
      "step": 1100
    },
    {
      "epoch": 0.0402407192575406,
      "grad_norm": 0.0,
      "learning_rate": 4.746231155778895e-05,
      "loss": 0.2101,
      "step": 1110
    },
    {
      "epoch": 0.04060324825986079,
      "grad_norm": 24.770247991226793,
      "learning_rate": 4.7437185929648244e-05,
      "loss": 1.4558,
      "step": 1120
    },
    {
      "epoch": 0.04096577726218097,
      "grad_norm": 9.050806117116249,
      "learning_rate": 4.741206030150754e-05,
      "loss": 0.7085,
      "step": 1130
    },
    {
      "epoch": 0.04132830626450116,
      "grad_norm": 0.0,
      "learning_rate": 4.738693467336683e-05,
      "loss": 1.1533,
      "step": 1140
    },
    {
      "epoch": 0.041690835266821345,
      "grad_norm": 33.13711084621553,
      "learning_rate": 4.7361809045226134e-05,
      "loss": 0.3411,
      "step": 1150
    },
    {
      "epoch": 0.04205336426914153,
      "grad_norm": 0.0,
      "learning_rate": 4.733668341708543e-05,
      "loss": 0.3912,
      "step": 1160
    },
    {
      "epoch": 0.04241589327146172,
      "grad_norm": 0.0,
      "learning_rate": 4.731155778894473e-05,
      "loss": 0.6277,
      "step": 1170
    },
    {
      "epoch": 0.0427784222737819,
      "grad_norm": 0.0,
      "learning_rate": 4.7286432160804024e-05,
      "loss": 0.0413,
      "step": 1180
    },
    {
      "epoch": 0.04314095127610209,
      "grad_norm": 0.0,
      "learning_rate": 4.726130653266332e-05,
      "loss": 0.2285,
      "step": 1190
    },
    {
      "epoch": 0.043503480278422275,
      "grad_norm": 53.54268704442746,
      "learning_rate": 4.723618090452262e-05,
      "loss": 0.3177,
      "step": 1200
    },
    {
      "epoch": 0.04386600928074246,
      "grad_norm": 0.0,
      "learning_rate": 4.721105527638191e-05,
      "loss": 0.0318,
      "step": 1210
    },
    {
      "epoch": 0.04422853828306265,
      "grad_norm": 0.0,
      "learning_rate": 4.7185929648241204e-05,
      "loss": 0.1578,
      "step": 1220
    },
    {
      "epoch": 0.044591067285382834,
      "grad_norm": 0.0,
      "learning_rate": 4.716080402010051e-05,
      "loss": 0.5191,
      "step": 1230
    },
    {
      "epoch": 0.04495359628770302,
      "grad_norm": 26.355013393224283,
      "learning_rate": 4.7135678391959804e-05,
      "loss": 0.7828,
      "step": 1240
    },
    {
      "epoch": 0.0453161252900232,
      "grad_norm": 0.0,
      "learning_rate": 4.71105527638191e-05,
      "loss": 0.9863,
      "step": 1250
    },
    {
      "epoch": 0.045678654292343385,
      "grad_norm": 20.058786589262915,
      "learning_rate": 4.70854271356784e-05,
      "loss": 0.9875,
      "step": 1260
    },
    {
      "epoch": 0.04604118329466357,
      "grad_norm": 0.0,
      "learning_rate": 4.7060301507537693e-05,
      "loss": 0.9129,
      "step": 1270
    },
    {
      "epoch": 0.04640371229698376,
      "grad_norm": 0.40258568831952396,
      "learning_rate": 4.703517587939698e-05,
      "loss": 0.0019,
      "step": 1280
    },
    {
      "epoch": 0.04676624129930394,
      "grad_norm": 15.821892764439218,
      "learning_rate": 4.701005025125628e-05,
      "loss": 1.8682,
      "step": 1290
    },
    {
      "epoch": 0.04712877030162413,
      "grad_norm": 0.0,
      "learning_rate": 4.6984924623115577e-05,
      "loss": 0.527,
      "step": 1300
    },
    {
      "epoch": 0.047491299303944315,
      "grad_norm": 19.47121789760506,
      "learning_rate": 4.695979899497487e-05,
      "loss": 0.3085,
      "step": 1310
    },
    {
      "epoch": 0.0478538283062645,
      "grad_norm": 23.432146524009624,
      "learning_rate": 4.6934673366834177e-05,
      "loss": 0.78,
      "step": 1320
    },
    {
      "epoch": 0.04821635730858469,
      "grad_norm": 0.0,
      "learning_rate": 4.690954773869347e-05,
      "loss": 0.239,
      "step": 1330
    },
    {
      "epoch": 0.04857888631090487,
      "grad_norm": 16.904538672627982,
      "learning_rate": 4.688442211055277e-05,
      "loss": 0.1455,
      "step": 1340
    },
    {
      "epoch": 0.04894141531322506,
      "grad_norm": 0.0,
      "learning_rate": 4.685929648241206e-05,
      "loss": 0.294,
      "step": 1350
    },
    {
      "epoch": 0.049303944315545245,
      "grad_norm": 0.0,
      "learning_rate": 4.6834170854271356e-05,
      "loss": 0.5029,
      "step": 1360
    },
    {
      "epoch": 0.04966647331786543,
      "grad_norm": 23.034297415416756,
      "learning_rate": 4.680904522613065e-05,
      "loss": 0.5831,
      "step": 1370
    },
    {
      "epoch": 0.05002900232018562,
      "grad_norm": 0.0,
      "learning_rate": 4.678391959798995e-05,
      "loss": 0.3864,
      "step": 1380
    },
    {
      "epoch": 0.0503915313225058,
      "grad_norm": 21.11261743001312,
      "learning_rate": 4.6758793969849246e-05,
      "loss": 0.2749,
      "step": 1390
    },
    {
      "epoch": 0.05075406032482599,
      "grad_norm": 0.0,
      "learning_rate": 4.673366834170855e-05,
      "loss": 0.8519,
      "step": 1400
    },
    {
      "epoch": 0.05111658932714617,
      "grad_norm": 0.0,
      "learning_rate": 4.6708542713567846e-05,
      "loss": 0.8385,
      "step": 1410
    },
    {
      "epoch": 0.051479118329466354,
      "grad_norm": 0.0,
      "learning_rate": 4.6683417085427136e-05,
      "loss": 0.2034,
      "step": 1420
    },
    {
      "epoch": 0.05184164733178654,
      "grad_norm": 0.0,
      "learning_rate": 4.665829145728643e-05,
      "loss": 0.5661,
      "step": 1430
    },
    {
      "epoch": 0.052204176334106726,
      "grad_norm": 0.672105616534955,
      "learning_rate": 4.663316582914573e-05,
      "loss": 0.1884,
      "step": 1440
    },
    {
      "epoch": 0.05256670533642691,
      "grad_norm": 0.0,
      "learning_rate": 4.6608040201005026e-05,
      "loss": 0.0,
      "step": 1450
    },
    {
      "epoch": 0.0529292343387471,
      "grad_norm": 0.0,
      "learning_rate": 4.658291457286432e-05,
      "loss": 0.153,
      "step": 1460
    },
    {
      "epoch": 0.053291763341067284,
      "grad_norm": 0.0,
      "learning_rate": 4.655778894472362e-05,
      "loss": 0.5529,
      "step": 1470
    },
    {
      "epoch": 0.05365429234338747,
      "grad_norm": 0.0,
      "learning_rate": 4.653266331658292e-05,
      "loss": 0.9486,
      "step": 1480
    },
    {
      "epoch": 0.05401682134570766,
      "grad_norm": 0.0,
      "learning_rate": 4.650753768844221e-05,
      "loss": 0.3316,
      "step": 1490
    },
    {
      "epoch": 0.05437935034802784,
      "grad_norm": 0.0,
      "learning_rate": 4.648241206030151e-05,
      "loss": 0.0476,
      "step": 1500
    },
    {
      "epoch": 0.05437935034802784,
      "eval_loss": NaN,
      "eval_runtime": 66.6441,
      "eval_samples_per_second": 9.558,
      "eval_steps_per_second": 1.606,
      "step": 1500
    },
    {
      "epoch": 0.05474187935034803,
      "grad_norm": 6.706782696872354,
      "learning_rate": 4.6457286432160806e-05,
      "loss": 0.0087,
      "step": 1510
    },
    {
      "epoch": 0.055104408352668215,
      "grad_norm": 0.0,
      "learning_rate": 4.64321608040201e-05,
      "loss": 0.5283,
      "step": 1520
    },
    {
      "epoch": 0.0554669373549884,
      "grad_norm": 0.0,
      "learning_rate": 4.64070351758794e-05,
      "loss": 1.8086,
      "step": 1530
    },
    {
      "epoch": 0.05582946635730859,
      "grad_norm": 0.0,
      "learning_rate": 4.6381909547738695e-05,
      "loss": 0.9375,
      "step": 1540
    },
    {
      "epoch": 0.05619199535962877,
      "grad_norm": 0.0,
      "learning_rate": 4.635678391959799e-05,
      "loss": 0.1687,
      "step": 1550
    },
    {
      "epoch": 0.05655452436194896,
      "grad_norm": 21.714906640604198,
      "learning_rate": 4.633165829145729e-05,
      "loss": 0.1664,
      "step": 1560
    },
    {
      "epoch": 0.056917053364269145,
      "grad_norm": 0.0,
      "learning_rate": 4.6306532663316585e-05,
      "loss": 0.1309,
      "step": 1570
    },
    {
      "epoch": 0.057279582366589324,
      "grad_norm": 0.0,
      "learning_rate": 4.628140703517588e-05,
      "loss": 0.1668,
      "step": 1580
    },
    {
      "epoch": 0.05764211136890951,
      "grad_norm": 0.0,
      "learning_rate": 4.625628140703518e-05,
      "loss": 0.3264,
      "step": 1590
    },
    {
      "epoch": 0.058004640371229696,
      "grad_norm": 0.0,
      "learning_rate": 4.6231155778894475e-05,
      "loss": 1.5584,
      "step": 1600
    },
    {
      "epoch": 0.05836716937354988,
      "grad_norm": 0.25087663316123826,
      "learning_rate": 4.620603015075377e-05,
      "loss": 0.0006,
      "step": 1610
    },
    {
      "epoch": 0.05872969837587007,
      "grad_norm": 29.139577729170597,
      "learning_rate": 4.618090452261307e-05,
      "loss": 0.1784,
      "step": 1620
    },
    {
      "epoch": 0.059092227378190254,
      "grad_norm": 34.072692354109805,
      "learning_rate": 4.6155778894472365e-05,
      "loss": 0.8184,
      "step": 1630
    },
    {
      "epoch": 0.05945475638051044,
      "grad_norm": 21.98909766815741,
      "learning_rate": 4.6130653266331655e-05,
      "loss": 0.6244,
      "step": 1640
    },
    {
      "epoch": 0.059817285382830626,
      "grad_norm": 0.0,
      "learning_rate": 4.610552763819096e-05,
      "loss": 0.3785,
      "step": 1650
    },
    {
      "epoch": 0.06017981438515081,
      "grad_norm": 0.0,
      "learning_rate": 4.6080402010050255e-05,
      "loss": 0.3995,
      "step": 1660
    },
    {
      "epoch": 0.060542343387471,
      "grad_norm": 0.545006037949879,
      "learning_rate": 4.605527638190955e-05,
      "loss": 0.1928,
      "step": 1670
    },
    {
      "epoch": 0.060904872389791184,
      "grad_norm": 0.0,
      "learning_rate": 4.603015075376885e-05,
      "loss": 0.971,
      "step": 1680
    },
    {
      "epoch": 0.06126740139211137,
      "grad_norm": 8.907682604763544,
      "learning_rate": 4.6005025125628145e-05,
      "loss": 0.1531,
      "step": 1690
    },
    {
      "epoch": 0.061629930394431556,
      "grad_norm": 0.0,
      "learning_rate": 4.597989949748744e-05,
      "loss": 0.4819,
      "step": 1700
    },
    {
      "epoch": 0.06199245939675174,
      "grad_norm": 0.0,
      "learning_rate": 4.595477386934673e-05,
      "loss": 0.3936,
      "step": 1710
    },
    {
      "epoch": 0.06235498839907193,
      "grad_norm": 0.0,
      "learning_rate": 4.592964824120603e-05,
      "loss": 1.4261,
      "step": 1720
    },
    {
      "epoch": 0.06271751740139211,
      "grad_norm": 0.5395094083225506,
      "learning_rate": 4.5904522613065324e-05,
      "loss": 0.9806,
      "step": 1730
    },
    {
      "epoch": 0.0630800464037123,
      "grad_norm": 0.0,
      "learning_rate": 4.587939698492463e-05,
      "loss": 0.9642,
      "step": 1740
    },
    {
      "epoch": 0.06344257540603249,
      "grad_norm": 5.831448423029155,
      "learning_rate": 4.5854271356783925e-05,
      "loss": 0.1536,
      "step": 1750
    },
    {
      "epoch": 0.06380510440835267,
      "grad_norm": 2.9279983737399062,
      "learning_rate": 4.582914572864322e-05,
      "loss": 1.2024,
      "step": 1760
    },
    {
      "epoch": 0.06416763341067286,
      "grad_norm": 0.0,
      "learning_rate": 4.580402010050252e-05,
      "loss": 0.6823,
      "step": 1770
    },
    {
      "epoch": 0.06453016241299304,
      "grad_norm": 0.0,
      "learning_rate": 4.577889447236181e-05,
      "loss": 0.4253,
      "step": 1780
    },
    {
      "epoch": 0.06489269141531323,
      "grad_norm": 17.519584813881327,
      "learning_rate": 4.5753768844221104e-05,
      "loss": 1.1534,
      "step": 1790
    },
    {
      "epoch": 0.06525522041763342,
      "grad_norm": 0.0,
      "learning_rate": 4.57286432160804e-05,
      "loss": 0.1472,
      "step": 1800
    },
    {
      "epoch": 0.0656177494199536,
      "grad_norm": 9.703535037506748,
      "learning_rate": 4.57035175879397e-05,
      "loss": 0.4524,
      "step": 1810
    },
    {
      "epoch": 0.06598027842227379,
      "grad_norm": 2.3000218639163865,
      "learning_rate": 4.5678391959799e-05,
      "loss": 0.9719,
      "step": 1820
    },
    {
      "epoch": 0.06634280742459396,
      "grad_norm": 13.903065932001125,
      "learning_rate": 4.56532663316583e-05,
      "loss": 0.6135,
      "step": 1830
    },
    {
      "epoch": 0.06670533642691415,
      "grad_norm": 11.101933601292163,
      "learning_rate": 4.5628140703517594e-05,
      "loss": 0.8021,
      "step": 1840
    },
    {
      "epoch": 0.06706786542923433,
      "grad_norm": 0.0,
      "learning_rate": 4.5603015075376884e-05,
      "loss": 0.7517,
      "step": 1850
    },
    {
      "epoch": 0.06743039443155452,
      "grad_norm": 0.0,
      "learning_rate": 4.557788944723618e-05,
      "loss": 0.1001,
      "step": 1860
    },
    {
      "epoch": 0.0677929234338747,
      "grad_norm": 0.0,
      "learning_rate": 4.555276381909548e-05,
      "loss": 0.4629,
      "step": 1870
    },
    {
      "epoch": 0.06815545243619489,
      "grad_norm": 0.0,
      "learning_rate": 4.5527638190954774e-05,
      "loss": 0.6255,
      "step": 1880
    },
    {
      "epoch": 0.06851798143851508,
      "grad_norm": 0.7000410476638542,
      "learning_rate": 4.550251256281407e-05,
      "loss": 0.2824,
      "step": 1890
    },
    {
      "epoch": 0.06888051044083526,
      "grad_norm": 10.990749284021483,
      "learning_rate": 4.5477386934673374e-05,
      "loss": 0.343,
      "step": 1900
    },
    {
      "epoch": 0.06924303944315545,
      "grad_norm": 0.0,
      "learning_rate": 4.545226130653267e-05,
      "loss": 0.3582,
      "step": 1910
    },
    {
      "epoch": 0.06960556844547564,
      "grad_norm": 0.0,
      "learning_rate": 4.542713567839196e-05,
      "loss": 0.2612,
      "step": 1920
    },
    {
      "epoch": 0.06996809744779582,
      "grad_norm": 0.0,
      "learning_rate": 4.540201005025126e-05,
      "loss": 0.9433,
      "step": 1930
    },
    {
      "epoch": 0.07033062645011601,
      "grad_norm": 0.0,
      "learning_rate": 4.5376884422110554e-05,
      "loss": 0.3022,
      "step": 1940
    },
    {
      "epoch": 0.0706931554524362,
      "grad_norm": 23.412547915644375,
      "learning_rate": 4.535175879396985e-05,
      "loss": 1.0061,
      "step": 1950
    },
    {
      "epoch": 0.07105568445475638,
      "grad_norm": 0.0,
      "learning_rate": 4.532663316582915e-05,
      "loss": 0.2344,
      "step": 1960
    },
    {
      "epoch": 0.07141821345707657,
      "grad_norm": 0.0,
      "learning_rate": 4.530150753768844e-05,
      "loss": 0.092,
      "step": 1970
    },
    {
      "epoch": 0.07178074245939675,
      "grad_norm": 22.856488518204465,
      "learning_rate": 4.527638190954774e-05,
      "loss": 0.3339,
      "step": 1980
    },
    {
      "epoch": 0.07214327146171694,
      "grad_norm": 17.95588279106991,
      "learning_rate": 4.525125628140704e-05,
      "loss": 0.7615,
      "step": 1990
    },
    {
      "epoch": 0.07250580046403712,
      "grad_norm": 0.0,
      "learning_rate": 4.522613065326633e-05,
      "loss": 0.298,
      "step": 2000
    },
    {
      "epoch": 0.07250580046403712,
      "eval_loss": NaN,
      "eval_runtime": 71.5243,
      "eval_samples_per_second": 8.906,
      "eval_steps_per_second": 1.496,
      "step": 2000
    },
    {
      "epoch": 0.07286832946635731,
      "grad_norm": 0.3636427280698114,
      "learning_rate": 4.520100502512563e-05,
      "loss": 0.6326,
      "step": 2010
    },
    {
      "epoch": 0.0732308584686775,
      "grad_norm": 33.695782550918004,
      "learning_rate": 4.5175879396984926e-05,
      "loss": 0.7721,
      "step": 2020
    },
    {
      "epoch": 0.07359338747099768,
      "grad_norm": 0.0,
      "learning_rate": 4.515075376884422e-05,
      "loss": 0.4468,
      "step": 2030
    },
    {
      "epoch": 0.07395591647331787,
      "grad_norm": 1.0020439597554638,
      "learning_rate": 4.512562814070352e-05,
      "loss": 0.1475,
      "step": 2040
    },
    {
      "epoch": 0.07431844547563805,
      "grad_norm": 0.0,
      "learning_rate": 4.5100502512562816e-05,
      "loss": 0.3731,
      "step": 2050
    },
    {
      "epoch": 0.07468097447795824,
      "grad_norm": 6.648317293364687,
      "learning_rate": 4.507537688442211e-05,
      "loss": 0.8676,
      "step": 2060
    },
    {
      "epoch": 0.07504350348027843,
      "grad_norm": 0.0,
      "learning_rate": 4.505025125628141e-05,
      "loss": 0.0,
      "step": 2070
    },
    {
      "epoch": 0.07540603248259861,
      "grad_norm": 0.0,
      "learning_rate": 4.5025125628140706e-05,
      "loss": 0.0182,
      "step": 2080
    },
    {
      "epoch": 0.0757685614849188,
      "grad_norm": 41.267441270139045,
      "learning_rate": 4.5e-05,
      "loss": 0.8587,
      "step": 2090
    },
    {
      "epoch": 0.07613109048723898,
      "grad_norm": 29.48587059832906,
      "learning_rate": 4.49748743718593e-05,
      "loss": 0.2966,
      "step": 2100
    },
    {
      "epoch": 0.07649361948955917,
      "grad_norm": 60.83973728421664,
      "learning_rate": 4.4949748743718596e-05,
      "loss": 0.9888,
      "step": 2110
    },
    {
      "epoch": 0.07685614849187936,
      "grad_norm": 0.0,
      "learning_rate": 4.492462311557789e-05,
      "loss": 0.3847,
      "step": 2120
    },
    {
      "epoch": 0.07721867749419954,
      "grad_norm": 0.0,
      "learning_rate": 4.489949748743719e-05,
      "loss": 0.0005,
      "step": 2130
    },
    {
      "epoch": 0.07758120649651973,
      "grad_norm": 9.726259329487036,
      "learning_rate": 4.487437185929648e-05,
      "loss": 0.8031,
      "step": 2140
    },
    {
      "epoch": 0.07794373549883991,
      "grad_norm": 0.0,
      "learning_rate": 4.484924623115578e-05,
      "loss": 0.4025,
      "step": 2150
    },
    {
      "epoch": 0.07830626450116009,
      "grad_norm": 0.0,
      "learning_rate": 4.482412060301508e-05,
      "loss": 0.1232,
      "step": 2160
    },
    {
      "epoch": 0.07866879350348027,
      "grad_norm": 0.0,
      "learning_rate": 4.4798994974874376e-05,
      "loss": 0.1962,
      "step": 2170
    },
    {
      "epoch": 0.07903132250580046,
      "grad_norm": 0.0,
      "learning_rate": 4.477386934673367e-05,
      "loss": 0.6566,
      "step": 2180
    },
    {
      "epoch": 0.07939385150812064,
      "grad_norm": 23.10709029865752,
      "learning_rate": 4.474874371859297e-05,
      "loss": 1.0394,
      "step": 2190
    },
    {
      "epoch": 0.07975638051044083,
      "grad_norm": 0.0,
      "learning_rate": 4.4723618090452266e-05,
      "loss": 0.004,
      "step": 2200
    },
    {
      "epoch": 0.08011890951276102,
      "grad_norm": 0.0,
      "learning_rate": 4.4698492462311556e-05,
      "loss": 0.1853,
      "step": 2210
    },
    {
      "epoch": 0.0804814385150812,
      "grad_norm": 0.6929646832713429,
      "learning_rate": 4.467336683417085e-05,
      "loss": 0.7454,
      "step": 2220
    },
    {
      "epoch": 0.08084396751740139,
      "grad_norm": 0.0,
      "learning_rate": 4.464824120603015e-05,
      "loss": 0.4856,
      "step": 2230
    },
    {
      "epoch": 0.08120649651972157,
      "grad_norm": 0.0,
      "learning_rate": 4.462311557788945e-05,
      "loss": 0.9033,
      "step": 2240
    },
    {
      "epoch": 0.08156902552204176,
      "grad_norm": 21.301675592700228,
      "learning_rate": 4.459798994974875e-05,
      "loss": 0.1132,
      "step": 2250
    },
    {
      "epoch": 0.08193155452436195,
      "grad_norm": 0.0,
      "learning_rate": 4.4572864321608045e-05,
      "loss": 0.0071,
      "step": 2260
    },
    {
      "epoch": 0.08229408352668213,
      "grad_norm": 44.01610201196972,
      "learning_rate": 4.454773869346734e-05,
      "loss": 0.248,
      "step": 2270
    },
    {
      "epoch": 0.08265661252900232,
      "grad_norm": 129.85539583754309,
      "learning_rate": 4.452261306532663e-05,
      "loss": 0.7978,
      "step": 2280
    },
    {
      "epoch": 0.0830191415313225,
      "grad_norm": 0.0,
      "learning_rate": 4.449748743718593e-05,
      "loss": 0.058,
      "step": 2290
    },
    {
      "epoch": 0.08338167053364269,
      "grad_norm": 47.32590938607255,
      "learning_rate": 4.4472361809045225e-05,
      "loss": 0.1927,
      "step": 2300
    },
    {
      "epoch": 0.08374419953596288,
      "grad_norm": 16.86071805934025,
      "learning_rate": 4.444723618090452e-05,
      "loss": 0.453,
      "step": 2310
    },
    {
      "epoch": 0.08410672853828306,
      "grad_norm": 0.0,
      "learning_rate": 4.4422110552763825e-05,
      "loss": 0.7819,
      "step": 2320
    },
    {
      "epoch": 0.08446925754060325,
      "grad_norm": 0.0,
      "learning_rate": 4.439698492462312e-05,
      "loss": 0.4306,
      "step": 2330
    },
    {
      "epoch": 0.08483178654292343,
      "grad_norm": 0.0,
      "learning_rate": 4.437185929648242e-05,
      "loss": 0.852,
      "step": 2340
    },
    {
      "epoch": 0.08519431554524362,
      "grad_norm": 0.0,
      "learning_rate": 4.434673366834171e-05,
      "loss": 0.0078,
      "step": 2350
    },
    {
      "epoch": 0.0855568445475638,
      "grad_norm": 29.451442259622446,
      "learning_rate": 4.4321608040201005e-05,
      "loss": 0.645,
      "step": 2360
    },
    {
      "epoch": 0.08591937354988399,
      "grad_norm": 0.0,
      "learning_rate": 4.42964824120603e-05,
      "loss": 0.3237,
      "step": 2370
    },
    {
      "epoch": 0.08628190255220418,
      "grad_norm": 0.0,
      "learning_rate": 4.42713567839196e-05,
      "loss": 0.9671,
      "step": 2380
    },
    {
      "epoch": 0.08664443155452436,
      "grad_norm": 0.5392738701883034,
      "learning_rate": 4.4246231155778895e-05,
      "loss": 0.1892,
      "step": 2390
    },
    {
      "epoch": 0.08700696055684455,
      "grad_norm": 0.0,
      "learning_rate": 4.42211055276382e-05,
      "loss": 0.0797,
      "step": 2400
    },
    {
      "epoch": 0.08736948955916474,
      "grad_norm": 0.0,
      "learning_rate": 4.4195979899497495e-05,
      "loss": 0.3128,
      "step": 2410
    },
    {
      "epoch": 0.08773201856148492,
      "grad_norm": 0.0,
      "learning_rate": 4.4170854271356785e-05,
      "loss": 0.0488,
      "step": 2420
    },
    {
      "epoch": 0.08809454756380511,
      "grad_norm": 0.0,
      "learning_rate": 4.414572864321608e-05,
      "loss": 0.4561,
      "step": 2430
    },
    {
      "epoch": 0.0884570765661253,
      "grad_norm": 0.0,
      "learning_rate": 4.412060301507538e-05,
      "loss": 0.3518,
      "step": 2440
    },
    {
      "epoch": 0.08881960556844548,
      "grad_norm": 0.0,
      "learning_rate": 4.4095477386934674e-05,
      "loss": 0.3224,
      "step": 2450
    },
    {
      "epoch": 0.08918213457076567,
      "grad_norm": 3.1437547566129522,
      "learning_rate": 4.407035175879397e-05,
      "loss": 0.0066,
      "step": 2460
    },
    {
      "epoch": 0.08954466357308585,
      "grad_norm": 0.0,
      "learning_rate": 4.404522613065327e-05,
      "loss": 0.0223,
      "step": 2470
    },
    {
      "epoch": 0.08990719257540604,
      "grad_norm": 0.0,
      "learning_rate": 4.4020100502512564e-05,
      "loss": 0.0039,
      "step": 2480
    },
    {
      "epoch": 0.09026972157772621,
      "grad_norm": 0.0,
      "learning_rate": 4.399497487437186e-05,
      "loss": 1.2465,
      "step": 2490
    },
    {
      "epoch": 0.0906322505800464,
      "grad_norm": 0.0,
      "learning_rate": 4.396984924623116e-05,
      "loss": 1.5248,
      "step": 2500
    },
    {
      "epoch": 0.0906322505800464,
      "eval_loss": NaN,
      "eval_runtime": 77.8131,
      "eval_samples_per_second": 8.186,
      "eval_steps_per_second": 1.375,
      "step": 2500
    },
    {
      "epoch": 0.09099477958236658,
      "grad_norm": 0.0,
      "learning_rate": 4.3944723618090454e-05,
      "loss": 0.09,
      "step": 2510
    },
    {
      "epoch": 0.09135730858468677,
      "grad_norm": 0.0,
      "learning_rate": 4.391959798994975e-05,
      "loss": 0.0602,
      "step": 2520
    },
    {
      "epoch": 0.09171983758700696,
      "grad_norm": 0.0,
      "learning_rate": 4.389447236180905e-05,
      "loss": 0.6828,
      "step": 2530
    },
    {
      "epoch": 0.09208236658932714,
      "grad_norm": 2.5831415556407804,
      "learning_rate": 4.3869346733668344e-05,
      "loss": 0.269,
      "step": 2540
    },
    {
      "epoch": 0.09244489559164733,
      "grad_norm": 8.698389048892814,
      "learning_rate": 4.384422110552764e-05,
      "loss": 0.0165,
      "step": 2550
    },
    {
      "epoch": 0.09280742459396751,
      "grad_norm": 0.0,
      "learning_rate": 4.381909547738694e-05,
      "loss": 0.2418,
      "step": 2560
    },
    {
      "epoch": 0.0931699535962877,
      "grad_norm": 0.0,
      "learning_rate": 4.3793969849246234e-05,
      "loss": 0.5901,
      "step": 2570
    },
    {
      "epoch": 0.09353248259860789,
      "grad_norm": 0.8626803209635803,
      "learning_rate": 4.376884422110553e-05,
      "loss": 0.741,
      "step": 2580
    },
    {
      "epoch": 0.09389501160092807,
      "grad_norm": 0.0,
      "learning_rate": 4.374371859296483e-05,
      "loss": 0.4998,
      "step": 2590
    },
    {
      "epoch": 0.09425754060324826,
      "grad_norm": 0.0,
      "learning_rate": 4.3718592964824124e-05,
      "loss": 1.6251,
      "step": 2600
    },
    {
      "epoch": 0.09462006960556844,
      "grad_norm": 25.733051537006837,
      "learning_rate": 4.369346733668342e-05,
      "loss": 0.0095,
      "step": 2610
    },
    {
      "epoch": 0.09498259860788863,
      "grad_norm": 13.496145192557531,
      "learning_rate": 4.366834170854272e-05,
      "loss": 0.4307,
      "step": 2620
    },
    {
      "epoch": 0.09534512761020882,
      "grad_norm": 0.0,
      "learning_rate": 4.3643216080402014e-05,
      "loss": 0.0774,
      "step": 2630
    },
    {
      "epoch": 0.095707656612529,
      "grad_norm": 5.858945296743636,
      "learning_rate": 4.3618090452261303e-05,
      "loss": 0.6009,
      "step": 2640
    },
    {
      "epoch": 0.09607018561484919,
      "grad_norm": 0.0,
      "learning_rate": 4.35929648241206e-05,
      "loss": 0.3136,
      "step": 2650
    },
    {
      "epoch": 0.09643271461716937,
      "grad_norm": 0.0,
      "learning_rate": 4.3567839195979903e-05,
      "loss": 0.0038,
      "step": 2660
    },
    {
      "epoch": 0.09679524361948956,
      "grad_norm": 0.0,
      "learning_rate": 4.35427135678392e-05,
      "loss": 0.942,
      "step": 2670
    },
    {
      "epoch": 0.09715777262180975,
      "grad_norm": 0.0,
      "learning_rate": 4.35175879396985e-05,
      "loss": 0.0301,
      "step": 2680
    },
    {
      "epoch": 0.09752030162412993,
      "grad_norm": 0.0,
      "learning_rate": 4.349246231155779e-05,
      "loss": 1.606,
      "step": 2690
    },
    {
      "epoch": 0.09788283062645012,
      "grad_norm": 0.0,
      "learning_rate": 4.346733668341709e-05,
      "loss": 1.455,
      "step": 2700
    },
    {
      "epoch": 0.0982453596287703,
      "grad_norm": 0.0,
      "learning_rate": 4.344221105527638e-05,
      "loss": 0.3575,
      "step": 2710
    },
    {
      "epoch": 0.09860788863109049,
      "grad_norm": 0.0,
      "learning_rate": 4.3417085427135676e-05,
      "loss": 0.1822,
      "step": 2720
    },
    {
      "epoch": 0.09897041763341068,
      "grad_norm": 10.567014553308054,
      "learning_rate": 4.339195979899497e-05,
      "loss": 0.4198,
      "step": 2730
    },
    {
      "epoch": 0.09933294663573086,
      "grad_norm": 0.0,
      "learning_rate": 4.3366834170854276e-05,
      "loss": 0.7454,
      "step": 2740
    },
    {
      "epoch": 0.09969547563805105,
      "grad_norm": 0.0,
      "learning_rate": 4.334170854271357e-05,
      "loss": 0.5054,
      "step": 2750
    },
    {
      "epoch": 0.10005800464037123,
      "grad_norm": 0.0,
      "learning_rate": 4.331658291457287e-05,
      "loss": 0.3457,
      "step": 2760
    },
    {
      "epoch": 0.10042053364269142,
      "grad_norm": 0.0,
      "learning_rate": 4.3291457286432166e-05,
      "loss": 0.8011,
      "step": 2770
    },
    {
      "epoch": 0.1007830626450116,
      "grad_norm": 0.0,
      "learning_rate": 4.3266331658291456e-05,
      "loss": 0.8336,
      "step": 2780
    },
    {
      "epoch": 0.10114559164733179,
      "grad_norm": 0.0,
      "learning_rate": 4.324120603015075e-05,
      "loss": 0.1887,
      "step": 2790
    },
    {
      "epoch": 0.10150812064965198,
      "grad_norm": 0.0,
      "learning_rate": 4.321608040201005e-05,
      "loss": 0.1634,
      "step": 2800
    },
    {
      "epoch": 0.10187064965197216,
      "grad_norm": 0.0,
      "learning_rate": 4.3190954773869346e-05,
      "loss": 0.7047,
      "step": 2810
    },
    {
      "epoch": 0.10223317865429234,
      "grad_norm": 0.068890825224378,
      "learning_rate": 4.316582914572865e-05,
      "loss": 0.6767,
      "step": 2820
    },
    {
      "epoch": 0.10259570765661252,
      "grad_norm": 39.63732217961138,
      "learning_rate": 4.3140703517587946e-05,
      "loss": 0.4354,
      "step": 2830
    },
    {
      "epoch": 0.10295823665893271,
      "grad_norm": 0.0,
      "learning_rate": 4.311557788944724e-05,
      "loss": 0.8061,
      "step": 2840
    },
    {
      "epoch": 0.1033207656612529,
      "grad_norm": 17.442174797596827,
      "learning_rate": 4.309045226130653e-05,
      "loss": 0.5203,
      "step": 2850
    },
    {
      "epoch": 0.10368329466357308,
      "grad_norm": 31.84058727547083,
      "learning_rate": 4.306532663316583e-05,
      "loss": 0.27,
      "step": 2860
    },
    {
      "epoch": 0.10404582366589327,
      "grad_norm": 0.0,
      "learning_rate": 4.3040201005025126e-05,
      "loss": 0.6159,
      "step": 2870
    },
    {
      "epoch": 0.10440835266821345,
      "grad_norm": 0.0,
      "learning_rate": 4.301507537688442e-05,
      "loss": 0.6039,
      "step": 2880
    },
    {
      "epoch": 0.10477088167053364,
      "grad_norm": 0.0,
      "learning_rate": 4.298994974874372e-05,
      "loss": 0.6083,
      "step": 2890
    },
    {
      "epoch": 0.10513341067285382,
      "grad_norm": 13.63311413975035,
      "learning_rate": 4.2964824120603016e-05,
      "loss": 0.1292,
      "step": 2900
    },
    {
      "epoch": 0.10549593967517401,
      "grad_norm": 0.0,
      "learning_rate": 4.293969849246232e-05,
      "loss": 0.6248,
      "step": 2910
    },
    {
      "epoch": 0.1058584686774942,
      "grad_norm": 10.9539023217399,
      "learning_rate": 4.291457286432161e-05,
      "loss": 0.4794,
      "step": 2920
    },
    {
      "epoch": 0.10622099767981438,
      "grad_norm": 0.0,
      "learning_rate": 4.2889447236180905e-05,
      "loss": 0.4244,
      "step": 2930
    },
    {
      "epoch": 0.10658352668213457,
      "grad_norm": 0.776076544334198,
      "learning_rate": 4.28643216080402e-05,
      "loss": 0.6337,
      "step": 2940
    },
    {
      "epoch": 0.10694605568445475,
      "grad_norm": 0.0,
      "learning_rate": 4.28391959798995e-05,
      "loss": 0.5183,
      "step": 2950
    },
    {
      "epoch": 0.10730858468677494,
      "grad_norm": 2.4546033935901375,
      "learning_rate": 4.2814070351758795e-05,
      "loss": 0.1741,
      "step": 2960
    },
    {
      "epoch": 0.10767111368909513,
      "grad_norm": 0.0,
      "learning_rate": 4.278894472361809e-05,
      "loss": 0.8285,
      "step": 2970
    },
    {
      "epoch": 0.10803364269141531,
      "grad_norm": 0.0,
      "learning_rate": 4.276381909547739e-05,
      "loss": 0.3064,
      "step": 2980
    },
    {
      "epoch": 0.1083961716937355,
      "grad_norm": 0.0,
      "learning_rate": 4.2738693467336685e-05,
      "loss": 0.1124,
      "step": 2990
    },
    {
      "epoch": 0.10875870069605569,
      "grad_norm": 0.0,
      "learning_rate": 4.271356783919598e-05,
      "loss": 0.7732,
      "step": 3000
    },
    {
      "epoch": 0.10875870069605569,
      "eval_loss": NaN,
      "eval_runtime": 68.9766,
      "eval_samples_per_second": 9.235,
      "eval_steps_per_second": 1.551,
      "step": 3000
    },
    {
      "epoch": 0.10912122969837587,
      "grad_norm": 12.998681221607697,
      "learning_rate": 4.268844221105528e-05,
      "loss": 0.432,
      "step": 3010
    },
    {
      "epoch": 0.10948375870069606,
      "grad_norm": 53.20647015915334,
      "learning_rate": 4.2663316582914575e-05,
      "loss": 0.5874,
      "step": 3020
    },
    {
      "epoch": 0.10984628770301624,
      "grad_norm": 39.58680323332985,
      "learning_rate": 4.263819095477387e-05,
      "loss": 0.2532,
      "step": 3030
    },
    {
      "epoch": 0.11020881670533643,
      "grad_norm": 22.92362835190813,
      "learning_rate": 4.261306532663317e-05,
      "loss": 0.8876,
      "step": 3040
    },
    {
      "epoch": 0.11057134570765662,
      "grad_norm": 8.82550906693361,
      "learning_rate": 4.2587939698492465e-05,
      "loss": 0.3002,
      "step": 3050
    },
    {
      "epoch": 0.1109338747099768,
      "grad_norm": 0.0,
      "learning_rate": 4.256281407035176e-05,
      "loss": 0.3304,
      "step": 3060
    },
    {
      "epoch": 0.11129640371229699,
      "grad_norm": 0.0,
      "learning_rate": 4.253768844221106e-05,
      "loss": 0.4269,
      "step": 3070
    },
    {
      "epoch": 0.11165893271461717,
      "grad_norm": 0.0,
      "learning_rate": 4.2512562814070355e-05,
      "loss": 0.3141,
      "step": 3080
    },
    {
      "epoch": 0.11202146171693736,
      "grad_norm": 0.0,
      "learning_rate": 4.248743718592965e-05,
      "loss": 0.3578,
      "step": 3090
    },
    {
      "epoch": 0.11238399071925755,
      "grad_norm": 5.173978349024739,
      "learning_rate": 4.246231155778895e-05,
      "loss": 0.3681,
      "step": 3100
    },
    {
      "epoch": 0.11274651972157773,
      "grad_norm": 0.0,
      "learning_rate": 4.2437185929648245e-05,
      "loss": 0.8065,
      "step": 3110
    },
    {
      "epoch": 0.11310904872389792,
      "grad_norm": 0.0,
      "learning_rate": 4.241206030150754e-05,
      "loss": 0.5168,
      "step": 3120
    },
    {
      "epoch": 0.1134715777262181,
      "grad_norm": 32.755305435603674,
      "learning_rate": 4.238693467336684e-05,
      "loss": 0.4247,
      "step": 3130
    },
    {
      "epoch": 0.11383410672853829,
      "grad_norm": 0.0,
      "learning_rate": 4.236180904522613e-05,
      "loss": 0.1699,
      "step": 3140
    },
    {
      "epoch": 0.11419663573085846,
      "grad_norm": 0.0,
      "learning_rate": 4.2336683417085424e-05,
      "loss": 0.2765,
      "step": 3150
    },
    {
      "epoch": 0.11455916473317865,
      "grad_norm": 0.0,
      "learning_rate": 4.231155778894473e-05,
      "loss": 0.6549,
      "step": 3160
    },
    {
      "epoch": 0.11492169373549883,
      "grad_norm": 15.227750963752412,
      "learning_rate": 4.2286432160804024e-05,
      "loss": 1.177,
      "step": 3170
    },
    {
      "epoch": 0.11528422273781902,
      "grad_norm": 28.793953112413096,
      "learning_rate": 4.226130653266332e-05,
      "loss": 0.2329,
      "step": 3180
    },
    {
      "epoch": 0.1156467517401392,
      "grad_norm": 16.81187466163937,
      "learning_rate": 4.223618090452262e-05,
      "loss": 0.5913,
      "step": 3190
    },
    {
      "epoch": 0.11600928074245939,
      "grad_norm": 0.0,
      "learning_rate": 4.2211055276381914e-05,
      "loss": 0.823,
      "step": 3200
    },
    {
      "epoch": 0.11637180974477958,
      "grad_norm": 0.0,
      "learning_rate": 4.2185929648241204e-05,
      "loss": 0.0,
      "step": 3210
    },
    {
      "epoch": 0.11673433874709976,
      "grad_norm": 2.6162810164944603,
      "learning_rate": 4.21608040201005e-05,
      "loss": 0.2154,
      "step": 3220
    },
    {
      "epoch": 0.11709686774941995,
      "grad_norm": 0.0,
      "learning_rate": 4.21356783919598e-05,
      "loss": 0.5166,
      "step": 3230
    },
    {
      "epoch": 0.11745939675174014,
      "grad_norm": 0.0,
      "learning_rate": 4.21105527638191e-05,
      "loss": 0.0339,
      "step": 3240
    },
    {
      "epoch": 0.11782192575406032,
      "grad_norm": 0.0,
      "learning_rate": 4.20854271356784e-05,
      "loss": 0.0662,
      "step": 3250
    },
    {
      "epoch": 0.11818445475638051,
      "grad_norm": 0.0,
      "learning_rate": 4.2060301507537694e-05,
      "loss": 0.723,
      "step": 3260
    },
    {
      "epoch": 0.1185469837587007,
      "grad_norm": 0.0,
      "learning_rate": 4.203517587939699e-05,
      "loss": 0.13,
      "step": 3270
    },
    {
      "epoch": 0.11890951276102088,
      "grad_norm": 0.0,
      "learning_rate": 4.201005025125628e-05,
      "loss": 1.1975,
      "step": 3280
    },
    {
      "epoch": 0.11927204176334107,
      "grad_norm": 0.0,
      "learning_rate": 4.198492462311558e-05,
      "loss": 0.1445,
      "step": 3290
    },
    {
      "epoch": 0.11963457076566125,
      "grad_norm": 0.0,
      "learning_rate": 4.1959798994974874e-05,
      "loss": 0.1047,
      "step": 3300
    },
    {
      "epoch": 0.11999709976798144,
      "grad_norm": 0.0,
      "learning_rate": 4.193467336683417e-05,
      "loss": 0.0142,
      "step": 3310
    },
    {
      "epoch": 0.12035962877030162,
      "grad_norm": 0.0,
      "learning_rate": 4.1909547738693474e-05,
      "loss": 0.4736,
      "step": 3320
    },
    {
      "epoch": 0.12072215777262181,
      "grad_norm": 0.0,
      "learning_rate": 4.188442211055277e-05,
      "loss": 0.6015,
      "step": 3330
    },
    {
      "epoch": 0.121084686774942,
      "grad_norm": 0.0,
      "learning_rate": 4.185929648241207e-05,
      "loss": 0.1979,
      "step": 3340
    },
    {
      "epoch": 0.12144721577726218,
      "grad_norm": 0.0,
      "learning_rate": 4.183417085427136e-05,
      "loss": 0.6156,
      "step": 3350
    },
    {
      "epoch": 0.12180974477958237,
      "grad_norm": 4.615249252779659,
      "learning_rate": 4.180904522613065e-05,
      "loss": 0.1851,
      "step": 3360
    },
    {
      "epoch": 0.12217227378190255,
      "grad_norm": 0.0,
      "learning_rate": 4.178391959798995e-05,
      "loss": 0.1578,
      "step": 3370
    },
    {
      "epoch": 0.12253480278422274,
      "grad_norm": 15.53178985087294,
      "learning_rate": 4.1758793969849247e-05,
      "loss": 0.1045,
      "step": 3380
    },
    {
      "epoch": 0.12289733178654293,
      "grad_norm": 0.0,
      "learning_rate": 4.173366834170854e-05,
      "loss": 0.6266,
      "step": 3390
    },
    {
      "epoch": 0.12325986078886311,
      "grad_norm": 34.081112317482756,
      "learning_rate": 4.170854271356784e-05,
      "loss": 0.6236,
      "step": 3400
    },
    {
      "epoch": 0.1236223897911833,
      "grad_norm": 0.0,
      "learning_rate": 4.168341708542714e-05,
      "loss": 0.027,
      "step": 3410
    },
    {
      "epoch": 0.12398491879350348,
      "grad_norm": 0.0,
      "learning_rate": 4.165829145728643e-05,
      "loss": 0.4391,
      "step": 3420
    },
    {
      "epoch": 0.12434744779582367,
      "grad_norm": 0.0,
      "learning_rate": 4.163316582914573e-05,
      "loss": 0.5424,
      "step": 3430
    },
    {
      "epoch": 0.12470997679814386,
      "grad_norm": 20.804681632556438,
      "learning_rate": 4.1608040201005026e-05,
      "loss": 0.4877,
      "step": 3440
    },
    {
      "epoch": 0.12507250580046403,
      "grad_norm": 8.65815928641902,
      "learning_rate": 4.158291457286432e-05,
      "loss": 0.2063,
      "step": 3450
    },
    {
      "epoch": 0.12543503480278423,
      "grad_norm": 0.0,
      "learning_rate": 4.155778894472362e-05,
      "loss": 0.7595,
      "step": 3460
    },
    {
      "epoch": 0.1257975638051044,
      "grad_norm": 0.0,
      "learning_rate": 4.1532663316582916e-05,
      "loss": 0.0449,
      "step": 3470
    },
    {
      "epoch": 0.1261600928074246,
      "grad_norm": 49.00734608916427,
      "learning_rate": 4.150753768844221e-05,
      "loss": 0.3139,
      "step": 3480
    },
    {
      "epoch": 0.12652262180974477,
      "grad_norm": 0.7464353568263438,
      "learning_rate": 4.148241206030151e-05,
      "loss": 0.4191,
      "step": 3490
    },
    {
      "epoch": 0.12688515081206497,
      "grad_norm": 26.751781939042164,
      "learning_rate": 4.1457286432160806e-05,
      "loss": 0.2946,
      "step": 3500
    },
    {
      "epoch": 0.12688515081206497,
      "eval_loss": NaN,
      "eval_runtime": 68.0802,
      "eval_samples_per_second": 9.357,
      "eval_steps_per_second": 1.572,
      "step": 3500
    },
    {
      "epoch": 0.12724767981438515,
      "grad_norm": 0.0,
      "learning_rate": 4.14321608040201e-05,
      "loss": 1.1157,
      "step": 3510
    },
    {
      "epoch": 0.12761020881670534,
      "grad_norm": 0.0,
      "learning_rate": 4.14070351758794e-05,
      "loss": 0.1863,
      "step": 3520
    },
    {
      "epoch": 0.12797273781902552,
      "grad_norm": 0.0,
      "learning_rate": 4.1381909547738696e-05,
      "loss": 1.1116,
      "step": 3530
    },
    {
      "epoch": 0.12833526682134572,
      "grad_norm": 0.0,
      "learning_rate": 4.135678391959799e-05,
      "loss": 1.2975,
      "step": 3540
    },
    {
      "epoch": 0.1286977958236659,
      "grad_norm": 0.0,
      "learning_rate": 4.133165829145729e-05,
      "loss": 0.0,
      "step": 3550
    },
    {
      "epoch": 0.1290603248259861,
      "grad_norm": 0.0,
      "learning_rate": 4.1306532663316586e-05,
      "loss": 0.2979,
      "step": 3560
    },
    {
      "epoch": 0.12942285382830626,
      "grad_norm": 0.0,
      "learning_rate": 4.128140703517588e-05,
      "loss": 0.9394,
      "step": 3570
    },
    {
      "epoch": 0.12978538283062646,
      "grad_norm": 0.0,
      "learning_rate": 4.125628140703518e-05,
      "loss": 0.8476,
      "step": 3580
    },
    {
      "epoch": 0.13014791183294663,
      "grad_norm": 0.0,
      "learning_rate": 4.1231155778894476e-05,
      "loss": 0.4731,
      "step": 3590
    },
    {
      "epoch": 0.13051044083526683,
      "grad_norm": 0.0,
      "learning_rate": 4.120603015075377e-05,
      "loss": 0.8721,
      "step": 3600
    },
    {
      "epoch": 0.130872969837587,
      "grad_norm": 10.353784401871119,
      "learning_rate": 4.118090452261307e-05,
      "loss": 0.6488,
      "step": 3610
    },
    {
      "epoch": 0.1312354988399072,
      "grad_norm": 0.0,
      "learning_rate": 4.1155778894472365e-05,
      "loss": 0.1355,
      "step": 3620
    },
    {
      "epoch": 0.13159802784222738,
      "grad_norm": 0.0,
      "learning_rate": 4.113065326633166e-05,
      "loss": 0.2033,
      "step": 3630
    },
    {
      "epoch": 0.13196055684454758,
      "grad_norm": 1.6164394251727114,
      "learning_rate": 4.110552763819095e-05,
      "loss": 0.6543,
      "step": 3640
    },
    {
      "epoch": 0.13232308584686775,
      "grad_norm": 0.0,
      "learning_rate": 4.108040201005025e-05,
      "loss": 0.085,
      "step": 3650
    },
    {
      "epoch": 0.13268561484918792,
      "grad_norm": 0.0,
      "learning_rate": 4.105527638190955e-05,
      "loss": 0.5156,
      "step": 3660
    },
    {
      "epoch": 0.13304814385150812,
      "grad_norm": 0.0,
      "learning_rate": 4.103015075376885e-05,
      "loss": 0.0288,
      "step": 3670
    },
    {
      "epoch": 0.1334106728538283,
      "grad_norm": 0.0,
      "learning_rate": 4.1005025125628145e-05,
      "loss": 0.8236,
      "step": 3680
    },
    {
      "epoch": 0.1337732018561485,
      "grad_norm": 27.569049498203142,
      "learning_rate": 4.097989949748744e-05,
      "loss": 0.6383,
      "step": 3690
    },
    {
      "epoch": 0.13413573085846867,
      "grad_norm": 0.0,
      "learning_rate": 4.095477386934674e-05,
      "loss": 0.5733,
      "step": 3700
    },
    {
      "epoch": 0.13449825986078887,
      "grad_norm": 24.795385805156624,
      "learning_rate": 4.092964824120603e-05,
      "loss": 0.321,
      "step": 3710
    },
    {
      "epoch": 0.13486078886310904,
      "grad_norm": 0.0,
      "learning_rate": 4.0904522613065325e-05,
      "loss": 0.0402,
      "step": 3720
    },
    {
      "epoch": 0.13522331786542924,
      "grad_norm": 0.0,
      "learning_rate": 4.087939698492462e-05,
      "loss": 0.4386,
      "step": 3730
    },
    {
      "epoch": 0.1355858468677494,
      "grad_norm": 0.0,
      "learning_rate": 4.0854271356783925e-05,
      "loss": 0.0,
      "step": 3740
    },
    {
      "epoch": 0.1359483758700696,
      "grad_norm": 26.40618296958948,
      "learning_rate": 4.082914572864322e-05,
      "loss": 0.6366,
      "step": 3750
    },
    {
      "epoch": 0.13631090487238978,
      "grad_norm": 16.68625821983186,
      "learning_rate": 4.080402010050252e-05,
      "loss": 0.1956,
      "step": 3760
    },
    {
      "epoch": 0.13667343387470998,
      "grad_norm": 0.0,
      "learning_rate": 4.0778894472361815e-05,
      "loss": 0.6643,
      "step": 3770
    },
    {
      "epoch": 0.13703596287703015,
      "grad_norm": 0.0,
      "learning_rate": 4.0753768844221105e-05,
      "loss": 0.4108,
      "step": 3780
    },
    {
      "epoch": 0.13739849187935035,
      "grad_norm": 0.0,
      "learning_rate": 4.07286432160804e-05,
      "loss": 1.0685,
      "step": 3790
    },
    {
      "epoch": 0.13776102088167053,
      "grad_norm": 0.0,
      "learning_rate": 4.07035175879397e-05,
      "loss": 1.5358,
      "step": 3800
    },
    {
      "epoch": 0.13812354988399073,
      "grad_norm": 0.0,
      "learning_rate": 4.0678391959798995e-05,
      "loss": 0.7582,
      "step": 3810
    },
    {
      "epoch": 0.1384860788863109,
      "grad_norm": 0.0,
      "learning_rate": 4.065326633165829e-05,
      "loss": 1.1844,
      "step": 3820
    },
    {
      "epoch": 0.1388486078886311,
      "grad_norm": 16.97731569026373,
      "learning_rate": 4.0628140703517595e-05,
      "loss": 0.2594,
      "step": 3830
    },
    {
      "epoch": 0.13921113689095127,
      "grad_norm": 0.0,
      "learning_rate": 4.060301507537689e-05,
      "loss": 0.5509,
      "step": 3840
    },
    {
      "epoch": 0.13957366589327147,
      "grad_norm": 0.0,
      "learning_rate": 4.057788944723618e-05,
      "loss": 0.009,
      "step": 3850
    },
    {
      "epoch": 0.13993619489559164,
      "grad_norm": 12.463468346046,
      "learning_rate": 4.055276381909548e-05,
      "loss": 0.0721,
      "step": 3860
    },
    {
      "epoch": 0.14029872389791184,
      "grad_norm": 0.0,
      "learning_rate": 4.0527638190954774e-05,
      "loss": 0.8728,
      "step": 3870
    },
    {
      "epoch": 0.14066125290023201,
      "grad_norm": 0.0,
      "learning_rate": 4.050251256281407e-05,
      "loss": 0.0152,
      "step": 3880
    },
    {
      "epoch": 0.14102378190255221,
      "grad_norm": 26.095554531540305,
      "learning_rate": 4.047738693467337e-05,
      "loss": 0.1352,
      "step": 3890
    },
    {
      "epoch": 0.1413863109048724,
      "grad_norm": 0.0,
      "learning_rate": 4.0452261306532664e-05,
      "loss": 0.0019,
      "step": 3900
    },
    {
      "epoch": 0.1417488399071926,
      "grad_norm": 0.0,
      "learning_rate": 4.042713567839197e-05,
      "loss": 0.2165,
      "step": 3910
    },
    {
      "epoch": 0.14211136890951276,
      "grad_norm": 0.42995614410359606,
      "learning_rate": 4.040201005025126e-05,
      "loss": 0.0011,
      "step": 3920
    },
    {
      "epoch": 0.14247389791183296,
      "grad_norm": 0.0,
      "learning_rate": 4.0376884422110554e-05,
      "loss": 0.9782,
      "step": 3930
    },
    {
      "epoch": 0.14283642691415313,
      "grad_norm": 0.0,
      "learning_rate": 4.035175879396985e-05,
      "loss": 1.2303,
      "step": 3940
    },
    {
      "epoch": 0.14319895591647333,
      "grad_norm": 0.0,
      "learning_rate": 4.032663316582915e-05,
      "loss": 0.8941,
      "step": 3950
    },
    {
      "epoch": 0.1435614849187935,
      "grad_norm": 0.0,
      "learning_rate": 4.0301507537688444e-05,
      "loss": 0.0904,
      "step": 3960
    },
    {
      "epoch": 0.1439240139211137,
      "grad_norm": 0.0,
      "learning_rate": 4.027638190954774e-05,
      "loss": 0.1739,
      "step": 3970
    },
    {
      "epoch": 0.14428654292343387,
      "grad_norm": 1.4176024076684608,
      "learning_rate": 4.025125628140704e-05,
      "loss": 0.5433,
      "step": 3980
    },
    {
      "epoch": 0.14464907192575405,
      "grad_norm": 25.191162448909413,
      "learning_rate": 4.0226130653266334e-05,
      "loss": 1.4671,
      "step": 3990
    },
    {
      "epoch": 0.14501160092807425,
      "grad_norm": 18.837911583872476,
      "learning_rate": 4.020100502512563e-05,
      "loss": 0.0963,
      "step": 4000
    },
    {
      "epoch": 0.14501160092807425,
      "eval_loss": NaN,
      "eval_runtime": 66.8237,
      "eval_samples_per_second": 9.533,
      "eval_steps_per_second": 1.601,
      "step": 4000
    },
    {
      "epoch": 0.14537412993039442,
      "grad_norm": 6.269351146166987,
      "learning_rate": 4.017587939698493e-05,
      "loss": 0.1972,
      "step": 4010
    },
    {
      "epoch": 0.14573665893271462,
      "grad_norm": 0.0,
      "learning_rate": 4.0150753768844224e-05,
      "loss": 0.1846,
      "step": 4020
    },
    {
      "epoch": 0.1460991879350348,
      "grad_norm": 0.19913440676678823,
      "learning_rate": 4.012562814070352e-05,
      "loss": 0.0304,
      "step": 4030
    },
    {
      "epoch": 0.146461716937355,
      "grad_norm": 23.806395061007898,
      "learning_rate": 4.010050251256282e-05,
      "loss": 0.3532,
      "step": 4040
    },
    {
      "epoch": 0.14682424593967516,
      "grad_norm": 2.343263397565949,
      "learning_rate": 4.0075376884422113e-05,
      "loss": 2.1474,
      "step": 4050
    },
    {
      "epoch": 0.14718677494199536,
      "grad_norm": 0.0,
      "learning_rate": 4.005025125628141e-05,
      "loss": 0.3343,
      "step": 4060
    },
    {
      "epoch": 0.14754930394431554,
      "grad_norm": 0.0,
      "learning_rate": 4.00251256281407e-05,
      "loss": 0.4493,
      "step": 4070
    },
    {
      "epoch": 0.14791183294663574,
      "grad_norm": 0.0,
      "learning_rate": 4e-05,
      "loss": 0.0,
      "step": 4080
    },
    {
      "epoch": 0.1482743619489559,
      "grad_norm": 0.0,
      "learning_rate": 3.99748743718593e-05,
      "loss": 0.2762,
      "step": 4090
    },
    {
      "epoch": 0.1486368909512761,
      "grad_norm": 25.63793618785756,
      "learning_rate": 3.9949748743718597e-05,
      "loss": 0.6183,
      "step": 4100
    },
    {
      "epoch": 0.14899941995359628,
      "grad_norm": 24.240772497375804,
      "learning_rate": 3.992462311557789e-05,
      "loss": 0.1232,
      "step": 4110
    },
    {
      "epoch": 0.14936194895591648,
      "grad_norm": 0.0,
      "learning_rate": 3.989949748743719e-05,
      "loss": 0.5845,
      "step": 4120
    },
    {
      "epoch": 0.14972447795823665,
      "grad_norm": 0.0,
      "learning_rate": 3.9874371859296486e-05,
      "loss": 0.5527,
      "step": 4130
    },
    {
      "epoch": 0.15008700696055685,
      "grad_norm": 2.7154937185637316,
      "learning_rate": 3.9849246231155776e-05,
      "loss": 0.8422,
      "step": 4140
    },
    {
      "epoch": 0.15044953596287702,
      "grad_norm": 0.05691823261381252,
      "learning_rate": 3.982412060301507e-05,
      "loss": 0.0299,
      "step": 4150
    },
    {
      "epoch": 0.15081206496519722,
      "grad_norm": 11.852675484366191,
      "learning_rate": 3.9798994974874376e-05,
      "loss": 0.1428,
      "step": 4160
    },
    {
      "epoch": 0.1511745939675174,
      "grad_norm": 0.7333842960624801,
      "learning_rate": 3.977386934673367e-05,
      "loss": 0.787,
      "step": 4170
    },
    {
      "epoch": 0.1515371229698376,
      "grad_norm": 15.690569938193818,
      "learning_rate": 3.974874371859297e-05,
      "loss": 0.9864,
      "step": 4180
    },
    {
      "epoch": 0.15189965197215777,
      "grad_norm": 0.14875319439399196,
      "learning_rate": 3.9723618090452266e-05,
      "loss": 0.3249,
      "step": 4190
    },
    {
      "epoch": 0.15226218097447797,
      "grad_norm": 0.0,
      "learning_rate": 3.969849246231156e-05,
      "loss": 0.3306,
      "step": 4200
    },
    {
      "epoch": 0.15262470997679814,
      "grad_norm": 0.0,
      "learning_rate": 3.967336683417085e-05,
      "loss": 0.3651,
      "step": 4210
    },
    {
      "epoch": 0.15298723897911834,
      "grad_norm": 20.68094256793067,
      "learning_rate": 3.964824120603015e-05,
      "loss": 1.0696,
      "step": 4220
    },
    {
      "epoch": 0.1533497679814385,
      "grad_norm": 15.721885656581808,
      "learning_rate": 3.9623115577889446e-05,
      "loss": 0.6524,
      "step": 4230
    },
    {
      "epoch": 0.1537122969837587,
      "grad_norm": 0.0,
      "learning_rate": 3.959798994974875e-05,
      "loss": 0.9862,
      "step": 4240
    },
    {
      "epoch": 0.15407482598607888,
      "grad_norm": 21.56301516594734,
      "learning_rate": 3.9572864321608046e-05,
      "loss": 0.9767,
      "step": 4250
    },
    {
      "epoch": 0.15443735498839908,
      "grad_norm": 0.0,
      "learning_rate": 3.954773869346734e-05,
      "loss": 0.0218,
      "step": 4260
    },
    {
      "epoch": 0.15479988399071926,
      "grad_norm": 0.0,
      "learning_rate": 3.952261306532664e-05,
      "loss": 0.3141,
      "step": 4270
    },
    {
      "epoch": 0.15516241299303946,
      "grad_norm": 0.0,
      "learning_rate": 3.949748743718593e-05,
      "loss": 0.3639,
      "step": 4280
    },
    {
      "epoch": 0.15552494199535963,
      "grad_norm": 0.0,
      "learning_rate": 3.9472361809045226e-05,
      "loss": 0.3783,
      "step": 4290
    },
    {
      "epoch": 0.15588747099767983,
      "grad_norm": 0.0,
      "learning_rate": 3.944723618090452e-05,
      "loss": 0.1826,
      "step": 4300
    },
    {
      "epoch": 0.15625,
      "grad_norm": 0.0,
      "learning_rate": 3.942211055276382e-05,
      "loss": 0.5835,
      "step": 4310
    },
    {
      "epoch": 0.15661252900232017,
      "grad_norm": 0.0,
      "learning_rate": 3.9396984924623115e-05,
      "loss": 0.0046,
      "step": 4320
    },
    {
      "epoch": 0.15697505800464037,
      "grad_norm": 0.0,
      "learning_rate": 3.937185929648242e-05,
      "loss": 0.6351,
      "step": 4330
    },
    {
      "epoch": 0.15733758700696054,
      "grad_norm": 0.0,
      "learning_rate": 3.9346733668341715e-05,
      "loss": 0.4443,
      "step": 4340
    },
    {
      "epoch": 0.15770011600928074,
      "grad_norm": 0.0,
      "learning_rate": 3.9321608040201005e-05,
      "loss": 0.1673,
      "step": 4350
    },
    {
      "epoch": 0.15806264501160092,
      "grad_norm": 0.0,
      "learning_rate": 3.92964824120603e-05,
      "loss": 0.0,
      "step": 4360
    },
    {
      "epoch": 0.15842517401392112,
      "grad_norm": 0.3607079622383466,
      "learning_rate": 3.92713567839196e-05,
      "loss": 0.0614,
      "step": 4370
    },
    {
      "epoch": 0.1587877030162413,
      "grad_norm": 0.0,
      "learning_rate": 3.9246231155778895e-05,
      "loss": 0.3199,
      "step": 4380
    },
    {
      "epoch": 0.1591502320185615,
      "grad_norm": 0.0,
      "learning_rate": 3.922110552763819e-05,
      "loss": 0.202,
      "step": 4390
    },
    {
      "epoch": 0.15951276102088166,
      "grad_norm": 0.0,
      "learning_rate": 3.919597989949749e-05,
      "loss": 0.7321,
      "step": 4400
    },
    {
      "epoch": 0.15987529002320186,
      "grad_norm": 0.0,
      "learning_rate": 3.9170854271356785e-05,
      "loss": 0.3711,
      "step": 4410
    },
    {
      "epoch": 0.16023781902552203,
      "grad_norm": 47.28244277246312,
      "learning_rate": 3.914572864321608e-05,
      "loss": 0.2986,
      "step": 4420
    },
    {
      "epoch": 0.16060034802784223,
      "grad_norm": 0.0,
      "learning_rate": 3.912060301507538e-05,
      "loss": 1.2012,
      "step": 4430
    },
    {
      "epoch": 0.1609628770301624,
      "grad_norm": 0.0,
      "learning_rate": 3.9095477386934675e-05,
      "loss": 0.1968,
      "step": 4440
    },
    {
      "epoch": 0.1613254060324826,
      "grad_norm": 0.0,
      "learning_rate": 3.907035175879397e-05,
      "loss": 0.0199,
      "step": 4450
    },
    {
      "epoch": 0.16168793503480278,
      "grad_norm": 0.0,
      "learning_rate": 3.904522613065327e-05,
      "loss": 0.2235,
      "step": 4460
    },
    {
      "epoch": 0.16205046403712298,
      "grad_norm": 0.0,
      "learning_rate": 3.9020100502512565e-05,
      "loss": 1.0727,
      "step": 4470
    },
    {
      "epoch": 0.16241299303944315,
      "grad_norm": 0.0,
      "learning_rate": 3.899497487437186e-05,
      "loss": 0.6377,
      "step": 4480
    },
    {
      "epoch": 0.16277552204176335,
      "grad_norm": 48.174411525012424,
      "learning_rate": 3.896984924623116e-05,
      "loss": 0.323,
      "step": 4490
    },
    {
      "epoch": 0.16313805104408352,
      "grad_norm": 31.686857619536546,
      "learning_rate": 3.8944723618090455e-05,
      "loss": 1.2545,
      "step": 4500
    },
    {
      "epoch": 0.16313805104408352,
      "eval_loss": NaN,
      "eval_runtime": 67.2023,
      "eval_samples_per_second": 9.479,
      "eval_steps_per_second": 1.592,
      "step": 4500
    },
    {
      "epoch": 0.16350058004640372,
      "grad_norm": 0.0,
      "learning_rate": 3.891959798994975e-05,
      "loss": 0.5523,
      "step": 4510
    },
    {
      "epoch": 0.1638631090487239,
      "grad_norm": 0.0,
      "learning_rate": 3.889447236180905e-05,
      "loss": 1.4335,
      "step": 4520
    },
    {
      "epoch": 0.1642256380510441,
      "grad_norm": 0.0,
      "learning_rate": 3.8869346733668344e-05,
      "loss": 0.5418,
      "step": 4530
    },
    {
      "epoch": 0.16458816705336426,
      "grad_norm": 0.0,
      "learning_rate": 3.884422110552764e-05,
      "loss": 0.5724,
      "step": 4540
    },
    {
      "epoch": 0.16495069605568446,
      "grad_norm": 0.0,
      "learning_rate": 3.881909547738694e-05,
      "loss": 0.4617,
      "step": 4550
    },
    {
      "epoch": 0.16531322505800464,
      "grad_norm": 0.0,
      "learning_rate": 3.8793969849246234e-05,
      "loss": 0.3177,
      "step": 4560
    },
    {
      "epoch": 0.16567575406032484,
      "grad_norm": 0.0,
      "learning_rate": 3.8768844221105524e-05,
      "loss": 0.0561,
      "step": 4570
    },
    {
      "epoch": 0.166038283062645,
      "grad_norm": 0.0,
      "learning_rate": 3.874371859296483e-05,
      "loss": 0.06,
      "step": 4580
    },
    {
      "epoch": 0.1664008120649652,
      "grad_norm": 0.0,
      "learning_rate": 3.8718592964824124e-05,
      "loss": 0.8534,
      "step": 4590
    },
    {
      "epoch": 0.16676334106728538,
      "grad_norm": 0.0,
      "learning_rate": 3.869346733668342e-05,
      "loss": 1.4401,
      "step": 4600
    },
    {
      "epoch": 0.16712587006960558,
      "grad_norm": 0.0,
      "learning_rate": 3.866834170854272e-05,
      "loss": 0.4114,
      "step": 4610
    },
    {
      "epoch": 0.16748839907192575,
      "grad_norm": 0.0,
      "learning_rate": 3.8643216080402014e-05,
      "loss": 0.319,
      "step": 4620
    },
    {
      "epoch": 0.16785092807424595,
      "grad_norm": 19.884246786430506,
      "learning_rate": 3.861809045226131e-05,
      "loss": 0.643,
      "step": 4630
    },
    {
      "epoch": 0.16821345707656613,
      "grad_norm": 0.0,
      "learning_rate": 3.85929648241206e-05,
      "loss": 0.184,
      "step": 4640
    },
    {
      "epoch": 0.1685759860788863,
      "grad_norm": 0.0,
      "learning_rate": 3.85678391959799e-05,
      "loss": 0.7417,
      "step": 4650
    },
    {
      "epoch": 0.1689385150812065,
      "grad_norm": 0.8228789735362323,
      "learning_rate": 3.85427135678392e-05,
      "loss": 0.5711,
      "step": 4660
    },
    {
      "epoch": 0.16930104408352667,
      "grad_norm": 0.0,
      "learning_rate": 3.85175879396985e-05,
      "loss": 0.0755,
      "step": 4670
    },
    {
      "epoch": 0.16966357308584687,
      "grad_norm": 0.0,
      "learning_rate": 3.8492462311557794e-05,
      "loss": 0.0856,
      "step": 4680
    },
    {
      "epoch": 0.17002610208816704,
      "grad_norm": 0.0,
      "learning_rate": 3.846733668341709e-05,
      "loss": 1.1596,
      "step": 4690
    },
    {
      "epoch": 0.17038863109048724,
      "grad_norm": 0.0,
      "learning_rate": 3.844221105527639e-05,
      "loss": 0.2654,
      "step": 4700
    },
    {
      "epoch": 0.1707511600928074,
      "grad_norm": 0.0,
      "learning_rate": 3.841708542713568e-05,
      "loss": 0.7501,
      "step": 4710
    },
    {
      "epoch": 0.1711136890951276,
      "grad_norm": 0.8236086788716962,
      "learning_rate": 3.8391959798994973e-05,
      "loss": 0.1426,
      "step": 4720
    },
    {
      "epoch": 0.17147621809744779,
      "grad_norm": 0.0,
      "learning_rate": 3.836683417085427e-05,
      "loss": 0.0009,
      "step": 4730
    },
    {
      "epoch": 0.17183874709976799,
      "grad_norm": 0.04530577815282835,
      "learning_rate": 3.834170854271357e-05,
      "loss": 0.7579,
      "step": 4740
    },
    {
      "epoch": 0.17220127610208816,
      "grad_norm": 0.0,
      "learning_rate": 3.831658291457287e-05,
      "loss": 0.0,
      "step": 4750
    },
    {
      "epoch": 0.17256380510440836,
      "grad_norm": 31.57000703576547,
      "learning_rate": 3.829145728643217e-05,
      "loss": 0.2003,
      "step": 4760
    },
    {
      "epoch": 0.17292633410672853,
      "grad_norm": 0.0,
      "learning_rate": 3.8266331658291457e-05,
      "loss": 0.1838,
      "step": 4770
    },
    {
      "epoch": 0.17328886310904873,
      "grad_norm": 0.0,
      "learning_rate": 3.824120603015075e-05,
      "loss": 0.0745,
      "step": 4780
    },
    {
      "epoch": 0.1736513921113689,
      "grad_norm": 0.0,
      "learning_rate": 3.821608040201005e-05,
      "loss": 0.2081,
      "step": 4790
    },
    {
      "epoch": 0.1740139211136891,
      "grad_norm": 38.24124982890285,
      "learning_rate": 3.8190954773869346e-05,
      "loss": 0.8734,
      "step": 4800
    },
    {
      "epoch": 0.17437645011600927,
      "grad_norm": 0.20235104934310957,
      "learning_rate": 3.816582914572864e-05,
      "loss": 0.1854,
      "step": 4810
    },
    {
      "epoch": 0.17473897911832947,
      "grad_norm": 0.0,
      "learning_rate": 3.814070351758794e-05,
      "loss": 0.6531,
      "step": 4820
    },
    {
      "epoch": 0.17510150812064965,
      "grad_norm": 12.528190867250148,
      "learning_rate": 3.811557788944724e-05,
      "loss": 0.496,
      "step": 4830
    },
    {
      "epoch": 0.17546403712296985,
      "grad_norm": 26.595806324729093,
      "learning_rate": 3.809045226130653e-05,
      "loss": 0.3078,
      "step": 4840
    },
    {
      "epoch": 0.17582656612529002,
      "grad_norm": 0.0,
      "learning_rate": 3.806532663316583e-05,
      "loss": 0.645,
      "step": 4850
    },
    {
      "epoch": 0.17618909512761022,
      "grad_norm": 0.0,
      "learning_rate": 3.8040201005025126e-05,
      "loss": 0.4361,
      "step": 4860
    },
    {
      "epoch": 0.1765516241299304,
      "grad_norm": 0.0,
      "learning_rate": 3.801507537688442e-05,
      "loss": 0.0,
      "step": 4870
    },
    {
      "epoch": 0.1769141531322506,
      "grad_norm": 0.0,
      "learning_rate": 3.798994974874372e-05,
      "loss": 0.7957,
      "step": 4880
    },
    {
      "epoch": 0.17727668213457076,
      "grad_norm": 0.0,
      "learning_rate": 3.7964824120603016e-05,
      "loss": 0.1357,
      "step": 4890
    },
    {
      "epoch": 0.17763921113689096,
      "grad_norm": 0.0,
      "learning_rate": 3.793969849246231e-05,
      "loss": 0.2402,
      "step": 4900
    },
    {
      "epoch": 0.17800174013921113,
      "grad_norm": 0.0,
      "learning_rate": 3.791457286432161e-05,
      "loss": 0.0528,
      "step": 4910
    },
    {
      "epoch": 0.17836426914153133,
      "grad_norm": 11.455544168109169,
      "learning_rate": 3.7889447236180906e-05,
      "loss": 0.1698,
      "step": 4920
    },
    {
      "epoch": 0.1787267981438515,
      "grad_norm": 0.0,
      "learning_rate": 3.78643216080402e-05,
      "loss": 0.8638,
      "step": 4930
    },
    {
      "epoch": 0.1790893271461717,
      "grad_norm": 11.45244684852802,
      "learning_rate": 3.78391959798995e-05,
      "loss": 0.2807,
      "step": 4940
    },
    {
      "epoch": 0.17945185614849188,
      "grad_norm": 0.0,
      "learning_rate": 3.7814070351758796e-05,
      "loss": 0.1133,
      "step": 4950
    },
    {
      "epoch": 0.17981438515081208,
      "grad_norm": 0.0,
      "learning_rate": 3.778894472361809e-05,
      "loss": 0.0001,
      "step": 4960
    },
    {
      "epoch": 0.18017691415313225,
      "grad_norm": 19.014429335355263,
      "learning_rate": 3.776381909547739e-05,
      "loss": 1.1347,
      "step": 4970
    },
    {
      "epoch": 0.18053944315545242,
      "grad_norm": 1.7534942482885787,
      "learning_rate": 3.7738693467336686e-05,
      "loss": 0.004,
      "step": 4980
    },
    {
      "epoch": 0.18090197215777262,
      "grad_norm": 7.155915231662151,
      "learning_rate": 3.771356783919598e-05,
      "loss": 0.614,
      "step": 4990
    },
    {
      "epoch": 0.1812645011600928,
      "grad_norm": 0.0,
      "learning_rate": 3.768844221105528e-05,
      "loss": 0.278,
      "step": 5000
    },
    {
      "epoch": 0.1812645011600928,
      "eval_loss": NaN,
      "eval_runtime": 67.3627,
      "eval_samples_per_second": 9.456,
      "eval_steps_per_second": 1.588,
      "step": 5000
    },
    {
      "epoch": 0.181627030162413,
      "grad_norm": 0.0,
      "learning_rate": 3.7663316582914575e-05,
      "loss": 0.3441,
      "step": 5010
    },
    {
      "epoch": 0.18198955916473317,
      "grad_norm": 17.57387535436345,
      "learning_rate": 3.763819095477387e-05,
      "loss": 0.0885,
      "step": 5020
    },
    {
      "epoch": 0.18235208816705337,
      "grad_norm": 3.8649938044924017,
      "learning_rate": 3.761306532663317e-05,
      "loss": 0.2631,
      "step": 5030
    },
    {
      "epoch": 0.18271461716937354,
      "grad_norm": 0.0,
      "learning_rate": 3.7587939698492465e-05,
      "loss": 0.1558,
      "step": 5040
    },
    {
      "epoch": 0.18307714617169374,
      "grad_norm": 0.0,
      "learning_rate": 3.756281407035176e-05,
      "loss": 0.2102,
      "step": 5050
    },
    {
      "epoch": 0.1834396751740139,
      "grad_norm": 9.305055651039671,
      "learning_rate": 3.753768844221106e-05,
      "loss": 1.0493,
      "step": 5060
    },
    {
      "epoch": 0.1838022041763341,
      "grad_norm": 32.268547461474576,
      "learning_rate": 3.751256281407035e-05,
      "loss": 1.3375,
      "step": 5070
    },
    {
      "epoch": 0.18416473317865428,
      "grad_norm": 0.22252057777305348,
      "learning_rate": 3.748743718592965e-05,
      "loss": 0.5474,
      "step": 5080
    },
    {
      "epoch": 0.18452726218097448,
      "grad_norm": 0.0,
      "learning_rate": 3.746231155778895e-05,
      "loss": 0.3477,
      "step": 5090
    },
    {
      "epoch": 0.18488979118329466,
      "grad_norm": 0.0,
      "learning_rate": 3.7437185929648245e-05,
      "loss": 0.5039,
      "step": 5100
    },
    {
      "epoch": 0.18525232018561485,
      "grad_norm": 7.581399552268867,
      "learning_rate": 3.741206030150754e-05,
      "loss": 0.4489,
      "step": 5110
    },
    {
      "epoch": 0.18561484918793503,
      "grad_norm": 10.980459369993325,
      "learning_rate": 3.738693467336684e-05,
      "loss": 0.8197,
      "step": 5120
    },
    {
      "epoch": 0.18597737819025523,
      "grad_norm": 0.0,
      "learning_rate": 3.7361809045226135e-05,
      "loss": 1.6284,
      "step": 5130
    },
    {
      "epoch": 0.1863399071925754,
      "grad_norm": 3.4917994204634697,
      "learning_rate": 3.7336683417085425e-05,
      "loss": 0.1079,
      "step": 5140
    },
    {
      "epoch": 0.1867024361948956,
      "grad_norm": 0.0,
      "learning_rate": 3.731155778894472e-05,
      "loss": 0.0,
      "step": 5150
    },
    {
      "epoch": 0.18706496519721577,
      "grad_norm": 0.0,
      "learning_rate": 3.7286432160804025e-05,
      "loss": 0.031,
      "step": 5160
    },
    {
      "epoch": 0.18742749419953597,
      "grad_norm": 18.68074612746788,
      "learning_rate": 3.726130653266332e-05,
      "loss": 0.2617,
      "step": 5170
    },
    {
      "epoch": 0.18779002320185614,
      "grad_norm": 14.858670030431465,
      "learning_rate": 3.723618090452262e-05,
      "loss": 0.357,
      "step": 5180
    },
    {
      "epoch": 0.18815255220417634,
      "grad_norm": 0.0,
      "learning_rate": 3.7211055276381915e-05,
      "loss": 0.2377,
      "step": 5190
    },
    {
      "epoch": 0.18851508120649652,
      "grad_norm": 0.0,
      "learning_rate": 3.7185929648241204e-05,
      "loss": 0.5303,
      "step": 5200
    },
    {
      "epoch": 0.18887761020881672,
      "grad_norm": 0.0,
      "learning_rate": 3.71608040201005e-05,
      "loss": 0.4772,
      "step": 5210
    },
    {
      "epoch": 0.1892401392111369,
      "grad_norm": 0.0,
      "learning_rate": 3.71356783919598e-05,
      "loss": 0.3449,
      "step": 5220
    },
    {
      "epoch": 0.1896026682134571,
      "grad_norm": 45.6556002905517,
      "learning_rate": 3.7110552763819094e-05,
      "loss": 0.6021,
      "step": 5230
    },
    {
      "epoch": 0.18996519721577726,
      "grad_norm": 0.0,
      "learning_rate": 3.708542713567839e-05,
      "loss": 0.4773,
      "step": 5240
    },
    {
      "epoch": 0.19032772621809746,
      "grad_norm": 0.0,
      "learning_rate": 3.7060301507537694e-05,
      "loss": 0.7592,
      "step": 5250
    },
    {
      "epoch": 0.19069025522041763,
      "grad_norm": 0.0,
      "learning_rate": 3.703517587939699e-05,
      "loss": 0.2865,
      "step": 5260
    },
    {
      "epoch": 0.19105278422273783,
      "grad_norm": 7.5432094731137775,
      "learning_rate": 3.701005025125628e-05,
      "loss": 0.1384,
      "step": 5270
    },
    {
      "epoch": 0.191415313225058,
      "grad_norm": 0.0,
      "learning_rate": 3.698492462311558e-05,
      "loss": 0.456,
      "step": 5280
    },
    {
      "epoch": 0.1917778422273782,
      "grad_norm": 0.0,
      "learning_rate": 3.6959798994974874e-05,
      "loss": 0.3109,
      "step": 5290
    },
    {
      "epoch": 0.19214037122969838,
      "grad_norm": 0.0,
      "learning_rate": 3.693467336683417e-05,
      "loss": 0.8606,
      "step": 5300
    },
    {
      "epoch": 0.19250290023201855,
      "grad_norm": 0.0,
      "learning_rate": 3.690954773869347e-05,
      "loss": 0.1825,
      "step": 5310
    },
    {
      "epoch": 0.19286542923433875,
      "grad_norm": 9.62402338795345,
      "learning_rate": 3.6884422110552764e-05,
      "loss": 0.5344,
      "step": 5320
    },
    {
      "epoch": 0.19322795823665892,
      "grad_norm": 0.0,
      "learning_rate": 3.685929648241207e-05,
      "loss": 0.9154,
      "step": 5330
    },
    {
      "epoch": 0.19359048723897912,
      "grad_norm": 0.0,
      "learning_rate": 3.683417085427136e-05,
      "loss": 0.6504,
      "step": 5340
    },
    {
      "epoch": 0.1939530162412993,
      "grad_norm": 0.39988279935332405,
      "learning_rate": 3.6809045226130654e-05,
      "loss": 0.2403,
      "step": 5350
    },
    {
      "epoch": 0.1943155452436195,
      "grad_norm": 0.0,
      "learning_rate": 3.678391959798995e-05,
      "loss": 0.0864,
      "step": 5360
    },
    {
      "epoch": 0.19467807424593966,
      "grad_norm": 0.0,
      "learning_rate": 3.675879396984925e-05,
      "loss": 0.0,
      "step": 5370
    },
    {
      "epoch": 0.19504060324825986,
      "grad_norm": 0.0,
      "learning_rate": 3.6733668341708544e-05,
      "loss": 0.4311,
      "step": 5380
    },
    {
      "epoch": 0.19540313225058004,
      "grad_norm": 0.0,
      "learning_rate": 3.670854271356784e-05,
      "loss": 0.0,
      "step": 5390
    },
    {
      "epoch": 0.19576566125290024,
      "grad_norm": 0.0,
      "learning_rate": 3.668341708542714e-05,
      "loss": 0.0088,
      "step": 5400
    },
    {
      "epoch": 0.1961281902552204,
      "grad_norm": 0.895570343064166,
      "learning_rate": 3.6658291457286434e-05,
      "loss": 0.4567,
      "step": 5410
    },
    {
      "epoch": 0.1964907192575406,
      "grad_norm": 0.0,
      "learning_rate": 3.663316582914573e-05,
      "loss": 1.9078,
      "step": 5420
    },
    {
      "epoch": 0.19685324825986078,
      "grad_norm": 18.41908259821226,
      "learning_rate": 3.660804020100503e-05,
      "loss": 0.5505,
      "step": 5430
    },
    {
      "epoch": 0.19721577726218098,
      "grad_norm": 0.0,
      "learning_rate": 3.658291457286432e-05,
      "loss": 0.0192,
      "step": 5440
    },
    {
      "epoch": 0.19757830626450115,
      "grad_norm": 0.0,
      "learning_rate": 3.655778894472362e-05,
      "loss": 0.8499,
      "step": 5450
    },
    {
      "epoch": 0.19794083526682135,
      "grad_norm": 0.0,
      "learning_rate": 3.653266331658292e-05,
      "loss": 0.5118,
      "step": 5460
    },
    {
      "epoch": 0.19830336426914152,
      "grad_norm": 0.0,
      "learning_rate": 3.650753768844221e-05,
      "loss": 0.0908,
      "step": 5470
    },
    {
      "epoch": 0.19866589327146172,
      "grad_norm": 0.0,
      "learning_rate": 3.648241206030151e-05,
      "loss": 0.0559,
      "step": 5480
    },
    {
      "epoch": 0.1990284222737819,
      "grad_norm": 6.478533289657859,
      "learning_rate": 3.6457286432160806e-05,
      "loss": 0.3184,
      "step": 5490
    },
    {
      "epoch": 0.1993909512761021,
      "grad_norm": 33.220015924255854,
      "learning_rate": 3.64321608040201e-05,
      "loss": 0.0352,
      "step": 5500
    },
    {
      "epoch": 0.1993909512761021,
      "eval_loss": NaN,
      "eval_runtime": 67.3037,
      "eval_samples_per_second": 9.465,
      "eval_steps_per_second": 1.59,
      "step": 5500
    },
    {
      "epoch": 0.19975348027842227,
      "grad_norm": 34.75413960561479,
      "learning_rate": 3.64070351758794e-05,
      "loss": 0.658,
      "step": 5510
    },
    {
      "epoch": 0.20011600928074247,
      "grad_norm": 0.0,
      "learning_rate": 3.6381909547738696e-05,
      "loss": 0.1733,
      "step": 5520
    },
    {
      "epoch": 0.20047853828306264,
      "grad_norm": 0.0,
      "learning_rate": 3.635678391959799e-05,
      "loss": 1.172,
      "step": 5530
    },
    {
      "epoch": 0.20084106728538284,
      "grad_norm": 0.0,
      "learning_rate": 3.633165829145729e-05,
      "loss": 0.0,
      "step": 5540
    },
    {
      "epoch": 0.201203596287703,
      "grad_norm": 0.0,
      "learning_rate": 3.6306532663316586e-05,
      "loss": 0.33,
      "step": 5550
    },
    {
      "epoch": 0.2015661252900232,
      "grad_norm": 0.0,
      "learning_rate": 3.628140703517588e-05,
      "loss": 0.1477,
      "step": 5560
    },
    {
      "epoch": 0.20192865429234338,
      "grad_norm": 0.0,
      "learning_rate": 3.625628140703517e-05,
      "loss": 0.4566,
      "step": 5570
    },
    {
      "epoch": 0.20229118329466358,
      "grad_norm": 0.0,
      "learning_rate": 3.6231155778894476e-05,
      "loss": 0.6746,
      "step": 5580
    },
    {
      "epoch": 0.20265371229698376,
      "grad_norm": 0.37671655930365106,
      "learning_rate": 3.620603015075377e-05,
      "loss": 0.579,
      "step": 5590
    },
    {
      "epoch": 0.20301624129930396,
      "grad_norm": 0.0,
      "learning_rate": 3.618090452261307e-05,
      "loss": 0.1068,
      "step": 5600
    },
    {
      "epoch": 0.20337877030162413,
      "grad_norm": 0.034656062566587445,
      "learning_rate": 3.6155778894472366e-05,
      "loss": 0.003,
      "step": 5610
    },
    {
      "epoch": 0.20374129930394433,
      "grad_norm": 0.0,
      "learning_rate": 3.613065326633166e-05,
      "loss": 1.204,
      "step": 5620
    },
    {
      "epoch": 0.2041038283062645,
      "grad_norm": 3.0648419514616028,
      "learning_rate": 3.610552763819095e-05,
      "loss": 0.0855,
      "step": 5630
    },
    {
      "epoch": 0.20446635730858467,
      "grad_norm": 4.614300698378747,
      "learning_rate": 3.608040201005025e-05,
      "loss": 0.1846,
      "step": 5640
    },
    {
      "epoch": 0.20482888631090487,
      "grad_norm": 0.021288611140409773,
      "learning_rate": 3.6055276381909546e-05,
      "loss": 0.0004,
      "step": 5650
    },
    {
      "epoch": 0.20519141531322505,
      "grad_norm": 3.5581240631911726,
      "learning_rate": 3.603015075376884e-05,
      "loss": 0.2451,
      "step": 5660
    },
    {
      "epoch": 0.20555394431554525,
      "grad_norm": 0.0,
      "learning_rate": 3.6005025125628146e-05,
      "loss": 0.3413,
      "step": 5670
    },
    {
      "epoch": 0.20591647331786542,
      "grad_norm": 0.0,
      "learning_rate": 3.597989949748744e-05,
      "loss": 0.0784,
      "step": 5680
    },
    {
      "epoch": 0.20627900232018562,
      "grad_norm": 0.0,
      "learning_rate": 3.595477386934674e-05,
      "loss": 0.2093,
      "step": 5690
    },
    {
      "epoch": 0.2066415313225058,
      "grad_norm": 0.0,
      "learning_rate": 3.592964824120603e-05,
      "loss": 0.2604,
      "step": 5700
    },
    {
      "epoch": 0.207004060324826,
      "grad_norm": 19.283941294395788,
      "learning_rate": 3.5904522613065325e-05,
      "loss": 0.0263,
      "step": 5710
    },
    {
      "epoch": 0.20736658932714616,
      "grad_norm": 10.948595097963054,
      "learning_rate": 3.587939698492462e-05,
      "loss": 0.926,
      "step": 5720
    },
    {
      "epoch": 0.20772911832946636,
      "grad_norm": 2.4423436676878563,
      "learning_rate": 3.585427135678392e-05,
      "loss": 0.8969,
      "step": 5730
    },
    {
      "epoch": 0.20809164733178653,
      "grad_norm": 0.0,
      "learning_rate": 3.5829145728643215e-05,
      "loss": 0.3606,
      "step": 5740
    },
    {
      "epoch": 0.20845417633410673,
      "grad_norm": 0.0,
      "learning_rate": 3.580402010050252e-05,
      "loss": 0.0567,
      "step": 5750
    },
    {
      "epoch": 0.2088167053364269,
      "grad_norm": 0.0,
      "learning_rate": 3.5778894472361815e-05,
      "loss": 0.0,
      "step": 5760
    },
    {
      "epoch": 0.2091792343387471,
      "grad_norm": 0.0,
      "learning_rate": 3.5753768844221105e-05,
      "loss": 0.1801,
      "step": 5770
    },
    {
      "epoch": 0.20954176334106728,
      "grad_norm": 0.0,
      "learning_rate": 3.57286432160804e-05,
      "loss": 1.1053,
      "step": 5780
    },
    {
      "epoch": 0.20990429234338748,
      "grad_norm": 0.0,
      "learning_rate": 3.57035175879397e-05,
      "loss": 0.0,
      "step": 5790
    },
    {
      "epoch": 0.21026682134570765,
      "grad_norm": 0.0,
      "learning_rate": 3.5678391959798995e-05,
      "loss": 0.3947,
      "step": 5800
    },
    {
      "epoch": 0.21062935034802785,
      "grad_norm": 28.830943925524164,
      "learning_rate": 3.565326633165829e-05,
      "loss": 0.4569,
      "step": 5810
    },
    {
      "epoch": 0.21099187935034802,
      "grad_norm": 0.0,
      "learning_rate": 3.562814070351759e-05,
      "loss": 1.5737,
      "step": 5820
    },
    {
      "epoch": 0.21135440835266822,
      "grad_norm": 0.0,
      "learning_rate": 3.560301507537689e-05,
      "loss": 0.3899,
      "step": 5830
    },
    {
      "epoch": 0.2117169373549884,
      "grad_norm": 0.21165386169823103,
      "learning_rate": 3.557788944723618e-05,
      "loss": 0.0347,
      "step": 5840
    },
    {
      "epoch": 0.2120794663573086,
      "grad_norm": 52.62353861539767,
      "learning_rate": 3.555276381909548e-05,
      "loss": 0.4211,
      "step": 5850
    },
    {
      "epoch": 0.21244199535962877,
      "grad_norm": 54.52555038265318,
      "learning_rate": 3.5527638190954775e-05,
      "loss": 0.3255,
      "step": 5860
    },
    {
      "epoch": 0.21280452436194897,
      "grad_norm": 0.0,
      "learning_rate": 3.550251256281407e-05,
      "loss": 0.0,
      "step": 5870
    },
    {
      "epoch": 0.21316705336426914,
      "grad_norm": 0.0,
      "learning_rate": 3.547738693467337e-05,
      "loss": 0.061,
      "step": 5880
    },
    {
      "epoch": 0.21352958236658934,
      "grad_norm": 0.0,
      "learning_rate": 3.5452261306532665e-05,
      "loss": 0.0391,
      "step": 5890
    },
    {
      "epoch": 0.2138921113689095,
      "grad_norm": 17.292682418710378,
      "learning_rate": 3.542713567839196e-05,
      "loss": 0.2442,
      "step": 5900
    },
    {
      "epoch": 0.2142546403712297,
      "grad_norm": 0.0,
      "learning_rate": 3.540201005025126e-05,
      "loss": 0.3739,
      "step": 5910
    },
    {
      "epoch": 0.21461716937354988,
      "grad_norm": 29.998354040133393,
      "learning_rate": 3.5376884422110554e-05,
      "loss": 0.4827,
      "step": 5920
    },
    {
      "epoch": 0.21497969837587008,
      "grad_norm": 29.925664740423898,
      "learning_rate": 3.535175879396985e-05,
      "loss": 0.8226,
      "step": 5930
    },
    {
      "epoch": 0.21534222737819025,
      "grad_norm": 89.29596592931844,
      "learning_rate": 3.532663316582915e-05,
      "loss": 0.2753,
      "step": 5940
    },
    {
      "epoch": 0.21570475638051045,
      "grad_norm": 0.0,
      "learning_rate": 3.5301507537688444e-05,
      "loss": 0.1128,
      "step": 5950
    },
    {
      "epoch": 0.21606728538283063,
      "grad_norm": 89.29544919027929,
      "learning_rate": 3.527638190954774e-05,
      "loss": 0.4924,
      "step": 5960
    },
    {
      "epoch": 0.2164298143851508,
      "grad_norm": 0.0,
      "learning_rate": 3.525125628140704e-05,
      "loss": 0.0644,
      "step": 5970
    },
    {
      "epoch": 0.216792343387471,
      "grad_norm": 0.0,
      "learning_rate": 3.5226130653266334e-05,
      "loss": 0.7126,
      "step": 5980
    },
    {
      "epoch": 0.21715487238979117,
      "grad_norm": 0.0,
      "learning_rate": 3.520100502512563e-05,
      "loss": 0.8062,
      "step": 5990
    },
    {
      "epoch": 0.21751740139211137,
      "grad_norm": 0.0,
      "learning_rate": 3.517587939698493e-05,
      "loss": 0.3469,
      "step": 6000
    },
    {
      "epoch": 0.21751740139211137,
      "eval_loss": NaN,
      "eval_runtime": 67.1942,
      "eval_samples_per_second": 9.48,
      "eval_steps_per_second": 1.592,
      "step": 6000
    },
    {
      "epoch": 0.21787993039443154,
      "grad_norm": 9.185179540616469,
      "learning_rate": 3.5150753768844224e-05,
      "loss": 0.8962,
      "step": 6010
    },
    {
      "epoch": 0.21824245939675174,
      "grad_norm": 0.0,
      "learning_rate": 3.512562814070352e-05,
      "loss": 0.2197,
      "step": 6020
    },
    {
      "epoch": 0.21860498839907191,
      "grad_norm": 0.0,
      "learning_rate": 3.510050251256282e-05,
      "loss": 0.0215,
      "step": 6030
    },
    {
      "epoch": 0.21896751740139211,
      "grad_norm": 5.744314617179545,
      "learning_rate": 3.5075376884422114e-05,
      "loss": 0.9172,
      "step": 6040
    },
    {
      "epoch": 0.2193300464037123,
      "grad_norm": 0.0,
      "learning_rate": 3.505025125628141e-05,
      "loss": 0.4662,
      "step": 6050
    },
    {
      "epoch": 0.2196925754060325,
      "grad_norm": 11.398982327194965,
      "learning_rate": 3.50251256281407e-05,
      "loss": 0.3014,
      "step": 6060
    },
    {
      "epoch": 0.22005510440835266,
      "grad_norm": 17.083888694606024,
      "learning_rate": 3.5e-05,
      "loss": 0.2285,
      "step": 6070
    },
    {
      "epoch": 0.22041763341067286,
      "grad_norm": 0.0,
      "learning_rate": 3.49748743718593e-05,
      "loss": 0.6555,
      "step": 6080
    },
    {
      "epoch": 0.22078016241299303,
      "grad_norm": 25.36507849448233,
      "learning_rate": 3.49497487437186e-05,
      "loss": 0.5435,
      "step": 6090
    },
    {
      "epoch": 0.22114269141531323,
      "grad_norm": 20.2699373784954,
      "learning_rate": 3.4924623115577894e-05,
      "loss": 0.061,
      "step": 6100
    },
    {
      "epoch": 0.2215052204176334,
      "grad_norm": 0.0,
      "learning_rate": 3.489949748743719e-05,
      "loss": 0.1067,
      "step": 6110
    },
    {
      "epoch": 0.2218677494199536,
      "grad_norm": 0.0,
      "learning_rate": 3.487437185929649e-05,
      "loss": 0.4616,
      "step": 6120
    },
    {
      "epoch": 0.22223027842227377,
      "grad_norm": 0.0,
      "learning_rate": 3.484924623115578e-05,
      "loss": 0.0,
      "step": 6130
    },
    {
      "epoch": 0.22259280742459397,
      "grad_norm": 0.0,
      "learning_rate": 3.482412060301507e-05,
      "loss": 0.1736,
      "step": 6140
    },
    {
      "epoch": 0.22295533642691415,
      "grad_norm": 0.0,
      "learning_rate": 3.479899497487437e-05,
      "loss": 0.1632,
      "step": 6150
    },
    {
      "epoch": 0.22331786542923435,
      "grad_norm": 0.0,
      "learning_rate": 3.4773869346733667e-05,
      "loss": 0.5722,
      "step": 6160
    },
    {
      "epoch": 0.22368039443155452,
      "grad_norm": 0.0,
      "learning_rate": 3.474874371859297e-05,
      "loss": 0.4292,
      "step": 6170
    },
    {
      "epoch": 0.22404292343387472,
      "grad_norm": 0.0,
      "learning_rate": 3.4723618090452267e-05,
      "loss": 0.0047,
      "step": 6180
    },
    {
      "epoch": 0.2244054524361949,
      "grad_norm": 0.0,
      "learning_rate": 3.469849246231156e-05,
      "loss": 0.4303,
      "step": 6190
    },
    {
      "epoch": 0.2247679814385151,
      "grad_norm": 0.0,
      "learning_rate": 3.467336683417085e-05,
      "loss": 0.4505,
      "step": 6200
    },
    {
      "epoch": 0.22513051044083526,
      "grad_norm": 14.190208411806637,
      "learning_rate": 3.464824120603015e-05,
      "loss": 0.668,
      "step": 6210
    },
    {
      "epoch": 0.22549303944315546,
      "grad_norm": 0.0,
      "learning_rate": 3.4623115577889446e-05,
      "loss": 0.4992,
      "step": 6220
    },
    {
      "epoch": 0.22585556844547564,
      "grad_norm": 42.31868780917746,
      "learning_rate": 3.459798994974874e-05,
      "loss": 0.25,
      "step": 6230
    },
    {
      "epoch": 0.22621809744779584,
      "grad_norm": 74.0116353553193,
      "learning_rate": 3.457286432160804e-05,
      "loss": 0.5227,
      "step": 6240
    },
    {
      "epoch": 0.226580626450116,
      "grad_norm": 0.0,
      "learning_rate": 3.454773869346734e-05,
      "loss": 0.275,
      "step": 6250
    },
    {
      "epoch": 0.2269431554524362,
      "grad_norm": 0.0,
      "learning_rate": 3.452261306532664e-05,
      "loss": 0.7818,
      "step": 6260
    },
    {
      "epoch": 0.22730568445475638,
      "grad_norm": 0.0,
      "learning_rate": 3.449748743718593e-05,
      "loss": 0.2599,
      "step": 6270
    },
    {
      "epoch": 0.22766821345707658,
      "grad_norm": 0.0,
      "learning_rate": 3.4472361809045226e-05,
      "loss": 0.3718,
      "step": 6280
    },
    {
      "epoch": 0.22803074245939675,
      "grad_norm": 6.671314653723385,
      "learning_rate": 3.444723618090452e-05,
      "loss": 0.3862,
      "step": 6290
    },
    {
      "epoch": 0.22839327146171692,
      "grad_norm": 21.728962161844255,
      "learning_rate": 3.442211055276382e-05,
      "loss": 0.7788,
      "step": 6300
    },
    {
      "epoch": 0.22875580046403712,
      "grad_norm": 0.0,
      "learning_rate": 3.4396984924623116e-05,
      "loss": 0.1149,
      "step": 6310
    },
    {
      "epoch": 0.2291183294663573,
      "grad_norm": 0.0,
      "learning_rate": 3.437185929648241e-05,
      "loss": 0.2094,
      "step": 6320
    },
    {
      "epoch": 0.2294808584686775,
      "grad_norm": 0.0,
      "learning_rate": 3.4346733668341716e-05,
      "loss": 0.5026,
      "step": 6330
    },
    {
      "epoch": 0.22984338747099767,
      "grad_norm": 27.407788850041104,
      "learning_rate": 3.4321608040201006e-05,
      "loss": 0.463,
      "step": 6340
    },
    {
      "epoch": 0.23020591647331787,
      "grad_norm": 55.51877145952529,
      "learning_rate": 3.42964824120603e-05,
      "loss": 0.7474,
      "step": 6350
    },
    {
      "epoch": 0.23056844547563804,
      "grad_norm": 0.0,
      "learning_rate": 3.42713567839196e-05,
      "loss": 0.3101,
      "step": 6360
    },
    {
      "epoch": 0.23093097447795824,
      "grad_norm": 0.0,
      "learning_rate": 3.4246231155778896e-05,
      "loss": 1.1379,
      "step": 6370
    },
    {
      "epoch": 0.2312935034802784,
      "grad_norm": 1.3695214975709435,
      "learning_rate": 3.422110552763819e-05,
      "loss": 0.3521,
      "step": 6380
    },
    {
      "epoch": 0.2316560324825986,
      "grad_norm": 19.18160791047638,
      "learning_rate": 3.419597989949749e-05,
      "loss": 0.685,
      "step": 6390
    },
    {
      "epoch": 0.23201856148491878,
      "grad_norm": 0.0,
      "learning_rate": 3.4170854271356785e-05,
      "loss": 0.2801,
      "step": 6400
    },
    {
      "epoch": 0.23238109048723898,
      "grad_norm": 0.43867068676944726,
      "learning_rate": 3.414572864321608e-05,
      "loss": 0.6708,
      "step": 6410
    },
    {
      "epoch": 0.23274361948955916,
      "grad_norm": 13.38084041675967,
      "learning_rate": 3.412060301507538e-05,
      "loss": 0.6154,
      "step": 6420
    },
    {
      "epoch": 0.23310614849187936,
      "grad_norm": 0.0,
      "learning_rate": 3.4095477386934675e-05,
      "loss": 0.0128,
      "step": 6430
    },
    {
      "epoch": 0.23346867749419953,
      "grad_norm": 22.19086269632236,
      "learning_rate": 3.407035175879397e-05,
      "loss": 1.0827,
      "step": 6440
    },
    {
      "epoch": 0.23383120649651973,
      "grad_norm": 0.0,
      "learning_rate": 3.404522613065327e-05,
      "loss": 0.3251,
      "step": 6450
    },
    {
      "epoch": 0.2341937354988399,
      "grad_norm": 0.0,
      "learning_rate": 3.4020100502512565e-05,
      "loss": 0.2854,
      "step": 6460
    },
    {
      "epoch": 0.2345562645011601,
      "grad_norm": 0.0,
      "learning_rate": 3.399497487437186e-05,
      "loss": 0.7353,
      "step": 6470
    },
    {
      "epoch": 0.23491879350348027,
      "grad_norm": 4.791589266386874,
      "learning_rate": 3.396984924623116e-05,
      "loss": 0.0766,
      "step": 6480
    },
    {
      "epoch": 0.23528132250580047,
      "grad_norm": 0.0,
      "learning_rate": 3.394472361809045e-05,
      "loss": 0.604,
      "step": 6490
    },
    {
      "epoch": 0.23564385150812064,
      "grad_norm": 0.0,
      "learning_rate": 3.391959798994975e-05,
      "loss": 0.7265,
      "step": 6500
    },
    {
      "epoch": 0.23564385150812064,
      "eval_loss": NaN,
      "eval_runtime": 67.2203,
      "eval_samples_per_second": 9.476,
      "eval_steps_per_second": 1.592,
      "step": 6500
    },
    {
      "epoch": 0.23600638051044084,
      "grad_norm": 6.337231523895207,
      "learning_rate": 3.389447236180905e-05,
      "loss": 0.4186,
      "step": 6510
    },
    {
      "epoch": 0.23636890951276102,
      "grad_norm": 17.18265112710665,
      "learning_rate": 3.3869346733668345e-05,
      "loss": 0.3213,
      "step": 6520
    },
    {
      "epoch": 0.23673143851508122,
      "grad_norm": 0.0,
      "learning_rate": 3.384422110552764e-05,
      "loss": 0.1114,
      "step": 6530
    },
    {
      "epoch": 0.2370939675174014,
      "grad_norm": 0.0,
      "learning_rate": 3.381909547738694e-05,
      "loss": 0.2414,
      "step": 6540
    },
    {
      "epoch": 0.2374564965197216,
      "grad_norm": 0.0,
      "learning_rate": 3.3793969849246235e-05,
      "loss": 0.6232,
      "step": 6550
    },
    {
      "epoch": 0.23781902552204176,
      "grad_norm": 0.0,
      "learning_rate": 3.3768844221105525e-05,
      "loss": 0.5559,
      "step": 6560
    },
    {
      "epoch": 0.23818155452436196,
      "grad_norm": 0.0,
      "learning_rate": 3.374371859296482e-05,
      "loss": 0.2506,
      "step": 6570
    },
    {
      "epoch": 0.23854408352668213,
      "grad_norm": 0.22879657428869926,
      "learning_rate": 3.371859296482412e-05,
      "loss": 0.0836,
      "step": 6580
    },
    {
      "epoch": 0.23890661252900233,
      "grad_norm": 0.0,
      "learning_rate": 3.369346733668342e-05,
      "loss": 0.0045,
      "step": 6590
    },
    {
      "epoch": 0.2392691415313225,
      "grad_norm": 0.10188507242375035,
      "learning_rate": 3.366834170854272e-05,
      "loss": 0.099,
      "step": 6600
    },
    {
      "epoch": 0.2396316705336427,
      "grad_norm": 0.8252039079387767,
      "learning_rate": 3.3643216080402014e-05,
      "loss": 0.3398,
      "step": 6610
    },
    {
      "epoch": 0.23999419953596288,
      "grad_norm": 50.22065082743602,
      "learning_rate": 3.361809045226131e-05,
      "loss": 0.1026,
      "step": 6620
    },
    {
      "epoch": 0.24035672853828308,
      "grad_norm": 0.11084333910031083,
      "learning_rate": 3.35929648241206e-05,
      "loss": 0.4687,
      "step": 6630
    },
    {
      "epoch": 0.24071925754060325,
      "grad_norm": 0.8805970607031867,
      "learning_rate": 3.35678391959799e-05,
      "loss": 0.0638,
      "step": 6640
    },
    {
      "epoch": 0.24108178654292342,
      "grad_norm": 0.0,
      "learning_rate": 3.3542713567839194e-05,
      "loss": 0.526,
      "step": 6650
    },
    {
      "epoch": 0.24144431554524362,
      "grad_norm": 0.0,
      "learning_rate": 3.351758793969849e-05,
      "loss": 0.4521,
      "step": 6660
    },
    {
      "epoch": 0.2418068445475638,
      "grad_norm": 0.0,
      "learning_rate": 3.3492462311557794e-05,
      "loss": 2.5715,
      "step": 6670
    },
    {
      "epoch": 0.242169373549884,
      "grad_norm": 0.0,
      "learning_rate": 3.346733668341709e-05,
      "loss": 0.2009,
      "step": 6680
    },
    {
      "epoch": 0.24253190255220416,
      "grad_norm": 0.0,
      "learning_rate": 3.344221105527639e-05,
      "loss": 0.0,
      "step": 6690
    },
    {
      "epoch": 0.24289443155452436,
      "grad_norm": 0.0,
      "learning_rate": 3.341708542713568e-05,
      "loss": 0.5741,
      "step": 6700
    },
    {
      "epoch": 0.24325696055684454,
      "grad_norm": 0.0,
      "learning_rate": 3.3391959798994974e-05,
      "loss": 0.0944,
      "step": 6710
    },
    {
      "epoch": 0.24361948955916474,
      "grad_norm": 0.0,
      "learning_rate": 3.336683417085427e-05,
      "loss": 0.1918,
      "step": 6720
    },
    {
      "epoch": 0.2439820185614849,
      "grad_norm": 9.24220772464503,
      "learning_rate": 3.334170854271357e-05,
      "loss": 0.4297,
      "step": 6730
    },
    {
      "epoch": 0.2443445475638051,
      "grad_norm": 25.63227316752018,
      "learning_rate": 3.3316582914572864e-05,
      "loss": 0.8581,
      "step": 6740
    },
    {
      "epoch": 0.24470707656612528,
      "grad_norm": 0.0,
      "learning_rate": 3.329145728643217e-05,
      "loss": 0.0111,
      "step": 6750
    },
    {
      "epoch": 0.24506960556844548,
      "grad_norm": 0.0,
      "learning_rate": 3.3266331658291464e-05,
      "loss": 0.0461,
      "step": 6760
    },
    {
      "epoch": 0.24543213457076565,
      "grad_norm": 0.0,
      "learning_rate": 3.3241206030150754e-05,
      "loss": 0.5537,
      "step": 6770
    },
    {
      "epoch": 0.24579466357308585,
      "grad_norm": 0.0,
      "learning_rate": 3.321608040201005e-05,
      "loss": 0.4912,
      "step": 6780
    },
    {
      "epoch": 0.24615719257540603,
      "grad_norm": 0.0,
      "learning_rate": 3.319095477386935e-05,
      "loss": 0.5571,
      "step": 6790
    },
    {
      "epoch": 0.24651972157772623,
      "grad_norm": 0.0,
      "learning_rate": 3.3165829145728643e-05,
      "loss": 0.8051,
      "step": 6800
    },
    {
      "epoch": 0.2468822505800464,
      "grad_norm": 0.0,
      "learning_rate": 3.314070351758794e-05,
      "loss": 0.1545,
      "step": 6810
    },
    {
      "epoch": 0.2472447795823666,
      "grad_norm": 0.10578229885342019,
      "learning_rate": 3.311557788944724e-05,
      "loss": 0.0121,
      "step": 6820
    },
    {
      "epoch": 0.24760730858468677,
      "grad_norm": 0.01912903212636756,
      "learning_rate": 3.309045226130653e-05,
      "loss": 0.5011,
      "step": 6830
    },
    {
      "epoch": 0.24796983758700697,
      "grad_norm": 0.0,
      "learning_rate": 3.306532663316583e-05,
      "loss": 0.3869,
      "step": 6840
    },
    {
      "epoch": 0.24833236658932714,
      "grad_norm": 62.24950779486634,
      "learning_rate": 3.3040201005025127e-05,
      "loss": 0.8364,
      "step": 6850
    },
    {
      "epoch": 0.24869489559164734,
      "grad_norm": 19.356822685364875,
      "learning_rate": 3.301507537688442e-05,
      "loss": 0.6611,
      "step": 6860
    },
    {
      "epoch": 0.2490574245939675,
      "grad_norm": 0.0,
      "learning_rate": 3.298994974874372e-05,
      "loss": 0.3424,
      "step": 6870
    },
    {
      "epoch": 0.2494199535962877,
      "grad_norm": 0.0,
      "learning_rate": 3.2964824120603016e-05,
      "loss": 0.7552,
      "step": 6880
    },
    {
      "epoch": 0.24978248259860789,
      "grad_norm": 0.0,
      "learning_rate": 3.293969849246231e-05,
      "loss": 0.4601,
      "step": 6890
    },
    {
      "epoch": 0.25014501160092806,
      "grad_norm": 10.348119636778938,
      "learning_rate": 3.291457286432161e-05,
      "loss": 0.3292,
      "step": 6900
    },
    {
      "epoch": 0.25050754060324826,
      "grad_norm": 0.0,
      "learning_rate": 3.2889447236180906e-05,
      "loss": 0.4671,
      "step": 6910
    },
    {
      "epoch": 0.25087006960556846,
      "grad_norm": 0.0,
      "learning_rate": 3.28643216080402e-05,
      "loss": 0.4782,
      "step": 6920
    },
    {
      "epoch": 0.25123259860788866,
      "grad_norm": 0.0,
      "learning_rate": 3.28391959798995e-05,
      "loss": 0.4565,
      "step": 6930
    },
    {
      "epoch": 0.2515951276102088,
      "grad_norm": 0.0,
      "learning_rate": 3.2814070351758796e-05,
      "loss": 0.0,
      "step": 6940
    },
    {
      "epoch": 0.251957656612529,
      "grad_norm": 0.0,
      "learning_rate": 3.278894472361809e-05,
      "loss": 0.4231,
      "step": 6950
    },
    {
      "epoch": 0.2523201856148492,
      "grad_norm": 0.0,
      "learning_rate": 3.276381909547739e-05,
      "loss": 0.0,
      "step": 6960
    },
    {
      "epoch": 0.25268271461716935,
      "grad_norm": 19.15393829087849,
      "learning_rate": 3.2738693467336686e-05,
      "loss": 0.3873,
      "step": 6970
    },
    {
      "epoch": 0.25304524361948955,
      "grad_norm": 0.0,
      "learning_rate": 3.271356783919598e-05,
      "loss": 2.1142,
      "step": 6980
    },
    {
      "epoch": 0.25340777262180975,
      "grad_norm": 0.0,
      "learning_rate": 3.268844221105527e-05,
      "loss": 0.6321,
      "step": 6990
    },
    {
      "epoch": 0.25377030162412995,
      "grad_norm": 0.10276857756806869,
      "learning_rate": 3.2663316582914576e-05,
      "loss": 0.1335,
      "step": 7000
    },
    {
      "epoch": 0.25377030162412995,
      "eval_loss": NaN,
      "eval_runtime": 67.0476,
      "eval_samples_per_second": 9.501,
      "eval_steps_per_second": 1.596,
      "step": 7000
    },
    {
      "epoch": 0.2541328306264501,
      "grad_norm": 0.0,
      "learning_rate": 3.263819095477387e-05,
      "loss": 0.6511,
      "step": 7010
    },
    {
      "epoch": 0.2544953596287703,
      "grad_norm": 0.0,
      "learning_rate": 3.261306532663317e-05,
      "loss": 0.1527,
      "step": 7020
    },
    {
      "epoch": 0.2548578886310905,
      "grad_norm": 0.0,
      "learning_rate": 3.2587939698492466e-05,
      "loss": 0.0,
      "step": 7030
    },
    {
      "epoch": 0.2552204176334107,
      "grad_norm": 0.0,
      "learning_rate": 3.256281407035176e-05,
      "loss": 0.3776,
      "step": 7040
    },
    {
      "epoch": 0.25558294663573083,
      "grad_norm": 31.843080103662732,
      "learning_rate": 3.253768844221106e-05,
      "loss": 0.5129,
      "step": 7050
    },
    {
      "epoch": 0.25594547563805103,
      "grad_norm": 6.906312415760095,
      "learning_rate": 3.251256281407035e-05,
      "loss": 0.4933,
      "step": 7060
    },
    {
      "epoch": 0.25630800464037123,
      "grad_norm": 0.0,
      "learning_rate": 3.2487437185929645e-05,
      "loss": 0.1495,
      "step": 7070
    },
    {
      "epoch": 0.25667053364269143,
      "grad_norm": 0.0,
      "learning_rate": 3.246231155778894e-05,
      "loss": 0.198,
      "step": 7080
    },
    {
      "epoch": 0.2570330626450116,
      "grad_norm": 0.0,
      "learning_rate": 3.2437185929648245e-05,
      "loss": 0.0008,
      "step": 7090
    },
    {
      "epoch": 0.2573955916473318,
      "grad_norm": 0.0,
      "learning_rate": 3.241206030150754e-05,
      "loss": 0.2356,
      "step": 7100
    },
    {
      "epoch": 0.257758120649652,
      "grad_norm": 9.21154669250836,
      "learning_rate": 3.238693467336684e-05,
      "loss": 0.9751,
      "step": 7110
    },
    {
      "epoch": 0.2581206496519722,
      "grad_norm": 0.0,
      "learning_rate": 3.2361809045226135e-05,
      "loss": 0.191,
      "step": 7120
    },
    {
      "epoch": 0.2584831786542923,
      "grad_norm": 0.0,
      "learning_rate": 3.2336683417085425e-05,
      "loss": 1.4454,
      "step": 7130
    },
    {
      "epoch": 0.2588457076566125,
      "grad_norm": 0.0,
      "learning_rate": 3.231155778894472e-05,
      "loss": 0.0584,
      "step": 7140
    },
    {
      "epoch": 0.2592082366589327,
      "grad_norm": 0.0,
      "learning_rate": 3.228643216080402e-05,
      "loss": 0.5047,
      "step": 7150
    },
    {
      "epoch": 0.2595707656612529,
      "grad_norm": 0.0,
      "learning_rate": 3.2261306532663315e-05,
      "loss": 0.0101,
      "step": 7160
    },
    {
      "epoch": 0.25993329466357307,
      "grad_norm": 8.793391295100543,
      "learning_rate": 3.223618090452262e-05,
      "loss": 0.1232,
      "step": 7170
    },
    {
      "epoch": 0.26029582366589327,
      "grad_norm": 0.0,
      "learning_rate": 3.2211055276381915e-05,
      "loss": 0.0307,
      "step": 7180
    },
    {
      "epoch": 0.26065835266821347,
      "grad_norm": 15.784651648393536,
      "learning_rate": 3.218592964824121e-05,
      "loss": 0.1299,
      "step": 7190
    },
    {
      "epoch": 0.26102088167053367,
      "grad_norm": 14.847148048557381,
      "learning_rate": 3.21608040201005e-05,
      "loss": 0.298,
      "step": 7200
    },
    {
      "epoch": 0.2613834106728538,
      "grad_norm": 33.599303683377315,
      "learning_rate": 3.21356783919598e-05,
      "loss": 0.3083,
      "step": 7210
    },
    {
      "epoch": 0.261745939675174,
      "grad_norm": 0.0,
      "learning_rate": 3.2110552763819095e-05,
      "loss": 0.0469,
      "step": 7220
    },
    {
      "epoch": 0.2621084686774942,
      "grad_norm": 0.0,
      "learning_rate": 3.208542713567839e-05,
      "loss": 0.1972,
      "step": 7230
    },
    {
      "epoch": 0.2624709976798144,
      "grad_norm": 8.08071332596605,
      "learning_rate": 3.206030150753769e-05,
      "loss": 0.734,
      "step": 7240
    },
    {
      "epoch": 0.26283352668213456,
      "grad_norm": 0.0,
      "learning_rate": 3.203517587939699e-05,
      "loss": 0.0031,
      "step": 7250
    },
    {
      "epoch": 0.26319605568445475,
      "grad_norm": 0.0,
      "learning_rate": 3.201005025125629e-05,
      "loss": 0.8745,
      "step": 7260
    },
    {
      "epoch": 0.26355858468677495,
      "grad_norm": 0.0,
      "learning_rate": 3.198492462311558e-05,
      "loss": 1.364,
      "step": 7270
    },
    {
      "epoch": 0.26392111368909515,
      "grad_norm": 56.8836446040292,
      "learning_rate": 3.1959798994974875e-05,
      "loss": 0.0751,
      "step": 7280
    },
    {
      "epoch": 0.2642836426914153,
      "grad_norm": 0.0,
      "learning_rate": 3.193467336683417e-05,
      "loss": 0.1454,
      "step": 7290
    },
    {
      "epoch": 0.2646461716937355,
      "grad_norm": 5.381961306747217,
      "learning_rate": 3.190954773869347e-05,
      "loss": 0.2434,
      "step": 7300
    },
    {
      "epoch": 0.2650087006960557,
      "grad_norm": 0.0,
      "learning_rate": 3.1884422110552764e-05,
      "loss": 0.1156,
      "step": 7310
    },
    {
      "epoch": 0.26537122969837584,
      "grad_norm": 0.7898003555889204,
      "learning_rate": 3.185929648241206e-05,
      "loss": 1.0573,
      "step": 7320
    },
    {
      "epoch": 0.26573375870069604,
      "grad_norm": 0.0,
      "learning_rate": 3.183417085427136e-05,
      "loss": 0.4715,
      "step": 7330
    },
    {
      "epoch": 0.26609628770301624,
      "grad_norm": 0.0,
      "learning_rate": 3.1809045226130654e-05,
      "loss": 0.3279,
      "step": 7340
    },
    {
      "epoch": 0.26645881670533644,
      "grad_norm": 0.0,
      "learning_rate": 3.178391959798995e-05,
      "loss": 0.0022,
      "step": 7350
    },
    {
      "epoch": 0.2668213457076566,
      "grad_norm": 0.0,
      "learning_rate": 3.175879396984925e-05,
      "loss": 0.1638,
      "step": 7360
    },
    {
      "epoch": 0.2671838747099768,
      "grad_norm": 0.0,
      "learning_rate": 3.1733668341708544e-05,
      "loss": 0.1695,
      "step": 7370
    },
    {
      "epoch": 0.267546403712297,
      "grad_norm": 0.0,
      "learning_rate": 3.170854271356784e-05,
      "loss": 0.4607,
      "step": 7380
    },
    {
      "epoch": 0.2679089327146172,
      "grad_norm": 0.0,
      "learning_rate": 3.168341708542714e-05,
      "loss": 0.5186,
      "step": 7390
    },
    {
      "epoch": 0.26827146171693733,
      "grad_norm": 0.0,
      "learning_rate": 3.1658291457286434e-05,
      "loss": 0.3673,
      "step": 7400
    },
    {
      "epoch": 0.26863399071925753,
      "grad_norm": 0.0,
      "learning_rate": 3.163316582914573e-05,
      "loss": 0.0514,
      "step": 7410
    },
    {
      "epoch": 0.26899651972157773,
      "grad_norm": 27.29506827163334,
      "learning_rate": 3.160804020100503e-05,
      "loss": 1.2014,
      "step": 7420
    },
    {
      "epoch": 0.26935904872389793,
      "grad_norm": 0.0,
      "learning_rate": 3.1582914572864324e-05,
      "loss": 0.6942,
      "step": 7430
    },
    {
      "epoch": 0.2697215777262181,
      "grad_norm": 0.0,
      "learning_rate": 3.155778894472362e-05,
      "loss": 0.4378,
      "step": 7440
    },
    {
      "epoch": 0.2700841067285383,
      "grad_norm": 4.991118362872897,
      "learning_rate": 3.153266331658292e-05,
      "loss": 0.5298,
      "step": 7450
    },
    {
      "epoch": 0.2704466357308585,
      "grad_norm": 0.0,
      "learning_rate": 3.1507537688442214e-05,
      "loss": 0.0043,
      "step": 7460
    },
    {
      "epoch": 0.2708091647331787,
      "grad_norm": 9.218365573949672,
      "learning_rate": 3.148241206030151e-05,
      "loss": 0.1267,
      "step": 7470
    },
    {
      "epoch": 0.2711716937354988,
      "grad_norm": 0.0,
      "learning_rate": 3.145728643216081e-05,
      "loss": 0.9551,
      "step": 7480
    },
    {
      "epoch": 0.271534222737819,
      "grad_norm": 0.0,
      "learning_rate": 3.14321608040201e-05,
      "loss": 0.0,
      "step": 7490
    },
    {
      "epoch": 0.2718967517401392,
      "grad_norm": 40.90433562413112,
      "learning_rate": 3.14070351758794e-05,
      "loss": 1.1275,
      "step": 7500
    },
    {
      "epoch": 0.2718967517401392,
      "eval_loss": NaN,
      "eval_runtime": 87.0505,
      "eval_samples_per_second": 7.318,
      "eval_steps_per_second": 1.229,
      "step": 7500
    },
    {
      "epoch": 0.2722592807424594,
      "grad_norm": 0.0,
      "learning_rate": 3.13819095477387e-05,
      "loss": 0.0161,
      "step": 7510
    },
    {
      "epoch": 0.27262180974477956,
      "grad_norm": 0.07751740578380426,
      "learning_rate": 3.1356783919597993e-05,
      "loss": 0.8341,
      "step": 7520
    },
    {
      "epoch": 0.27298433874709976,
      "grad_norm": 0.0,
      "learning_rate": 3.133165829145729e-05,
      "loss": 1.1425,
      "step": 7530
    },
    {
      "epoch": 0.27334686774941996,
      "grad_norm": 0.0,
      "learning_rate": 3.130653266331659e-05,
      "loss": 0.0926,
      "step": 7540
    },
    {
      "epoch": 0.27370939675174016,
      "grad_norm": 9.466053191531428,
      "learning_rate": 3.128140703517588e-05,
      "loss": 0.6257,
      "step": 7550
    },
    {
      "epoch": 0.2740719257540603,
      "grad_norm": 0.0,
      "learning_rate": 3.125628140703517e-05,
      "loss": 0.4762,
      "step": 7560
    },
    {
      "epoch": 0.2744344547563805,
      "grad_norm": 0.0,
      "learning_rate": 3.123115577889447e-05,
      "loss": 0.1161,
      "step": 7570
    },
    {
      "epoch": 0.2747969837587007,
      "grad_norm": 0.0,
      "learning_rate": 3.1206030150753766e-05,
      "loss": 0.6375,
      "step": 7580
    },
    {
      "epoch": 0.2751595127610209,
      "grad_norm": 0.0,
      "learning_rate": 3.118090452261307e-05,
      "loss": 0.2217,
      "step": 7590
    },
    {
      "epoch": 0.27552204176334105,
      "grad_norm": 11.87368220998157,
      "learning_rate": 3.1155778894472366e-05,
      "loss": 0.4376,
      "step": 7600
    },
    {
      "epoch": 0.27588457076566125,
      "grad_norm": 0.0,
      "learning_rate": 3.113065326633166e-05,
      "loss": 0.5283,
      "step": 7610
    },
    {
      "epoch": 0.27624709976798145,
      "grad_norm": 0.0,
      "learning_rate": 3.110552763819096e-05,
      "loss": 0.029,
      "step": 7620
    },
    {
      "epoch": 0.2766096287703016,
      "grad_norm": 0.0,
      "learning_rate": 3.108040201005025e-05,
      "loss": 0.4711,
      "step": 7630
    },
    {
      "epoch": 0.2769721577726218,
      "grad_norm": 0.0,
      "learning_rate": 3.1055276381909546e-05,
      "loss": 0.2443,
      "step": 7640
    },
    {
      "epoch": 0.277334686774942,
      "grad_norm": 0.0,
      "learning_rate": 3.103015075376884e-05,
      "loss": 0.4203,
      "step": 7650
    },
    {
      "epoch": 0.2776972157772622,
      "grad_norm": 1.8969796945252313,
      "learning_rate": 3.100502512562814e-05,
      "loss": 0.0086,
      "step": 7660
    },
    {
      "epoch": 0.27805974477958234,
      "grad_norm": 0.0,
      "learning_rate": 3.097989949748744e-05,
      "loss": 0.4093,
      "step": 7670
    },
    {
      "epoch": 0.27842227378190254,
      "grad_norm": 0.0,
      "learning_rate": 3.095477386934674e-05,
      "loss": 0.4048,
      "step": 7680
    },
    {
      "epoch": 0.27878480278422274,
      "grad_norm": 3.9230093360418334,
      "learning_rate": 3.0929648241206036e-05,
      "loss": 0.0534,
      "step": 7690
    },
    {
      "epoch": 0.27914733178654294,
      "grad_norm": 0.0,
      "learning_rate": 3.0904522613065326e-05,
      "loss": 0.1385,
      "step": 7700
    },
    {
      "epoch": 0.2795098607888631,
      "grad_norm": 4.42322403781132,
      "learning_rate": 3.087939698492462e-05,
      "loss": 1.783,
      "step": 7710
    },
    {
      "epoch": 0.2798723897911833,
      "grad_norm": 0.7237488194194118,
      "learning_rate": 3.085427135678392e-05,
      "loss": 0.3099,
      "step": 7720
    },
    {
      "epoch": 0.2802349187935035,
      "grad_norm": 0.0,
      "learning_rate": 3.0829145728643216e-05,
      "loss": 0.0811,
      "step": 7730
    },
    {
      "epoch": 0.2805974477958237,
      "grad_norm": 0.0,
      "learning_rate": 3.080402010050251e-05,
      "loss": 0.0084,
      "step": 7740
    },
    {
      "epoch": 0.28095997679814383,
      "grad_norm": 29.92588807129153,
      "learning_rate": 3.077889447236181e-05,
      "loss": 0.6421,
      "step": 7750
    },
    {
      "epoch": 0.28132250580046403,
      "grad_norm": 0.0,
      "learning_rate": 3.075376884422111e-05,
      "loss": 0.0186,
      "step": 7760
    },
    {
      "epoch": 0.28168503480278423,
      "grad_norm": 0.0,
      "learning_rate": 3.07286432160804e-05,
      "loss": 0.5059,
      "step": 7770
    },
    {
      "epoch": 0.28204756380510443,
      "grad_norm": 0.0,
      "learning_rate": 3.07035175879397e-05,
      "loss": 0.6923,
      "step": 7780
    },
    {
      "epoch": 0.2824100928074246,
      "grad_norm": 0.46145639469379596,
      "learning_rate": 3.0678391959798995e-05,
      "loss": 0.2643,
      "step": 7790
    },
    {
      "epoch": 0.2827726218097448,
      "grad_norm": 0.0,
      "learning_rate": 3.065326633165829e-05,
      "loss": 0.2,
      "step": 7800
    },
    {
      "epoch": 0.283135150812065,
      "grad_norm": 0.4552126182278829,
      "learning_rate": 3.062814070351759e-05,
      "loss": 0.261,
      "step": 7810
    },
    {
      "epoch": 0.2834976798143852,
      "grad_norm": 0.0,
      "learning_rate": 3.0603015075376885e-05,
      "loss": 1.0854,
      "step": 7820
    },
    {
      "epoch": 0.2838602088167053,
      "grad_norm": 0.0,
      "learning_rate": 3.057788944723618e-05,
      "loss": 0.2794,
      "step": 7830
    },
    {
      "epoch": 0.2842227378190255,
      "grad_norm": 0.0,
      "learning_rate": 3.055276381909548e-05,
      "loss": 0.0116,
      "step": 7840
    },
    {
      "epoch": 0.2845852668213457,
      "grad_norm": 9.493830635175378,
      "learning_rate": 3.0527638190954775e-05,
      "loss": 0.3875,
      "step": 7850
    },
    {
      "epoch": 0.2849477958236659,
      "grad_norm": 0.0,
      "learning_rate": 3.0502512562814072e-05,
      "loss": 0.0731,
      "step": 7860
    },
    {
      "epoch": 0.28531032482598606,
      "grad_norm": 27.68057391679734,
      "learning_rate": 3.047738693467337e-05,
      "loss": 0.3632,
      "step": 7870
    },
    {
      "epoch": 0.28567285382830626,
      "grad_norm": 0.0,
      "learning_rate": 3.0452261306532665e-05,
      "loss": 0.6653,
      "step": 7880
    },
    {
      "epoch": 0.28603538283062646,
      "grad_norm": 0.0,
      "learning_rate": 3.042713567839196e-05,
      "loss": 0.007,
      "step": 7890
    },
    {
      "epoch": 0.28639791183294666,
      "grad_norm": 0.0,
      "learning_rate": 3.0402010050251255e-05,
      "loss": 0.5304,
      "step": 7900
    },
    {
      "epoch": 0.2867604408352668,
      "grad_norm": 0.0,
      "learning_rate": 3.037688442211055e-05,
      "loss": 0.3056,
      "step": 7910
    },
    {
      "epoch": 0.287122969837587,
      "grad_norm": 0.0,
      "learning_rate": 3.0351758793969855e-05,
      "loss": 0.2194,
      "step": 7920
    },
    {
      "epoch": 0.2874854988399072,
      "grad_norm": 0.0,
      "learning_rate": 3.0326633165829148e-05,
      "loss": 0.2504,
      "step": 7930
    },
    {
      "epoch": 0.2878480278422274,
      "grad_norm": 1.6141025032337428,
      "learning_rate": 3.0301507537688445e-05,
      "loss": 0.431,
      "step": 7940
    },
    {
      "epoch": 0.28821055684454755,
      "grad_norm": 0.0,
      "learning_rate": 3.027638190954774e-05,
      "loss": 0.3959,
      "step": 7950
    },
    {
      "epoch": 0.28857308584686775,
      "grad_norm": 0.0,
      "learning_rate": 3.0251256281407038e-05,
      "loss": 0.1662,
      "step": 7960
    },
    {
      "epoch": 0.28893561484918795,
      "grad_norm": 9.340337940449311,
      "learning_rate": 3.022613065326633e-05,
      "loss": 0.3535,
      "step": 7970
    },
    {
      "epoch": 0.2892981438515081,
      "grad_norm": 0.0,
      "learning_rate": 3.0201005025125628e-05,
      "loss": 0.1213,
      "step": 7980
    },
    {
      "epoch": 0.2896606728538283,
      "grad_norm": 0.0,
      "learning_rate": 3.0175879396984924e-05,
      "loss": 1.0269,
      "step": 7990
    },
    {
      "epoch": 0.2900232018561485,
      "grad_norm": 0.0,
      "learning_rate": 3.015075376884422e-05,
      "loss": 0.0228,
      "step": 8000
    },
    {
      "epoch": 0.2900232018561485,
      "eval_loss": NaN,
      "eval_runtime": 83.156,
      "eval_samples_per_second": 7.66,
      "eval_steps_per_second": 1.287,
      "step": 8000
    },
    {
      "epoch": 0.2903857308584687,
      "grad_norm": 0.0,
      "learning_rate": 3.012562814070352e-05,
      "loss": 0.7279,
      "step": 8010
    },
    {
      "epoch": 0.29074825986078884,
      "grad_norm": 0.0,
      "learning_rate": 3.0100502512562818e-05,
      "loss": 0.7488,
      "step": 8020
    },
    {
      "epoch": 0.29111078886310904,
      "grad_norm": 1.944900775526054,
      "learning_rate": 3.0075376884422114e-05,
      "loss": 1.27,
      "step": 8030
    },
    {
      "epoch": 0.29147331786542924,
      "grad_norm": 0.0,
      "learning_rate": 3.0050251256281408e-05,
      "loss": 0.2197,
      "step": 8040
    },
    {
      "epoch": 0.29183584686774944,
      "grad_norm": 0.0,
      "learning_rate": 3.0025125628140704e-05,
      "loss": 0.0435,
      "step": 8050
    },
    {
      "epoch": 0.2921983758700696,
      "grad_norm": 0.0,
      "learning_rate": 3e-05,
      "loss": 0.4948,
      "step": 8060
    },
    {
      "epoch": 0.2925609048723898,
      "grad_norm": 0.0,
      "learning_rate": 2.9974874371859297e-05,
      "loss": 0.0104,
      "step": 8070
    },
    {
      "epoch": 0.29292343387471,
      "grad_norm": 0.0,
      "learning_rate": 2.994974874371859e-05,
      "loss": 0.2626,
      "step": 8080
    },
    {
      "epoch": 0.2932859628770302,
      "grad_norm": 7.387681048090162,
      "learning_rate": 2.9924623115577894e-05,
      "loss": 0.1631,
      "step": 8090
    },
    {
      "epoch": 0.2936484918793503,
      "grad_norm": 0.0,
      "learning_rate": 2.989949748743719e-05,
      "loss": 1.1772,
      "step": 8100
    },
    {
      "epoch": 0.2940110208816705,
      "grad_norm": 0.0,
      "learning_rate": 2.9874371859296484e-05,
      "loss": 0.5574,
      "step": 8110
    },
    {
      "epoch": 0.2943735498839907,
      "grad_norm": 11.48753743129273,
      "learning_rate": 2.984924623115578e-05,
      "loss": 1.5882,
      "step": 8120
    },
    {
      "epoch": 0.2947360788863109,
      "grad_norm": 0.0,
      "learning_rate": 2.9824120603015077e-05,
      "loss": 0.3817,
      "step": 8130
    },
    {
      "epoch": 0.29509860788863107,
      "grad_norm": 0.0,
      "learning_rate": 2.9798994974874374e-05,
      "loss": 0.1869,
      "step": 8140
    },
    {
      "epoch": 0.29546113689095127,
      "grad_norm": 0.0,
      "learning_rate": 2.9773869346733667e-05,
      "loss": 0.2275,
      "step": 8150
    },
    {
      "epoch": 0.29582366589327147,
      "grad_norm": 0.0,
      "learning_rate": 2.9748743718592964e-05,
      "loss": 0.2537,
      "step": 8160
    },
    {
      "epoch": 0.29618619489559167,
      "grad_norm": 0.0,
      "learning_rate": 2.9723618090452267e-05,
      "loss": 0.1727,
      "step": 8170
    },
    {
      "epoch": 0.2965487238979118,
      "grad_norm": 119.2374944307578,
      "learning_rate": 2.969849246231156e-05,
      "loss": 0.3686,
      "step": 8180
    },
    {
      "epoch": 0.296911252900232,
      "grad_norm": 0.6766060002462617,
      "learning_rate": 2.9673366834170857e-05,
      "loss": 0.2155,
      "step": 8190
    },
    {
      "epoch": 0.2972737819025522,
      "grad_norm": 0.0,
      "learning_rate": 2.9648241206030153e-05,
      "loss": 0.5673,
      "step": 8200
    },
    {
      "epoch": 0.2976363109048724,
      "grad_norm": 0.1088420964656746,
      "learning_rate": 2.962311557788945e-05,
      "loss": 0.1453,
      "step": 8210
    },
    {
      "epoch": 0.29799883990719256,
      "grad_norm": 0.0,
      "learning_rate": 2.9597989949748743e-05,
      "loss": 1.0314,
      "step": 8220
    },
    {
      "epoch": 0.29836136890951276,
      "grad_norm": 0.0,
      "learning_rate": 2.957286432160804e-05,
      "loss": 0.9306,
      "step": 8230
    },
    {
      "epoch": 0.29872389791183296,
      "grad_norm": 0.0,
      "learning_rate": 2.9547738693467337e-05,
      "loss": 0.3126,
      "step": 8240
    },
    {
      "epoch": 0.29908642691415316,
      "grad_norm": 20.797412799441922,
      "learning_rate": 2.9522613065326633e-05,
      "loss": 0.5248,
      "step": 8250
    },
    {
      "epoch": 0.2994489559164733,
      "grad_norm": 0.0,
      "learning_rate": 2.9497487437185933e-05,
      "loss": 0.0239,
      "step": 8260
    },
    {
      "epoch": 0.2998114849187935,
      "grad_norm": 0.0,
      "learning_rate": 2.947236180904523e-05,
      "loss": 1.0735,
      "step": 8270
    },
    {
      "epoch": 0.3001740139211137,
      "grad_norm": 0.0,
      "learning_rate": 2.9447236180904526e-05,
      "loss": 0.3179,
      "step": 8280
    },
    {
      "epoch": 0.30053654292343385,
      "grad_norm": 0.0,
      "learning_rate": 2.942211055276382e-05,
      "loss": 0.5243,
      "step": 8290
    },
    {
      "epoch": 0.30089907192575405,
      "grad_norm": 0.0,
      "learning_rate": 2.9396984924623116e-05,
      "loss": 0.4004,
      "step": 8300
    },
    {
      "epoch": 0.30126160092807425,
      "grad_norm": 5.605079642690487,
      "learning_rate": 2.9371859296482413e-05,
      "loss": 0.2793,
      "step": 8310
    },
    {
      "epoch": 0.30162412993039445,
      "grad_norm": 19.9747062957522,
      "learning_rate": 2.934673366834171e-05,
      "loss": 0.4874,
      "step": 8320
    },
    {
      "epoch": 0.3019866589327146,
      "grad_norm": 0.0,
      "learning_rate": 2.9321608040201003e-05,
      "loss": 0.0,
      "step": 8330
    },
    {
      "epoch": 0.3023491879350348,
      "grad_norm": 14.980674501520545,
      "learning_rate": 2.9296482412060306e-05,
      "loss": 1.4257,
      "step": 8340
    },
    {
      "epoch": 0.302711716937355,
      "grad_norm": 0.0,
      "learning_rate": 2.9271356783919603e-05,
      "loss": 0.2286,
      "step": 8350
    },
    {
      "epoch": 0.3030742459396752,
      "grad_norm": 0.0,
      "learning_rate": 2.9246231155778896e-05,
      "loss": 0.178,
      "step": 8360
    },
    {
      "epoch": 0.30343677494199534,
      "grad_norm": 0.0,
      "learning_rate": 2.9221105527638193e-05,
      "loss": 0.1271,
      "step": 8370
    },
    {
      "epoch": 0.30379930394431554,
      "grad_norm": 0.0,
      "learning_rate": 2.919597989949749e-05,
      "loss": 0.81,
      "step": 8380
    },
    {
      "epoch": 0.30416183294663574,
      "grad_norm": 0.0,
      "learning_rate": 2.9170854271356786e-05,
      "loss": 0.1127,
      "step": 8390
    },
    {
      "epoch": 0.30452436194895594,
      "grad_norm": 0.0,
      "learning_rate": 2.914572864321608e-05,
      "loss": 1.3726,
      "step": 8400
    },
    {
      "epoch": 0.3048868909512761,
      "grad_norm": 0.0,
      "learning_rate": 2.9120603015075376e-05,
      "loss": 1.2673,
      "step": 8410
    },
    {
      "epoch": 0.3052494199535963,
      "grad_norm": 0.0,
      "learning_rate": 2.909547738693468e-05,
      "loss": 0.2276,
      "step": 8420
    },
    {
      "epoch": 0.3056119489559165,
      "grad_norm": 16.27484485183106,
      "learning_rate": 2.9070351758793972e-05,
      "loss": 0.2675,
      "step": 8430
    },
    {
      "epoch": 0.3059744779582367,
      "grad_norm": 0.0,
      "learning_rate": 2.904522613065327e-05,
      "loss": 0.0,
      "step": 8440
    },
    {
      "epoch": 0.3063370069605568,
      "grad_norm": 0.0,
      "learning_rate": 2.9020100502512566e-05,
      "loss": 0.1453,
      "step": 8450
    },
    {
      "epoch": 0.306699535962877,
      "grad_norm": 13.843635369164236,
      "learning_rate": 2.8994974874371862e-05,
      "loss": 0.1613,
      "step": 8460
    },
    {
      "epoch": 0.3070620649651972,
      "grad_norm": 2.4716732246618887,
      "learning_rate": 2.8969849246231155e-05,
      "loss": 0.245,
      "step": 8470
    },
    {
      "epoch": 0.3074245939675174,
      "grad_norm": 0.0,
      "learning_rate": 2.8944723618090452e-05,
      "loss": 0.2628,
      "step": 8480
    },
    {
      "epoch": 0.30778712296983757,
      "grad_norm": 0.0,
      "learning_rate": 2.891959798994975e-05,
      "loss": 0.4391,
      "step": 8490
    },
    {
      "epoch": 0.30814965197215777,
      "grad_norm": 0.0,
      "learning_rate": 2.8894472361809045e-05,
      "loss": 0.2247,
      "step": 8500
    },
    {
      "epoch": 0.30814965197215777,
      "eval_loss": NaN,
      "eval_runtime": 84.4215,
      "eval_samples_per_second": 7.545,
      "eval_steps_per_second": 1.267,
      "step": 8500
    },
    {
      "epoch": 0.30851218097447797,
      "grad_norm": 0.0,
      "learning_rate": 2.8869346733668345e-05,
      "loss": 0.672,
      "step": 8510
    },
    {
      "epoch": 0.30887470997679817,
      "grad_norm": 0.0,
      "learning_rate": 2.8844221105527642e-05,
      "loss": 0.5165,
      "step": 8520
    },
    {
      "epoch": 0.3092372389791183,
      "grad_norm": 0.0,
      "learning_rate": 2.881909547738694e-05,
      "loss": 0.2674,
      "step": 8530
    },
    {
      "epoch": 0.3095997679814385,
      "grad_norm": 0.0,
      "learning_rate": 2.8793969849246232e-05,
      "loss": 0.4663,
      "step": 8540
    },
    {
      "epoch": 0.3099622969837587,
      "grad_norm": 0.0,
      "learning_rate": 2.876884422110553e-05,
      "loss": 0.4208,
      "step": 8550
    },
    {
      "epoch": 0.3103248259860789,
      "grad_norm": 0.0,
      "learning_rate": 2.8743718592964825e-05,
      "loss": 0.6593,
      "step": 8560
    },
    {
      "epoch": 0.31068735498839906,
      "grad_norm": 19.953609834066523,
      "learning_rate": 2.871859296482412e-05,
      "loss": 0.3526,
      "step": 8570
    },
    {
      "epoch": 0.31104988399071926,
      "grad_norm": 18.434585806505712,
      "learning_rate": 2.8693467336683415e-05,
      "loss": 0.2703,
      "step": 8580
    },
    {
      "epoch": 0.31141241299303946,
      "grad_norm": 0.0,
      "learning_rate": 2.8668341708542718e-05,
      "loss": 0.0914,
      "step": 8590
    },
    {
      "epoch": 0.31177494199535966,
      "grad_norm": 0.0,
      "learning_rate": 2.8643216080402015e-05,
      "loss": 0.0593,
      "step": 8600
    },
    {
      "epoch": 0.3121374709976798,
      "grad_norm": 0.0,
      "learning_rate": 2.8618090452261308e-05,
      "loss": 0.1601,
      "step": 8610
    },
    {
      "epoch": 0.3125,
      "grad_norm": 0.4488260460017753,
      "learning_rate": 2.8592964824120605e-05,
      "loss": 0.0589,
      "step": 8620
    },
    {
      "epoch": 0.3128625290023202,
      "grad_norm": 0.0,
      "learning_rate": 2.85678391959799e-05,
      "loss": 0.6277,
      "step": 8630
    },
    {
      "epoch": 0.31322505800464034,
      "grad_norm": 0.0,
      "learning_rate": 2.8542713567839198e-05,
      "loss": 0.2701,
      "step": 8640
    },
    {
      "epoch": 0.31358758700696054,
      "grad_norm": 0.0,
      "learning_rate": 2.851758793969849e-05,
      "loss": 0.5236,
      "step": 8650
    },
    {
      "epoch": 0.31395011600928074,
      "grad_norm": 0.0,
      "learning_rate": 2.8492462311557788e-05,
      "loss": 0.3968,
      "step": 8660
    },
    {
      "epoch": 0.31431264501160094,
      "grad_norm": 0.0,
      "learning_rate": 2.8467336683417084e-05,
      "loss": 0.3932,
      "step": 8670
    },
    {
      "epoch": 0.3146751740139211,
      "grad_norm": 0.0,
      "learning_rate": 2.8442211055276384e-05,
      "loss": 0.3477,
      "step": 8680
    },
    {
      "epoch": 0.3150377030162413,
      "grad_norm": 1.3229171072090598,
      "learning_rate": 2.841708542713568e-05,
      "loss": 0.1234,
      "step": 8690
    },
    {
      "epoch": 0.3154002320185615,
      "grad_norm": 0.0,
      "learning_rate": 2.8391959798994978e-05,
      "loss": 0.2147,
      "step": 8700
    },
    {
      "epoch": 0.3157627610208817,
      "grad_norm": 0.0,
      "learning_rate": 2.8366834170854274e-05,
      "loss": 0.5893,
      "step": 8710
    },
    {
      "epoch": 0.31612529002320183,
      "grad_norm": 55.94488865308653,
      "learning_rate": 2.8341708542713568e-05,
      "loss": 0.2923,
      "step": 8720
    },
    {
      "epoch": 0.31648781902552203,
      "grad_norm": 0.0,
      "learning_rate": 2.8316582914572864e-05,
      "loss": 0.0432,
      "step": 8730
    },
    {
      "epoch": 0.31685034802784223,
      "grad_norm": 139.9791139554398,
      "learning_rate": 2.829145728643216e-05,
      "loss": 1.2177,
      "step": 8740
    },
    {
      "epoch": 0.31721287703016243,
      "grad_norm": 0.0,
      "learning_rate": 2.8266331658291457e-05,
      "loss": 0.3738,
      "step": 8750
    },
    {
      "epoch": 0.3175754060324826,
      "grad_norm": 0.0,
      "learning_rate": 2.8241206030150757e-05,
      "loss": 0.1514,
      "step": 8760
    },
    {
      "epoch": 0.3179379350348028,
      "grad_norm": 19.792041697378803,
      "learning_rate": 2.8216080402010054e-05,
      "loss": 0.0912,
      "step": 8770
    },
    {
      "epoch": 0.318300464037123,
      "grad_norm": 0.0,
      "learning_rate": 2.819095477386935e-05,
      "loss": 0.2471,
      "step": 8780
    },
    {
      "epoch": 0.3186629930394432,
      "grad_norm": 0.0,
      "learning_rate": 2.8165829145728644e-05,
      "loss": 0.7417,
      "step": 8790
    },
    {
      "epoch": 0.3190255220417633,
      "grad_norm": 0.0,
      "learning_rate": 2.814070351758794e-05,
      "loss": 0.1388,
      "step": 8800
    },
    {
      "epoch": 0.3193880510440835,
      "grad_norm": 0.0,
      "learning_rate": 2.8115577889447237e-05,
      "loss": 0.2602,
      "step": 8810
    },
    {
      "epoch": 0.3197505800464037,
      "grad_norm": 0.0,
      "learning_rate": 2.8090452261306534e-05,
      "loss": 0.4645,
      "step": 8820
    },
    {
      "epoch": 0.3201131090487239,
      "grad_norm": 17.344760844697905,
      "learning_rate": 2.8065326633165827e-05,
      "loss": 0.4765,
      "step": 8830
    },
    {
      "epoch": 0.32047563805104406,
      "grad_norm": 10.128138679699957,
      "learning_rate": 2.804020100502513e-05,
      "loss": 0.0642,
      "step": 8840
    },
    {
      "epoch": 0.32083816705336426,
      "grad_norm": 0.0,
      "learning_rate": 2.8015075376884427e-05,
      "loss": 0.0822,
      "step": 8850
    },
    {
      "epoch": 0.32120069605568446,
      "grad_norm": 0.0,
      "learning_rate": 2.798994974874372e-05,
      "loss": 0.0183,
      "step": 8860
    },
    {
      "epoch": 0.32156322505800466,
      "grad_norm": 0.0,
      "learning_rate": 2.7964824120603017e-05,
      "loss": 0.0159,
      "step": 8870
    },
    {
      "epoch": 0.3219257540603248,
      "grad_norm": 0.7423536014405034,
      "learning_rate": 2.7939698492462314e-05,
      "loss": 0.0091,
      "step": 8880
    },
    {
      "epoch": 0.322288283062645,
      "grad_norm": 57.30483182071124,
      "learning_rate": 2.791457286432161e-05,
      "loss": 0.483,
      "step": 8890
    },
    {
      "epoch": 0.3226508120649652,
      "grad_norm": 0.0,
      "learning_rate": 2.7889447236180903e-05,
      "loss": 0.9732,
      "step": 8900
    },
    {
      "epoch": 0.3230133410672854,
      "grad_norm": 17.516654672567157,
      "learning_rate": 2.78643216080402e-05,
      "loss": 0.8873,
      "step": 8910
    },
    {
      "epoch": 0.32337587006960555,
      "grad_norm": 0.0,
      "learning_rate": 2.7839195979899497e-05,
      "loss": 0.0586,
      "step": 8920
    },
    {
      "epoch": 0.32373839907192575,
      "grad_norm": 0.7301294283243589,
      "learning_rate": 2.7814070351758797e-05,
      "loss": 0.0221,
      "step": 8930
    },
    {
      "epoch": 0.32410092807424595,
      "grad_norm": 0.0,
      "learning_rate": 2.7788944723618093e-05,
      "loss": 0.0194,
      "step": 8940
    },
    {
      "epoch": 0.32446345707656615,
      "grad_norm": 0.0,
      "learning_rate": 2.776381909547739e-05,
      "loss": 0.3814,
      "step": 8950
    },
    {
      "epoch": 0.3248259860788863,
      "grad_norm": 0.0,
      "learning_rate": 2.7738693467336686e-05,
      "loss": 0.2357,
      "step": 8960
    },
    {
      "epoch": 0.3251885150812065,
      "grad_norm": 0.0,
      "learning_rate": 2.771356783919598e-05,
      "loss": 0.0119,
      "step": 8970
    },
    {
      "epoch": 0.3255510440835267,
      "grad_norm": 0.6931301328986685,
      "learning_rate": 2.7688442211055276e-05,
      "loss": 0.183,
      "step": 8980
    },
    {
      "epoch": 0.32591357308584684,
      "grad_norm": 0.0,
      "learning_rate": 2.7663316582914573e-05,
      "loss": 1.6151,
      "step": 8990
    },
    {
      "epoch": 0.32627610208816704,
      "grad_norm": 0.0,
      "learning_rate": 2.763819095477387e-05,
      "loss": 0.4847,
      "step": 9000
    },
    {
      "epoch": 0.32627610208816704,
      "eval_loss": NaN,
      "eval_runtime": 86.1907,
      "eval_samples_per_second": 7.391,
      "eval_steps_per_second": 1.241,
      "step": 9000
    },
    {
      "epoch": 0.32663863109048724,
      "grad_norm": 0.0,
      "learning_rate": 2.761306532663317e-05,
      "loss": 0.1315,
      "step": 9010
    },
    {
      "epoch": 0.32700116009280744,
      "grad_norm": 0.0,
      "learning_rate": 2.7587939698492466e-05,
      "loss": 0.3556,
      "step": 9020
    },
    {
      "epoch": 0.3273636890951276,
      "grad_norm": 0.010805937525580855,
      "learning_rate": 2.7562814070351763e-05,
      "loss": 0.1768,
      "step": 9030
    },
    {
      "epoch": 0.3277262180974478,
      "grad_norm": 4.599277000000053,
      "learning_rate": 2.7537688442211056e-05,
      "loss": 0.2302,
      "step": 9040
    },
    {
      "epoch": 0.328088747099768,
      "grad_norm": 0.13008754054637317,
      "learning_rate": 2.7512562814070353e-05,
      "loss": 0.0765,
      "step": 9050
    },
    {
      "epoch": 0.3284512761020882,
      "grad_norm": 0.0,
      "learning_rate": 2.748743718592965e-05,
      "loss": 1.8349,
      "step": 9060
    },
    {
      "epoch": 0.32881380510440833,
      "grad_norm": 0.0,
      "learning_rate": 2.7462311557788946e-05,
      "loss": 0.2356,
      "step": 9070
    },
    {
      "epoch": 0.32917633410672853,
      "grad_norm": 0.0,
      "learning_rate": 2.743718592964824e-05,
      "loss": 0.0008,
      "step": 9080
    },
    {
      "epoch": 0.32953886310904873,
      "grad_norm": 0.0,
      "learning_rate": 2.7412060301507543e-05,
      "loss": 0.6227,
      "step": 9090
    },
    {
      "epoch": 0.32990139211136893,
      "grad_norm": 24.854848395625577,
      "learning_rate": 2.738693467336684e-05,
      "loss": 0.8023,
      "step": 9100
    },
    {
      "epoch": 0.3302639211136891,
      "grad_norm": 6.1358104983116455,
      "learning_rate": 2.7361809045226132e-05,
      "loss": 0.084,
      "step": 9110
    },
    {
      "epoch": 0.3306264501160093,
      "grad_norm": 0.09258907973587403,
      "learning_rate": 2.733668341708543e-05,
      "loss": 0.8505,
      "step": 9120
    },
    {
      "epoch": 0.3309889791183295,
      "grad_norm": 0.0,
      "learning_rate": 2.7311557788944726e-05,
      "loss": 0.3833,
      "step": 9130
    },
    {
      "epoch": 0.3313515081206497,
      "grad_norm": 0.0,
      "learning_rate": 2.7286432160804022e-05,
      "loss": 0.8688,
      "step": 9140
    },
    {
      "epoch": 0.3317140371229698,
      "grad_norm": 41.94974526656494,
      "learning_rate": 2.7261306532663315e-05,
      "loss": 0.4946,
      "step": 9150
    },
    {
      "epoch": 0.33207656612529,
      "grad_norm": 0.0,
      "learning_rate": 2.7236180904522612e-05,
      "loss": 0.5115,
      "step": 9160
    },
    {
      "epoch": 0.3324390951276102,
      "grad_norm": 0.0,
      "learning_rate": 2.721105527638191e-05,
      "loss": 2.4855,
      "step": 9170
    },
    {
      "epoch": 0.3328016241299304,
      "grad_norm": 0.0,
      "learning_rate": 2.718592964824121e-05,
      "loss": 0.0057,
      "step": 9180
    },
    {
      "epoch": 0.33316415313225056,
      "grad_norm": 0.15039238371378055,
      "learning_rate": 2.7160804020100505e-05,
      "loss": 0.8816,
      "step": 9190
    },
    {
      "epoch": 0.33352668213457076,
      "grad_norm": 0.0,
      "learning_rate": 2.7135678391959802e-05,
      "loss": 1.5745,
      "step": 9200
    },
    {
      "epoch": 0.33388921113689096,
      "grad_norm": 0.0,
      "learning_rate": 2.71105527638191e-05,
      "loss": 0.0803,
      "step": 9210
    },
    {
      "epoch": 0.33425174013921116,
      "grad_norm": 0.0,
      "learning_rate": 2.7085427135678392e-05,
      "loss": 0.456,
      "step": 9220
    },
    {
      "epoch": 0.3346142691415313,
      "grad_norm": 0.0,
      "learning_rate": 2.706030150753769e-05,
      "loss": 0.7367,
      "step": 9230
    },
    {
      "epoch": 0.3349767981438515,
      "grad_norm": 0.9240806831167974,
      "learning_rate": 2.7035175879396985e-05,
      "loss": 0.7681,
      "step": 9240
    },
    {
      "epoch": 0.3353393271461717,
      "grad_norm": 0.0,
      "learning_rate": 2.7010050251256282e-05,
      "loss": 0.2767,
      "step": 9250
    },
    {
      "epoch": 0.3357018561484919,
      "grad_norm": 0.0,
      "learning_rate": 2.6984924623115582e-05,
      "loss": 0.0061,
      "step": 9260
    },
    {
      "epoch": 0.33606438515081205,
      "grad_norm": 65.60311018851355,
      "learning_rate": 2.695979899497488e-05,
      "loss": 0.3359,
      "step": 9270
    },
    {
      "epoch": 0.33642691415313225,
      "grad_norm": 0.0,
      "learning_rate": 2.6934673366834175e-05,
      "loss": 0.5328,
      "step": 9280
    },
    {
      "epoch": 0.33678944315545245,
      "grad_norm": 0.0,
      "learning_rate": 2.6909547738693468e-05,
      "loss": 0.3042,
      "step": 9290
    },
    {
      "epoch": 0.3371519721577726,
      "grad_norm": 14.670968089649026,
      "learning_rate": 2.6884422110552765e-05,
      "loss": 2.7315,
      "step": 9300
    },
    {
      "epoch": 0.3375145011600928,
      "grad_norm": 21.236095232472852,
      "learning_rate": 2.685929648241206e-05,
      "loss": 1.0868,
      "step": 9310
    },
    {
      "epoch": 0.337877030162413,
      "grad_norm": 21.71107876550839,
      "learning_rate": 2.6834170854271358e-05,
      "loss": 0.1276,
      "step": 9320
    },
    {
      "epoch": 0.3382395591647332,
      "grad_norm": 0.0,
      "learning_rate": 2.680904522613065e-05,
      "loss": 0.6462,
      "step": 9330
    },
    {
      "epoch": 0.33860208816705334,
      "grad_norm": 0.0,
      "learning_rate": 2.6783919597989955e-05,
      "loss": 0.0657,
      "step": 9340
    },
    {
      "epoch": 0.33896461716937354,
      "grad_norm": 0.0,
      "learning_rate": 2.6758793969849248e-05,
      "loss": 0.5032,
      "step": 9350
    },
    {
      "epoch": 0.33932714617169374,
      "grad_norm": 0.0,
      "learning_rate": 2.6733668341708545e-05,
      "loss": 0.1971,
      "step": 9360
    },
    {
      "epoch": 0.33968967517401394,
      "grad_norm": 0.0,
      "learning_rate": 2.670854271356784e-05,
      "loss": 0.4476,
      "step": 9370
    },
    {
      "epoch": 0.3400522041763341,
      "grad_norm": 0.0,
      "learning_rate": 2.6683417085427138e-05,
      "loss": 0.1329,
      "step": 9380
    },
    {
      "epoch": 0.3404147331786543,
      "grad_norm": 0.0,
      "learning_rate": 2.6658291457286434e-05,
      "loss": 0.166,
      "step": 9390
    },
    {
      "epoch": 0.3407772621809745,
      "grad_norm": 0.0,
      "learning_rate": 2.6633165829145728e-05,
      "loss": 0.1523,
      "step": 9400
    },
    {
      "epoch": 0.3411397911832947,
      "grad_norm": 0.0,
      "learning_rate": 2.6608040201005024e-05,
      "loss": 0.3273,
      "step": 9410
    },
    {
      "epoch": 0.3415023201856148,
      "grad_norm": 0.0,
      "learning_rate": 2.658291457286432e-05,
      "loss": 0.0174,
      "step": 9420
    },
    {
      "epoch": 0.341864849187935,
      "grad_norm": 1.2717307887695057,
      "learning_rate": 2.655778894472362e-05,
      "loss": 0.9362,
      "step": 9430
    },
    {
      "epoch": 0.3422273781902552,
      "grad_norm": 0.0,
      "learning_rate": 2.6532663316582917e-05,
      "loss": 0.9472,
      "step": 9440
    },
    {
      "epoch": 0.3425899071925754,
      "grad_norm": 0.0,
      "learning_rate": 2.6507537688442214e-05,
      "loss": 0.2373,
      "step": 9450
    },
    {
      "epoch": 0.34295243619489557,
      "grad_norm": 0.0,
      "learning_rate": 2.648241206030151e-05,
      "loss": 0.6838,
      "step": 9460
    },
    {
      "epoch": 0.34331496519721577,
      "grad_norm": 0.0,
      "learning_rate": 2.6457286432160804e-05,
      "loss": 0.6011,
      "step": 9470
    },
    {
      "epoch": 0.34367749419953597,
      "grad_norm": 10.901656180732823,
      "learning_rate": 2.64321608040201e-05,
      "loss": 0.4818,
      "step": 9480
    },
    {
      "epoch": 0.34404002320185617,
      "grad_norm": 0.0,
      "learning_rate": 2.6407035175879397e-05,
      "loss": 0.2606,
      "step": 9490
    },
    {
      "epoch": 0.3444025522041763,
      "grad_norm": 0.0,
      "learning_rate": 2.6381909547738694e-05,
      "loss": 0.0885,
      "step": 9500
    },
    {
      "epoch": 0.3444025522041763,
      "eval_loss": NaN,
      "eval_runtime": 76.7288,
      "eval_samples_per_second": 8.302,
      "eval_steps_per_second": 1.395,
      "step": 9500
    },
    {
      "epoch": 0.3447650812064965,
      "grad_norm": 0.0,
      "learning_rate": 2.6356783919597994e-05,
      "loss": 0.2106,
      "step": 9510
    },
    {
      "epoch": 0.3451276102088167,
      "grad_norm": 0.0,
      "learning_rate": 2.633165829145729e-05,
      "loss": 0.0236,
      "step": 9520
    },
    {
      "epoch": 0.3454901392111369,
      "grad_norm": 0.0,
      "learning_rate": 2.6306532663316587e-05,
      "loss": 0.6903,
      "step": 9530
    },
    {
      "epoch": 0.34585266821345706,
      "grad_norm": 0.0,
      "learning_rate": 2.628140703517588e-05,
      "loss": 0.0129,
      "step": 9540
    },
    {
      "epoch": 0.34621519721577726,
      "grad_norm": 2.1040113284745217,
      "learning_rate": 2.6256281407035177e-05,
      "loss": 0.5954,
      "step": 9550
    },
    {
      "epoch": 0.34657772621809746,
      "grad_norm": 0.0,
      "learning_rate": 2.6231155778894474e-05,
      "loss": 0.0212,
      "step": 9560
    },
    {
      "epoch": 0.34694025522041766,
      "grad_norm": 0.0,
      "learning_rate": 2.620603015075377e-05,
      "loss": 0.1123,
      "step": 9570
    },
    {
      "epoch": 0.3473027842227378,
      "grad_norm": 0.0,
      "learning_rate": 2.6180904522613063e-05,
      "loss": 0.0,
      "step": 9580
    },
    {
      "epoch": 0.347665313225058,
      "grad_norm": 0.0,
      "learning_rate": 2.615577889447236e-05,
      "loss": 0.5666,
      "step": 9590
    },
    {
      "epoch": 0.3480278422273782,
      "grad_norm": 0.0,
      "learning_rate": 2.613065326633166e-05,
      "loss": 0.4586,
      "step": 9600
    },
    {
      "epoch": 0.3483903712296984,
      "grad_norm": 0.0,
      "learning_rate": 2.6105527638190957e-05,
      "loss": 0.5635,
      "step": 9610
    },
    {
      "epoch": 0.34875290023201855,
      "grad_norm": 11.006209268229215,
      "learning_rate": 2.6080402010050253e-05,
      "loss": 0.3214,
      "step": 9620
    },
    {
      "epoch": 0.34911542923433875,
      "grad_norm": 0.0,
      "learning_rate": 2.605527638190955e-05,
      "loss": 0.5068,
      "step": 9630
    },
    {
      "epoch": 0.34947795823665895,
      "grad_norm": 0.0,
      "learning_rate": 2.6030150753768847e-05,
      "loss": 0.5876,
      "step": 9640
    },
    {
      "epoch": 0.3498404872389791,
      "grad_norm": 0.0,
      "learning_rate": 2.600502512562814e-05,
      "loss": 0.7009,
      "step": 9650
    },
    {
      "epoch": 0.3502030162412993,
      "grad_norm": 7.35966734092925,
      "learning_rate": 2.5979899497487436e-05,
      "loss": 0.0924,
      "step": 9660
    },
    {
      "epoch": 0.3505655452436195,
      "grad_norm": 0.0,
      "learning_rate": 2.5954773869346733e-05,
      "loss": 0.6506,
      "step": 9670
    },
    {
      "epoch": 0.3509280742459397,
      "grad_norm": 0.0,
      "learning_rate": 2.5929648241206033e-05,
      "loss": 0.5504,
      "step": 9680
    },
    {
      "epoch": 0.35129060324825984,
      "grad_norm": 0.0,
      "learning_rate": 2.590452261306533e-05,
      "loss": 0.8424,
      "step": 9690
    },
    {
      "epoch": 0.35165313225058004,
      "grad_norm": 0.0,
      "learning_rate": 2.5879396984924626e-05,
      "loss": 0.5743,
      "step": 9700
    },
    {
      "epoch": 0.35201566125290024,
      "grad_norm": 0.0,
      "learning_rate": 2.5854271356783923e-05,
      "loss": 0.4368,
      "step": 9710
    },
    {
      "epoch": 0.35237819025522044,
      "grad_norm": 0.0,
      "learning_rate": 2.5829145728643216e-05,
      "loss": 0.4863,
      "step": 9720
    },
    {
      "epoch": 0.3527407192575406,
      "grad_norm": 0.0,
      "learning_rate": 2.5804020100502513e-05,
      "loss": 0.936,
      "step": 9730
    },
    {
      "epoch": 0.3531032482598608,
      "grad_norm": 0.0,
      "learning_rate": 2.577889447236181e-05,
      "loss": 0.4185,
      "step": 9740
    },
    {
      "epoch": 0.353465777262181,
      "grad_norm": 0.0,
      "learning_rate": 2.5753768844221106e-05,
      "loss": 0.405,
      "step": 9750
    },
    {
      "epoch": 0.3538283062645012,
      "grad_norm": 0.0,
      "learning_rate": 2.5728643216080406e-05,
      "loss": 0.0873,
      "step": 9760
    },
    {
      "epoch": 0.3541908352668213,
      "grad_norm": 0.0,
      "learning_rate": 2.5703517587939703e-05,
      "loss": 0.1853,
      "step": 9770
    },
    {
      "epoch": 0.3545533642691415,
      "grad_norm": 0.0,
      "learning_rate": 2.5678391959798996e-05,
      "loss": 1.7812,
      "step": 9780
    },
    {
      "epoch": 0.3549158932714617,
      "grad_norm": 0.0,
      "learning_rate": 2.5653266331658292e-05,
      "loss": 0.1208,
      "step": 9790
    },
    {
      "epoch": 0.3552784222737819,
      "grad_norm": 0.0,
      "learning_rate": 2.562814070351759e-05,
      "loss": 0.0546,
      "step": 9800
    },
    {
      "epoch": 0.35564095127610207,
      "grad_norm": 2.8098604319654816,
      "learning_rate": 2.5603015075376886e-05,
      "loss": 0.1984,
      "step": 9810
    },
    {
      "epoch": 0.35600348027842227,
      "grad_norm": 0.0,
      "learning_rate": 2.5577889447236182e-05,
      "loss": 0.4272,
      "step": 9820
    },
    {
      "epoch": 0.35636600928074247,
      "grad_norm": 0.0,
      "learning_rate": 2.5552763819095476e-05,
      "loss": 0.4411,
      "step": 9830
    },
    {
      "epoch": 0.35672853828306267,
      "grad_norm": 0.01952468418982355,
      "learning_rate": 2.5527638190954772e-05,
      "loss": 0.8677,
      "step": 9840
    },
    {
      "epoch": 0.3570910672853828,
      "grad_norm": 0.0,
      "learning_rate": 2.5502512562814072e-05,
      "loss": 0.4935,
      "step": 9850
    },
    {
      "epoch": 0.357453596287703,
      "grad_norm": 59.436175310553715,
      "learning_rate": 2.547738693467337e-05,
      "loss": 0.357,
      "step": 9860
    },
    {
      "epoch": 0.3578161252900232,
      "grad_norm": 0.0,
      "learning_rate": 2.5452261306532665e-05,
      "loss": 0.0162,
      "step": 9870
    },
    {
      "epoch": 0.3581786542923434,
      "grad_norm": 25.48238347713536,
      "learning_rate": 2.5427135678391962e-05,
      "loss": 0.3248,
      "step": 9880
    },
    {
      "epoch": 0.35854118329466356,
      "grad_norm": 29.367493015170595,
      "learning_rate": 2.540201005025126e-05,
      "loss": 0.1535,
      "step": 9890
    },
    {
      "epoch": 0.35890371229698376,
      "grad_norm": 1.1890741756231913,
      "learning_rate": 2.5376884422110552e-05,
      "loss": 0.7546,
      "step": 9900
    },
    {
      "epoch": 0.35926624129930396,
      "grad_norm": 0.0,
      "learning_rate": 2.535175879396985e-05,
      "loss": 0.0747,
      "step": 9910
    },
    {
      "epoch": 0.35962877030162416,
      "grad_norm": 0.0,
      "learning_rate": 2.5326633165829145e-05,
      "loss": 0.2948,
      "step": 9920
    },
    {
      "epoch": 0.3599912993039443,
      "grad_norm": 31.801605337636357,
      "learning_rate": 2.5301507537688445e-05,
      "loss": 0.8724,
      "step": 9930
    },
    {
      "epoch": 0.3603538283062645,
      "grad_norm": 10.251867356816406,
      "learning_rate": 2.5276381909547742e-05,
      "loss": 0.3751,
      "step": 9940
    },
    {
      "epoch": 0.3607163573085847,
      "grad_norm": 25.262890235419917,
      "learning_rate": 2.525125628140704e-05,
      "loss": 0.9013,
      "step": 9950
    },
    {
      "epoch": 0.36107888631090485,
      "grad_norm": 35.002246021684094,
      "learning_rate": 2.522613065326633e-05,
      "loss": 0.6559,
      "step": 9960
    },
    {
      "epoch": 0.36144141531322505,
      "grad_norm": 1.4216440872659213,
      "learning_rate": 2.5201005025125628e-05,
      "loss": 0.0034,
      "step": 9970
    },
    {
      "epoch": 0.36180394431554525,
      "grad_norm": 0.0,
      "learning_rate": 2.5175879396984925e-05,
      "loss": 0.3653,
      "step": 9980
    },
    {
      "epoch": 0.36216647331786544,
      "grad_norm": 0.0,
      "learning_rate": 2.515075376884422e-05,
      "loss": 1.5267,
      "step": 9990
    },
    {
      "epoch": 0.3625290023201856,
      "grad_norm": 0.0,
      "learning_rate": 2.5125628140703518e-05,
      "loss": 0.2831,
      "step": 10000
    },
    {
      "epoch": 0.3625290023201856,
      "eval_loss": NaN,
      "eval_runtime": 76.2918,
      "eval_samples_per_second": 8.35,
      "eval_steps_per_second": 1.403,
      "step": 10000
    },
    {
      "epoch": 0.3628915313225058,
      "grad_norm": 0.0,
      "learning_rate": 2.5100502512562818e-05,
      "loss": 0.1044,
      "step": 10010
    },
    {
      "epoch": 0.363254060324826,
      "grad_norm": 0.0,
      "learning_rate": 2.5075376884422115e-05,
      "loss": 0.4739,
      "step": 10020
    },
    {
      "epoch": 0.3636165893271462,
      "grad_norm": 1.2671114351935677,
      "learning_rate": 2.5050251256281408e-05,
      "loss": 0.0136,
      "step": 10030
    },
    {
      "epoch": 0.36397911832946633,
      "grad_norm": 14.565859951374202,
      "learning_rate": 2.5025125628140705e-05,
      "loss": 0.8677,
      "step": 10040
    },
    {
      "epoch": 0.36434164733178653,
      "grad_norm": 7.698389543833406,
      "learning_rate": 2.5e-05,
      "loss": 0.2947,
      "step": 10050
    },
    {
      "epoch": 0.36470417633410673,
      "grad_norm": 0.0,
      "learning_rate": 2.4974874371859298e-05,
      "loss": 0.4945,
      "step": 10060
    },
    {
      "epoch": 0.36506670533642693,
      "grad_norm": 8.6450206206094,
      "learning_rate": 2.4949748743718594e-05,
      "loss": 0.0428,
      "step": 10070
    },
    {
      "epoch": 0.3654292343387471,
      "grad_norm": 16.051121106313143,
      "learning_rate": 2.492462311557789e-05,
      "loss": 0.2381,
      "step": 10080
    },
    {
      "epoch": 0.3657917633410673,
      "grad_norm": 0.0,
      "learning_rate": 2.4899497487437188e-05,
      "loss": 0.2326,
      "step": 10090
    },
    {
      "epoch": 0.3661542923433875,
      "grad_norm": 0.0,
      "learning_rate": 2.4874371859296484e-05,
      "loss": 0.4412,
      "step": 10100
    },
    {
      "epoch": 0.3665168213457077,
      "grad_norm": 4.411567671620721,
      "learning_rate": 2.4849246231155778e-05,
      "loss": 0.0713,
      "step": 10110
    },
    {
      "epoch": 0.3668793503480278,
      "grad_norm": 21.59824369849028,
      "learning_rate": 2.4824120603015078e-05,
      "loss": 0.9149,
      "step": 10120
    },
    {
      "epoch": 0.367241879350348,
      "grad_norm": 0.38971346357986103,
      "learning_rate": 2.4798994974874374e-05,
      "loss": 0.1017,
      "step": 10130
    },
    {
      "epoch": 0.3676044083526682,
      "grad_norm": 40.84821638978332,
      "learning_rate": 2.477386934673367e-05,
      "loss": 0.8923,
      "step": 10140
    },
    {
      "epoch": 0.3679669373549884,
      "grad_norm": 0.0,
      "learning_rate": 2.4748743718592964e-05,
      "loss": 0.1084,
      "step": 10150
    },
    {
      "epoch": 0.36832946635730857,
      "grad_norm": 0.05302118964690698,
      "learning_rate": 2.4723618090452264e-05,
      "loss": 0.5595,
      "step": 10160
    },
    {
      "epoch": 0.36869199535962877,
      "grad_norm": 0.0,
      "learning_rate": 2.469849246231156e-05,
      "loss": 0.6174,
      "step": 10170
    },
    {
      "epoch": 0.36905452436194897,
      "grad_norm": 0.0,
      "learning_rate": 2.4673366834170854e-05,
      "loss": 0.2255,
      "step": 10180
    },
    {
      "epoch": 0.36941705336426917,
      "grad_norm": 0.0,
      "learning_rate": 2.464824120603015e-05,
      "loss": 0.7557,
      "step": 10190
    },
    {
      "epoch": 0.3697795823665893,
      "grad_norm": 16.45239789466493,
      "learning_rate": 2.462311557788945e-05,
      "loss": 0.6663,
      "step": 10200
    },
    {
      "epoch": 0.3701421113689095,
      "grad_norm": 0.0,
      "learning_rate": 2.4597989949748744e-05,
      "loss": 0.1695,
      "step": 10210
    },
    {
      "epoch": 0.3705046403712297,
      "grad_norm": 0.007979097961555182,
      "learning_rate": 2.457286432160804e-05,
      "loss": 0.6648,
      "step": 10220
    },
    {
      "epoch": 0.3708671693735499,
      "grad_norm": 16.141305648765684,
      "learning_rate": 2.4547738693467337e-05,
      "loss": 0.1214,
      "step": 10230
    },
    {
      "epoch": 0.37122969837587005,
      "grad_norm": 0.0,
      "learning_rate": 2.4522613065326637e-05,
      "loss": 0.7635,
      "step": 10240
    },
    {
      "epoch": 0.37159222737819025,
      "grad_norm": 0.0,
      "learning_rate": 2.449748743718593e-05,
      "loss": 0.118,
      "step": 10250
    },
    {
      "epoch": 0.37195475638051045,
      "grad_norm": 0.0,
      "learning_rate": 2.4472361809045227e-05,
      "loss": 0.7477,
      "step": 10260
    },
    {
      "epoch": 0.37231728538283065,
      "grad_norm": 0.0,
      "learning_rate": 2.4447236180904523e-05,
      "loss": 0.1034,
      "step": 10270
    },
    {
      "epoch": 0.3726798143851508,
      "grad_norm": 0.0,
      "learning_rate": 2.442211055276382e-05,
      "loss": 0.1092,
      "step": 10280
    },
    {
      "epoch": 0.373042343387471,
      "grad_norm": 0.0,
      "learning_rate": 2.4396984924623117e-05,
      "loss": 0.6683,
      "step": 10290
    },
    {
      "epoch": 0.3734048723897912,
      "grad_norm": 14.636235021697061,
      "learning_rate": 2.4371859296482413e-05,
      "loss": 0.2114,
      "step": 10300
    },
    {
      "epoch": 0.37376740139211134,
      "grad_norm": 0.0,
      "learning_rate": 2.434673366834171e-05,
      "loss": 0.3787,
      "step": 10310
    },
    {
      "epoch": 0.37412993039443154,
      "grad_norm": 0.0,
      "learning_rate": 2.4321608040201007e-05,
      "loss": 0.5927,
      "step": 10320
    },
    {
      "epoch": 0.37449245939675174,
      "grad_norm": 0.0,
      "learning_rate": 2.4296482412060303e-05,
      "loss": 0.2294,
      "step": 10330
    },
    {
      "epoch": 0.37485498839907194,
      "grad_norm": 0.0,
      "learning_rate": 2.42713567839196e-05,
      "loss": 0.5195,
      "step": 10340
    },
    {
      "epoch": 0.3752175174013921,
      "grad_norm": 0.0,
      "learning_rate": 2.4246231155778896e-05,
      "loss": 0.0416,
      "step": 10350
    },
    {
      "epoch": 0.3755800464037123,
      "grad_norm": 0.0,
      "learning_rate": 2.422110552763819e-05,
      "loss": 0.3858,
      "step": 10360
    },
    {
      "epoch": 0.3759425754060325,
      "grad_norm": 0.0,
      "learning_rate": 2.419597989949749e-05,
      "loss": 0.0009,
      "step": 10370
    },
    {
      "epoch": 0.3763051044083527,
      "grad_norm": 0.0,
      "learning_rate": 2.4170854271356786e-05,
      "loss": 1.2909,
      "step": 10380
    },
    {
      "epoch": 0.37666763341067283,
      "grad_norm": 14.902145620406374,
      "learning_rate": 2.414572864321608e-05,
      "loss": 0.9386,
      "step": 10390
    },
    {
      "epoch": 0.37703016241299303,
      "grad_norm": 10.239865386793346,
      "learning_rate": 2.4120603015075376e-05,
      "loss": 0.1534,
      "step": 10400
    },
    {
      "epoch": 0.37739269141531323,
      "grad_norm": 0.0,
      "learning_rate": 2.4095477386934676e-05,
      "loss": 0.0136,
      "step": 10410
    },
    {
      "epoch": 0.37775522041763343,
      "grad_norm": 0.0,
      "learning_rate": 2.4070351758793973e-05,
      "loss": 0.6805,
      "step": 10420
    },
    {
      "epoch": 0.3781177494199536,
      "grad_norm": 0.0,
      "learning_rate": 2.4045226130653266e-05,
      "loss": 0.5796,
      "step": 10430
    },
    {
      "epoch": 0.3784802784222738,
      "grad_norm": 0.0,
      "learning_rate": 2.4020100502512563e-05,
      "loss": 0.0121,
      "step": 10440
    },
    {
      "epoch": 0.378842807424594,
      "grad_norm": 0.0,
      "learning_rate": 2.3994974874371863e-05,
      "loss": 0.0219,
      "step": 10450
    },
    {
      "epoch": 0.3792053364269142,
      "grad_norm": 0.0,
      "learning_rate": 2.3969849246231156e-05,
      "loss": 0.2488,
      "step": 10460
    },
    {
      "epoch": 0.3795678654292343,
      "grad_norm": 0.0,
      "learning_rate": 2.3944723618090452e-05,
      "loss": 0.4888,
      "step": 10470
    },
    {
      "epoch": 0.3799303944315545,
      "grad_norm": 0.0,
      "learning_rate": 2.391959798994975e-05,
      "loss": 0.3107,
      "step": 10480
    },
    {
      "epoch": 0.3802929234338747,
      "grad_norm": 8.24003693063108,
      "learning_rate": 2.389447236180905e-05,
      "loss": 0.4921,
      "step": 10490
    },
    {
      "epoch": 0.3806554524361949,
      "grad_norm": 0.0,
      "learning_rate": 2.3869346733668342e-05,
      "loss": 0.1941,
      "step": 10500
    },
    {
      "epoch": 0.3806554524361949,
      "eval_loss": NaN,
      "eval_runtime": 85.1798,
      "eval_samples_per_second": 7.478,
      "eval_steps_per_second": 1.256,
      "step": 10500
    },
    {
      "epoch": 0.38101798143851506,
      "grad_norm": 0.0,
      "learning_rate": 2.384422110552764e-05,
      "loss": 1.0389,
      "step": 10510
    },
    {
      "epoch": 0.38138051044083526,
      "grad_norm": 0.9654944075388369,
      "learning_rate": 2.3819095477386936e-05,
      "loss": 0.9808,
      "step": 10520
    },
    {
      "epoch": 0.38174303944315546,
      "grad_norm": 0.0,
      "learning_rate": 2.3793969849246232e-05,
      "loss": 0.2355,
      "step": 10530
    },
    {
      "epoch": 0.38210556844547566,
      "grad_norm": 0.0,
      "learning_rate": 2.376884422110553e-05,
      "loss": 0.4801,
      "step": 10540
    },
    {
      "epoch": 0.3824680974477958,
      "grad_norm": 0.0,
      "learning_rate": 2.3743718592964825e-05,
      "loss": 0.1253,
      "step": 10550
    },
    {
      "epoch": 0.382830626450116,
      "grad_norm": 0.0,
      "learning_rate": 2.3718592964824122e-05,
      "loss": 0.8778,
      "step": 10560
    },
    {
      "epoch": 0.3831931554524362,
      "grad_norm": 0.0,
      "learning_rate": 2.3693467336683415e-05,
      "loss": 0.6595,
      "step": 10570
    },
    {
      "epoch": 0.3835556844547564,
      "grad_norm": 0.0,
      "learning_rate": 2.3668341708542715e-05,
      "loss": 0.9462,
      "step": 10580
    },
    {
      "epoch": 0.38391821345707655,
      "grad_norm": 0.0,
      "learning_rate": 2.3643216080402012e-05,
      "loss": 1.6704,
      "step": 10590
    },
    {
      "epoch": 0.38428074245939675,
      "grad_norm": 40.16098737863105,
      "learning_rate": 2.361809045226131e-05,
      "loss": 0.52,
      "step": 10600
    },
    {
      "epoch": 0.38464327146171695,
      "grad_norm": 0.0,
      "learning_rate": 2.3592964824120602e-05,
      "loss": 0.1972,
      "step": 10610
    },
    {
      "epoch": 0.3850058004640371,
      "grad_norm": 0.0,
      "learning_rate": 2.3567839195979902e-05,
      "loss": 0.4538,
      "step": 10620
    },
    {
      "epoch": 0.3853683294663573,
      "grad_norm": 0.0,
      "learning_rate": 2.35427135678392e-05,
      "loss": 0.324,
      "step": 10630
    },
    {
      "epoch": 0.3857308584686775,
      "grad_norm": 0.0,
      "learning_rate": 2.351758793969849e-05,
      "loss": 0.0,
      "step": 10640
    },
    {
      "epoch": 0.3860933874709977,
      "grad_norm": 1.4407513378957229,
      "learning_rate": 2.3492462311557788e-05,
      "loss": 0.4767,
      "step": 10650
    },
    {
      "epoch": 0.38645591647331784,
      "grad_norm": 41.50226191595616,
      "learning_rate": 2.3467336683417088e-05,
      "loss": 0.1197,
      "step": 10660
    },
    {
      "epoch": 0.38681844547563804,
      "grad_norm": 13.532648802734965,
      "learning_rate": 2.3442211055276385e-05,
      "loss": 0.7047,
      "step": 10670
    },
    {
      "epoch": 0.38718097447795824,
      "grad_norm": 0.0,
      "learning_rate": 2.3417085427135678e-05,
      "loss": 0.1955,
      "step": 10680
    },
    {
      "epoch": 0.38754350348027844,
      "grad_norm": 0.0,
      "learning_rate": 2.3391959798994975e-05,
      "loss": 0.1039,
      "step": 10690
    },
    {
      "epoch": 0.3879060324825986,
      "grad_norm": 0.4624458300596464,
      "learning_rate": 2.3366834170854275e-05,
      "loss": 0.0252,
      "step": 10700
    },
    {
      "epoch": 0.3882685614849188,
      "grad_norm": 0.0,
      "learning_rate": 2.3341708542713568e-05,
      "loss": 0.763,
      "step": 10710
    },
    {
      "epoch": 0.388631090487239,
      "grad_norm": 0.0,
      "learning_rate": 2.3316582914572865e-05,
      "loss": 0.0033,
      "step": 10720
    },
    {
      "epoch": 0.3889936194895592,
      "grad_norm": 1.3093510955595031,
      "learning_rate": 2.329145728643216e-05,
      "loss": 0.0762,
      "step": 10730
    },
    {
      "epoch": 0.38935614849187933,
      "grad_norm": 0.0,
      "learning_rate": 2.326633165829146e-05,
      "loss": 1.0965,
      "step": 10740
    },
    {
      "epoch": 0.38971867749419953,
      "grad_norm": 0.0,
      "learning_rate": 2.3241206030150754e-05,
      "loss": 0.1675,
      "step": 10750
    },
    {
      "epoch": 0.39008120649651973,
      "grad_norm": 0.0,
      "learning_rate": 2.321608040201005e-05,
      "loss": 0.0024,
      "step": 10760
    },
    {
      "epoch": 0.39044373549883993,
      "grad_norm": 0.0,
      "learning_rate": 2.3190954773869348e-05,
      "loss": 0.2204,
      "step": 10770
    },
    {
      "epoch": 0.39080626450116007,
      "grad_norm": 29.03560268264689,
      "learning_rate": 2.3165829145728644e-05,
      "loss": 1.6363,
      "step": 10780
    },
    {
      "epoch": 0.39116879350348027,
      "grad_norm": 0.0,
      "learning_rate": 2.314070351758794e-05,
      "loss": 0.2232,
      "step": 10790
    },
    {
      "epoch": 0.39153132250580047,
      "grad_norm": 0.0,
      "learning_rate": 2.3115577889447238e-05,
      "loss": 0.0638,
      "step": 10800
    },
    {
      "epoch": 0.39189385150812067,
      "grad_norm": 0.0,
      "learning_rate": 2.3090452261306534e-05,
      "loss": 0.2848,
      "step": 10810
    },
    {
      "epoch": 0.3922563805104408,
      "grad_norm": 0.0,
      "learning_rate": 2.3065326633165827e-05,
      "loss": 0.5564,
      "step": 10820
    },
    {
      "epoch": 0.392618909512761,
      "grad_norm": 0.0,
      "learning_rate": 2.3040201005025127e-05,
      "loss": 0.0032,
      "step": 10830
    },
    {
      "epoch": 0.3929814385150812,
      "grad_norm": 0.0,
      "learning_rate": 2.3015075376884424e-05,
      "loss": 1.3762,
      "step": 10840
    },
    {
      "epoch": 0.3933439675174014,
      "grad_norm": 0.0,
      "learning_rate": 2.298994974874372e-05,
      "loss": 0.1308,
      "step": 10850
    },
    {
      "epoch": 0.39370649651972156,
      "grad_norm": 16.382568473981348,
      "learning_rate": 2.2964824120603014e-05,
      "loss": 1.0368,
      "step": 10860
    },
    {
      "epoch": 0.39406902552204176,
      "grad_norm": 0.0,
      "learning_rate": 2.2939698492462314e-05,
      "loss": 0.0647,
      "step": 10870
    },
    {
      "epoch": 0.39443155452436196,
      "grad_norm": 0.0,
      "learning_rate": 2.291457286432161e-05,
      "loss": 0.4059,
      "step": 10880
    },
    {
      "epoch": 0.39479408352668216,
      "grad_norm": 0.0,
      "learning_rate": 2.2889447236180904e-05,
      "loss": 0.1787,
      "step": 10890
    },
    {
      "epoch": 0.3951566125290023,
      "grad_norm": 0.0,
      "learning_rate": 2.28643216080402e-05,
      "loss": 0.266,
      "step": 10900
    },
    {
      "epoch": 0.3955191415313225,
      "grad_norm": 6.375601646605689,
      "learning_rate": 2.28391959798995e-05,
      "loss": 0.236,
      "step": 10910
    },
    {
      "epoch": 0.3958816705336427,
      "grad_norm": 0.0,
      "learning_rate": 2.2814070351758797e-05,
      "loss": 0.2955,
      "step": 10920
    },
    {
      "epoch": 0.3962441995359629,
      "grad_norm": 4.341050660894676,
      "learning_rate": 2.278894472361809e-05,
      "loss": 0.3495,
      "step": 10930
    },
    {
      "epoch": 0.39660672853828305,
      "grad_norm": 0.0,
      "learning_rate": 2.2763819095477387e-05,
      "loss": 0.7462,
      "step": 10940
    },
    {
      "epoch": 0.39696925754060325,
      "grad_norm": 4.880053517407742,
      "learning_rate": 2.2738693467336687e-05,
      "loss": 0.7204,
      "step": 10950
    },
    {
      "epoch": 0.39733178654292345,
      "grad_norm": 0.7163058061812027,
      "learning_rate": 2.271356783919598e-05,
      "loss": 0.1065,
      "step": 10960
    },
    {
      "epoch": 0.3976943155452436,
      "grad_norm": 0.0,
      "learning_rate": 2.2688442211055277e-05,
      "loss": 0.6514,
      "step": 10970
    },
    {
      "epoch": 0.3980568445475638,
      "grad_norm": 0.0,
      "learning_rate": 2.2663316582914573e-05,
      "loss": 0.5099,
      "step": 10980
    },
    {
      "epoch": 0.398419373549884,
      "grad_norm": 8.874519442590346,
      "learning_rate": 2.263819095477387e-05,
      "loss": 0.2105,
      "step": 10990
    },
    {
      "epoch": 0.3987819025522042,
      "grad_norm": 93.46598646031615,
      "learning_rate": 2.2613065326633167e-05,
      "loss": 0.901,
      "step": 11000
    },
    {
      "epoch": 0.3987819025522042,
      "eval_loss": NaN,
      "eval_runtime": 84.6874,
      "eval_samples_per_second": 7.522,
      "eval_steps_per_second": 1.263,
      "step": 11000
    },
    {
      "epoch": 0.39914443155452434,
      "grad_norm": 0.0,
      "learning_rate": 2.2587939698492463e-05,
      "loss": 0.665,
      "step": 11010
    },
    {
      "epoch": 0.39950696055684454,
      "grad_norm": 0.0,
      "learning_rate": 2.256281407035176e-05,
      "loss": 0.6285,
      "step": 11020
    },
    {
      "epoch": 0.39986948955916474,
      "grad_norm": 4.1718512259388145,
      "learning_rate": 2.2537688442211056e-05,
      "loss": 0.1338,
      "step": 11030
    },
    {
      "epoch": 0.40023201856148494,
      "grad_norm": 0.0,
      "learning_rate": 2.2512562814070353e-05,
      "loss": 0.124,
      "step": 11040
    },
    {
      "epoch": 0.4005945475638051,
      "grad_norm": 1.985311032100587,
      "learning_rate": 2.248743718592965e-05,
      "loss": 2.0598,
      "step": 11050
    },
    {
      "epoch": 0.4009570765661253,
      "grad_norm": 0.9856858985872874,
      "learning_rate": 2.2462311557788946e-05,
      "loss": 0.0401,
      "step": 11060
    },
    {
      "epoch": 0.4013196055684455,
      "grad_norm": 0.0,
      "learning_rate": 2.243718592964824e-05,
      "loss": 1.0508,
      "step": 11070
    },
    {
      "epoch": 0.4016821345707657,
      "grad_norm": 0.0,
      "learning_rate": 2.241206030150754e-05,
      "loss": 0.0491,
      "step": 11080
    },
    {
      "epoch": 0.4020446635730858,
      "grad_norm": 7.704116850286676,
      "learning_rate": 2.2386934673366836e-05,
      "loss": 0.3431,
      "step": 11090
    },
    {
      "epoch": 0.402407192575406,
      "grad_norm": 0.0,
      "learning_rate": 2.2361809045226133e-05,
      "loss": 0.9118,
      "step": 11100
    },
    {
      "epoch": 0.4027697215777262,
      "grad_norm": 0.0,
      "learning_rate": 2.2336683417085426e-05,
      "loss": 0.0266,
      "step": 11110
    },
    {
      "epoch": 0.4031322505800464,
      "grad_norm": 14.91837583727097,
      "learning_rate": 2.2311557788944726e-05,
      "loss": 0.7085,
      "step": 11120
    },
    {
      "epoch": 0.40349477958236657,
      "grad_norm": 3.3536660588892713,
      "learning_rate": 2.2286432160804023e-05,
      "loss": 0.3894,
      "step": 11130
    },
    {
      "epoch": 0.40385730858468677,
      "grad_norm": 29.260374136857962,
      "learning_rate": 2.2261306532663316e-05,
      "loss": 0.5921,
      "step": 11140
    },
    {
      "epoch": 0.40421983758700697,
      "grad_norm": 0.550615975763888,
      "learning_rate": 2.2236180904522613e-05,
      "loss": 0.5961,
      "step": 11150
    },
    {
      "epoch": 0.40458236658932717,
      "grad_norm": 0.0,
      "learning_rate": 2.2211055276381913e-05,
      "loss": 1.3847,
      "step": 11160
    },
    {
      "epoch": 0.4049448955916473,
      "grad_norm": 0.0,
      "learning_rate": 2.218592964824121e-05,
      "loss": 1.0438,
      "step": 11170
    },
    {
      "epoch": 0.4053074245939675,
      "grad_norm": 0.0,
      "learning_rate": 2.2160804020100502e-05,
      "loss": 0.391,
      "step": 11180
    },
    {
      "epoch": 0.4056699535962877,
      "grad_norm": 65.537430413133,
      "learning_rate": 2.21356783919598e-05,
      "loss": 0.5728,
      "step": 11190
    },
    {
      "epoch": 0.4060324825986079,
      "grad_norm": 0.0,
      "learning_rate": 2.21105527638191e-05,
      "loss": 0.8271,
      "step": 11200
    },
    {
      "epoch": 0.40639501160092806,
      "grad_norm": 0.0,
      "learning_rate": 2.2085427135678392e-05,
      "loss": 0.1587,
      "step": 11210
    },
    {
      "epoch": 0.40675754060324826,
      "grad_norm": 0.0,
      "learning_rate": 2.206030150753769e-05,
      "loss": 0.5587,
      "step": 11220
    },
    {
      "epoch": 0.40712006960556846,
      "grad_norm": 0.9452111686432518,
      "learning_rate": 2.2035175879396986e-05,
      "loss": 0.2301,
      "step": 11230
    },
    {
      "epoch": 0.40748259860788866,
      "grad_norm": 12.503877572405415,
      "learning_rate": 2.2010050251256282e-05,
      "loss": 0.4952,
      "step": 11240
    },
    {
      "epoch": 0.4078451276102088,
      "grad_norm": 0.0,
      "learning_rate": 2.198492462311558e-05,
      "loss": 0.0605,
      "step": 11250
    },
    {
      "epoch": 0.408207656612529,
      "grad_norm": 0.0,
      "learning_rate": 2.1959798994974875e-05,
      "loss": 0.1263,
      "step": 11260
    },
    {
      "epoch": 0.4085701856148492,
      "grad_norm": 0.0,
      "learning_rate": 2.1934673366834172e-05,
      "loss": 0.3629,
      "step": 11270
    },
    {
      "epoch": 0.40893271461716935,
      "grad_norm": 0.0,
      "learning_rate": 2.190954773869347e-05,
      "loss": 0.9125,
      "step": 11280
    },
    {
      "epoch": 0.40929524361948955,
      "grad_norm": 0.30574491607590876,
      "learning_rate": 2.1884422110552765e-05,
      "loss": 0.3029,
      "step": 11290
    },
    {
      "epoch": 0.40965777262180975,
      "grad_norm": 0.0,
      "learning_rate": 2.1859296482412062e-05,
      "loss": 0.0537,
      "step": 11300
    },
    {
      "epoch": 0.41002030162412995,
      "grad_norm": 0.1993678040237249,
      "learning_rate": 2.183417085427136e-05,
      "loss": 0.3946,
      "step": 11310
    },
    {
      "epoch": 0.4103828306264501,
      "grad_norm": 0.0,
      "learning_rate": 2.1809045226130652e-05,
      "loss": 0.4403,
      "step": 11320
    },
    {
      "epoch": 0.4107453596287703,
      "grad_norm": 0.3026740229345646,
      "learning_rate": 2.1783919597989952e-05,
      "loss": 0.2793,
      "step": 11330
    },
    {
      "epoch": 0.4111078886310905,
      "grad_norm": 13.100409441657254,
      "learning_rate": 2.175879396984925e-05,
      "loss": 0.3408,
      "step": 11340
    },
    {
      "epoch": 0.4114704176334107,
      "grad_norm": 14.511590994558777,
      "learning_rate": 2.1733668341708545e-05,
      "loss": 0.1657,
      "step": 11350
    },
    {
      "epoch": 0.41183294663573083,
      "grad_norm": 0.0,
      "learning_rate": 2.1708542713567838e-05,
      "loss": 0.5463,
      "step": 11360
    },
    {
      "epoch": 0.41219547563805103,
      "grad_norm": 0.0,
      "learning_rate": 2.1683417085427138e-05,
      "loss": 0.5707,
      "step": 11370
    },
    {
      "epoch": 0.41255800464037123,
      "grad_norm": 0.0,
      "learning_rate": 2.1658291457286435e-05,
      "loss": 0.3373,
      "step": 11380
    },
    {
      "epoch": 0.41292053364269143,
      "grad_norm": 2.6623072952952893,
      "learning_rate": 2.1633165829145728e-05,
      "loss": 0.2637,
      "step": 11390
    },
    {
      "epoch": 0.4132830626450116,
      "grad_norm": 0.0,
      "learning_rate": 2.1608040201005025e-05,
      "loss": 0.2218,
      "step": 11400
    },
    {
      "epoch": 0.4136455916473318,
      "grad_norm": 16.80867227424721,
      "learning_rate": 2.1582914572864325e-05,
      "loss": 0.4413,
      "step": 11410
    },
    {
      "epoch": 0.414008120649652,
      "grad_norm": 0.0,
      "learning_rate": 2.155778894472362e-05,
      "loss": 0.4342,
      "step": 11420
    },
    {
      "epoch": 0.4143706496519722,
      "grad_norm": 0.0,
      "learning_rate": 2.1532663316582915e-05,
      "loss": 0.5787,
      "step": 11430
    },
    {
      "epoch": 0.4147331786542923,
      "grad_norm": 0.0,
      "learning_rate": 2.150753768844221e-05,
      "loss": 0.0672,
      "step": 11440
    },
    {
      "epoch": 0.4150957076566125,
      "grad_norm": 0.0,
      "learning_rate": 2.1482412060301508e-05,
      "loss": 0.1684,
      "step": 11450
    },
    {
      "epoch": 0.4154582366589327,
      "grad_norm": 0.0,
      "learning_rate": 2.1457286432160804e-05,
      "loss": 0.7737,
      "step": 11460
    },
    {
      "epoch": 0.4158207656612529,
      "grad_norm": 0.8927584743476772,
      "learning_rate": 2.14321608040201e-05,
      "loss": 0.0137,
      "step": 11470
    },
    {
      "epoch": 0.41618329466357307,
      "grad_norm": 14.404177568361842,
      "learning_rate": 2.1407035175879398e-05,
      "loss": 0.1724,
      "step": 11480
    },
    {
      "epoch": 0.41654582366589327,
      "grad_norm": 0.0,
      "learning_rate": 2.1381909547738694e-05,
      "loss": 0.7131,
      "step": 11490
    },
    {
      "epoch": 0.41690835266821347,
      "grad_norm": 0.0,
      "learning_rate": 2.135678391959799e-05,
      "loss": 0.2546,
      "step": 11500
    },
    {
      "epoch": 0.41690835266821347,
      "eval_loss": NaN,
      "eval_runtime": 84.9855,
      "eval_samples_per_second": 7.495,
      "eval_steps_per_second": 1.259,
      "step": 11500
    },
    {
      "epoch": 0.41727088167053367,
      "grad_norm": 0.0,
      "learning_rate": 2.1331658291457288e-05,
      "loss": 0.5713,
      "step": 11510
    },
    {
      "epoch": 0.4176334106728538,
      "grad_norm": 0.0,
      "learning_rate": 2.1306532663316584e-05,
      "loss": 0.3675,
      "step": 11520
    },
    {
      "epoch": 0.417995939675174,
      "grad_norm": 0.0,
      "learning_rate": 2.128140703517588e-05,
      "loss": 0.2991,
      "step": 11530
    },
    {
      "epoch": 0.4183584686774942,
      "grad_norm": 1.059669707949597,
      "learning_rate": 2.1256281407035177e-05,
      "loss": 0.4101,
      "step": 11540
    },
    {
      "epoch": 0.4187209976798144,
      "grad_norm": 0.0,
      "learning_rate": 2.1231155778894474e-05,
      "loss": 0.6243,
      "step": 11550
    },
    {
      "epoch": 0.41908352668213456,
      "grad_norm": 15.337477635349424,
      "learning_rate": 2.120603015075377e-05,
      "loss": 0.8671,
      "step": 11560
    },
    {
      "epoch": 0.41944605568445475,
      "grad_norm": 0.0,
      "learning_rate": 2.1180904522613064e-05,
      "loss": 0.5275,
      "step": 11570
    },
    {
      "epoch": 0.41980858468677495,
      "grad_norm": 17.57657805693151,
      "learning_rate": 2.1155778894472364e-05,
      "loss": 0.4542,
      "step": 11580
    },
    {
      "epoch": 0.42017111368909515,
      "grad_norm": 0.0,
      "learning_rate": 2.113065326633166e-05,
      "loss": 0.9518,
      "step": 11590
    },
    {
      "epoch": 0.4205336426914153,
      "grad_norm": 0.0,
      "learning_rate": 2.1105527638190957e-05,
      "loss": 0.3096,
      "step": 11600
    },
    {
      "epoch": 0.4208961716937355,
      "grad_norm": 0.0,
      "learning_rate": 2.108040201005025e-05,
      "loss": 0.1678,
      "step": 11610
    },
    {
      "epoch": 0.4212587006960557,
      "grad_norm": 0.0,
      "learning_rate": 2.105527638190955e-05,
      "loss": 0.1369,
      "step": 11620
    },
    {
      "epoch": 0.42162122969837584,
      "grad_norm": 0.0,
      "learning_rate": 2.1030150753768847e-05,
      "loss": 0.4024,
      "step": 11630
    },
    {
      "epoch": 0.42198375870069604,
      "grad_norm": 0.0,
      "learning_rate": 2.100502512562814e-05,
      "loss": 0.4195,
      "step": 11640
    },
    {
      "epoch": 0.42234628770301624,
      "grad_norm": 18.44091185990024,
      "learning_rate": 2.0979899497487437e-05,
      "loss": 0.1277,
      "step": 11650
    },
    {
      "epoch": 0.42270881670533644,
      "grad_norm": 0.0,
      "learning_rate": 2.0954773869346737e-05,
      "loss": 0.1306,
      "step": 11660
    },
    {
      "epoch": 0.4230713457076566,
      "grad_norm": 0.0,
      "learning_rate": 2.0929648241206033e-05,
      "loss": 0.5407,
      "step": 11670
    },
    {
      "epoch": 0.4234338747099768,
      "grad_norm": 0.0,
      "learning_rate": 2.0904522613065327e-05,
      "loss": 0.2661,
      "step": 11680
    },
    {
      "epoch": 0.423796403712297,
      "grad_norm": 0.0,
      "learning_rate": 2.0879396984924623e-05,
      "loss": 0.2587,
      "step": 11690
    },
    {
      "epoch": 0.4241589327146172,
      "grad_norm": 6.552051182250046,
      "learning_rate": 2.085427135678392e-05,
      "loss": 0.4975,
      "step": 11700
    },
    {
      "epoch": 0.42452146171693733,
      "grad_norm": 0.0,
      "learning_rate": 2.0829145728643217e-05,
      "loss": 0.0439,
      "step": 11710
    },
    {
      "epoch": 0.42488399071925753,
      "grad_norm": 0.0,
      "learning_rate": 2.0804020100502513e-05,
      "loss": 0.2882,
      "step": 11720
    },
    {
      "epoch": 0.42524651972157773,
      "grad_norm": 0.0,
      "learning_rate": 2.077889447236181e-05,
      "loss": 0.0136,
      "step": 11730
    },
    {
      "epoch": 0.42560904872389793,
      "grad_norm": 0.0,
      "learning_rate": 2.0753768844221106e-05,
      "loss": 0.3009,
      "step": 11740
    },
    {
      "epoch": 0.4259715777262181,
      "grad_norm": 0.0,
      "learning_rate": 2.0728643216080403e-05,
      "loss": 0.2145,
      "step": 11750
    },
    {
      "epoch": 0.4263341067285383,
      "grad_norm": 20.929025512114002,
      "learning_rate": 2.07035175879397e-05,
      "loss": 0.4307,
      "step": 11760
    },
    {
      "epoch": 0.4266966357308585,
      "grad_norm": 0.0,
      "learning_rate": 2.0678391959798996e-05,
      "loss": 0.7862,
      "step": 11770
    },
    {
      "epoch": 0.4270591647331787,
      "grad_norm": 0.0,
      "learning_rate": 2.0653266331658293e-05,
      "loss": 0.4205,
      "step": 11780
    },
    {
      "epoch": 0.4274216937354988,
      "grad_norm": 0.0,
      "learning_rate": 2.062814070351759e-05,
      "loss": 0.1278,
      "step": 11790
    },
    {
      "epoch": 0.427784222737819,
      "grad_norm": 0.0,
      "learning_rate": 2.0603015075376886e-05,
      "loss": 0.06,
      "step": 11800
    },
    {
      "epoch": 0.4281467517401392,
      "grad_norm": 0.0,
      "learning_rate": 2.0577889447236183e-05,
      "loss": 0.0433,
      "step": 11810
    },
    {
      "epoch": 0.4285092807424594,
      "grad_norm": 0.0,
      "learning_rate": 2.0552763819095476e-05,
      "loss": 0.4166,
      "step": 11820
    },
    {
      "epoch": 0.42887180974477956,
      "grad_norm": 0.0,
      "learning_rate": 2.0527638190954776e-05,
      "loss": 0.3857,
      "step": 11830
    },
    {
      "epoch": 0.42923433874709976,
      "grad_norm": 22.310224657487833,
      "learning_rate": 2.0502512562814073e-05,
      "loss": 0.8037,
      "step": 11840
    },
    {
      "epoch": 0.42959686774941996,
      "grad_norm": 0.0,
      "learning_rate": 2.047738693467337e-05,
      "loss": 0.206,
      "step": 11850
    },
    {
      "epoch": 0.42995939675174016,
      "grad_norm": 0.0,
      "learning_rate": 2.0452261306532662e-05,
      "loss": 0.2508,
      "step": 11860
    },
    {
      "epoch": 0.4303219257540603,
      "grad_norm": 0.0,
      "learning_rate": 2.0427135678391962e-05,
      "loss": 0.2979,
      "step": 11870
    },
    {
      "epoch": 0.4306844547563805,
      "grad_norm": 0.0,
      "learning_rate": 2.040201005025126e-05,
      "loss": 0.1426,
      "step": 11880
    },
    {
      "epoch": 0.4310469837587007,
      "grad_norm": 0.0,
      "learning_rate": 2.0376884422110552e-05,
      "loss": 1.0476,
      "step": 11890
    },
    {
      "epoch": 0.4314095127610209,
      "grad_norm": 30.34769018895322,
      "learning_rate": 2.035175879396985e-05,
      "loss": 0.3808,
      "step": 11900
    },
    {
      "epoch": 0.43177204176334105,
      "grad_norm": 0.0,
      "learning_rate": 2.0326633165829146e-05,
      "loss": 0.0,
      "step": 11910
    },
    {
      "epoch": 0.43213457076566125,
      "grad_norm": 0.0,
      "learning_rate": 2.0301507537688446e-05,
      "loss": 0.0045,
      "step": 11920
    },
    {
      "epoch": 0.43249709976798145,
      "grad_norm": 0.0,
      "learning_rate": 2.027638190954774e-05,
      "loss": 0.0,
      "step": 11930
    },
    {
      "epoch": 0.4328596287703016,
      "grad_norm": 16.483709443021407,
      "learning_rate": 2.0251256281407035e-05,
      "loss": 0.3652,
      "step": 11940
    },
    {
      "epoch": 0.4332221577726218,
      "grad_norm": 14.34954650374991,
      "learning_rate": 2.0226130653266332e-05,
      "loss": 0.65,
      "step": 11950
    },
    {
      "epoch": 0.433584686774942,
      "grad_norm": 0.0,
      "learning_rate": 2.020100502512563e-05,
      "loss": 0.3107,
      "step": 11960
    },
    {
      "epoch": 0.4339472157772622,
      "grad_norm": 0.253643868665247,
      "learning_rate": 2.0175879396984925e-05,
      "loss": 0.2964,
      "step": 11970
    },
    {
      "epoch": 0.43430974477958234,
      "grad_norm": 0.0,
      "learning_rate": 2.0150753768844222e-05,
      "loss": 0.0279,
      "step": 11980
    },
    {
      "epoch": 0.43467227378190254,
      "grad_norm": 0.0,
      "learning_rate": 2.012562814070352e-05,
      "loss": 0.6049,
      "step": 11990
    },
    {
      "epoch": 0.43503480278422274,
      "grad_norm": 0.0,
      "learning_rate": 2.0100502512562815e-05,
      "loss": 0.3259,
      "step": 12000
    },
    {
      "epoch": 0.43503480278422274,
      "eval_loss": NaN,
      "eval_runtime": 82.2205,
      "eval_samples_per_second": 7.747,
      "eval_steps_per_second": 1.301,
      "step": 12000
    },
    {
      "epoch": 0.43539733178654294,
      "grad_norm": 0.0,
      "learning_rate": 2.0075376884422112e-05,
      "loss": 0.0156,
      "step": 12010
    },
    {
      "epoch": 0.4357598607888631,
      "grad_norm": 0.0,
      "learning_rate": 2.005025125628141e-05,
      "loss": 0.7654,
      "step": 12020
    },
    {
      "epoch": 0.4361223897911833,
      "grad_norm": 0.0,
      "learning_rate": 2.0025125628140705e-05,
      "loss": 1.4004,
      "step": 12030
    },
    {
      "epoch": 0.4364849187935035,
      "grad_norm": 0.0,
      "learning_rate": 2e-05,
      "loss": 0.0285,
      "step": 12040
    },
    {
      "epoch": 0.4368474477958237,
      "grad_norm": 4.444775057787632,
      "learning_rate": 1.9974874371859298e-05,
      "loss": 1.215,
      "step": 12050
    },
    {
      "epoch": 0.43720997679814383,
      "grad_norm": 0.20105518734552785,
      "learning_rate": 1.9949748743718595e-05,
      "loss": 0.0011,
      "step": 12060
    },
    {
      "epoch": 0.43757250580046403,
      "grad_norm": 0.0,
      "learning_rate": 1.9924623115577888e-05,
      "loss": 0.1136,
      "step": 12070
    },
    {
      "epoch": 0.43793503480278423,
      "grad_norm": 0.0,
      "learning_rate": 1.9899497487437188e-05,
      "loss": 0.0686,
      "step": 12080
    },
    {
      "epoch": 0.43829756380510443,
      "grad_norm": 37.91283015589429,
      "learning_rate": 1.9874371859296485e-05,
      "loss": 0.253,
      "step": 12090
    },
    {
      "epoch": 0.4386600928074246,
      "grad_norm": 0.17162252978410777,
      "learning_rate": 1.984924623115578e-05,
      "loss": 0.5119,
      "step": 12100
    },
    {
      "epoch": 0.4390226218097448,
      "grad_norm": 0.19081309918891498,
      "learning_rate": 1.9824120603015075e-05,
      "loss": 0.0923,
      "step": 12110
    },
    {
      "epoch": 0.439385150812065,
      "grad_norm": 0.0,
      "learning_rate": 1.9798994974874375e-05,
      "loss": 0.6841,
      "step": 12120
    },
    {
      "epoch": 0.4397476798143852,
      "grad_norm": 0.0,
      "learning_rate": 1.977386934673367e-05,
      "loss": 0.0,
      "step": 12130
    },
    {
      "epoch": 0.4401102088167053,
      "grad_norm": 0.18781513315408285,
      "learning_rate": 1.9748743718592964e-05,
      "loss": 0.6195,
      "step": 12140
    },
    {
      "epoch": 0.4404727378190255,
      "grad_norm": 0.0,
      "learning_rate": 1.972361809045226e-05,
      "loss": 0.4953,
      "step": 12150
    },
    {
      "epoch": 0.4408352668213457,
      "grad_norm": 0.0,
      "learning_rate": 1.9698492462311558e-05,
      "loss": 0.5622,
      "step": 12160
    },
    {
      "epoch": 0.4411977958236659,
      "grad_norm": 0.21437735652184456,
      "learning_rate": 1.9673366834170858e-05,
      "loss": 0.7973,
      "step": 12170
    },
    {
      "epoch": 0.44156032482598606,
      "grad_norm": 0.0,
      "learning_rate": 1.964824120603015e-05,
      "loss": 0.3901,
      "step": 12180
    },
    {
      "epoch": 0.44192285382830626,
      "grad_norm": 0.0,
      "learning_rate": 1.9623115577889448e-05,
      "loss": 1.4367,
      "step": 12190
    },
    {
      "epoch": 0.44228538283062646,
      "grad_norm": 0.163824988059089,
      "learning_rate": 1.9597989949748744e-05,
      "loss": 0.1857,
      "step": 12200
    },
    {
      "epoch": 0.44264791183294666,
      "grad_norm": 0.0,
      "learning_rate": 1.957286432160804e-05,
      "loss": 0.5084,
      "step": 12210
    },
    {
      "epoch": 0.4430104408352668,
      "grad_norm": 0.0,
      "learning_rate": 1.9547738693467337e-05,
      "loss": 0.1967,
      "step": 12220
    },
    {
      "epoch": 0.443372969837587,
      "grad_norm": 4.433561269498314,
      "learning_rate": 1.9522613065326634e-05,
      "loss": 0.0123,
      "step": 12230
    },
    {
      "epoch": 0.4437354988399072,
      "grad_norm": 6.075738982791453,
      "learning_rate": 1.949748743718593e-05,
      "loss": 0.934,
      "step": 12240
    },
    {
      "epoch": 0.4440980278422274,
      "grad_norm": 27.61122084590905,
      "learning_rate": 1.9472361809045227e-05,
      "loss": 1.3902,
      "step": 12250
    },
    {
      "epoch": 0.44446055684454755,
      "grad_norm": 0.0,
      "learning_rate": 1.9447236180904524e-05,
      "loss": 0.8161,
      "step": 12260
    },
    {
      "epoch": 0.44482308584686775,
      "grad_norm": 0.0,
      "learning_rate": 1.942211055276382e-05,
      "loss": 0.3146,
      "step": 12270
    },
    {
      "epoch": 0.44518561484918795,
      "grad_norm": 0.0,
      "learning_rate": 1.9396984924623117e-05,
      "loss": 0.1286,
      "step": 12280
    },
    {
      "epoch": 0.4455481438515081,
      "grad_norm": 0.0,
      "learning_rate": 1.9371859296482414e-05,
      "loss": 0.0447,
      "step": 12290
    },
    {
      "epoch": 0.4459106728538283,
      "grad_norm": 0.0,
      "learning_rate": 1.934673366834171e-05,
      "loss": 0.0064,
      "step": 12300
    },
    {
      "epoch": 0.4462732018561485,
      "grad_norm": 0.0,
      "learning_rate": 1.9321608040201007e-05,
      "loss": 0.8436,
      "step": 12310
    },
    {
      "epoch": 0.4466357308584687,
      "grad_norm": 41.58238627872158,
      "learning_rate": 1.92964824120603e-05,
      "loss": 1.279,
      "step": 12320
    },
    {
      "epoch": 0.44699825986078884,
      "grad_norm": 0.0,
      "learning_rate": 1.92713567839196e-05,
      "loss": 1.1401,
      "step": 12330
    },
    {
      "epoch": 0.44736078886310904,
      "grad_norm": 0.31191456316368515,
      "learning_rate": 1.9246231155778897e-05,
      "loss": 0.0039,
      "step": 12340
    },
    {
      "epoch": 0.44772331786542924,
      "grad_norm": 0.0,
      "learning_rate": 1.9221105527638193e-05,
      "loss": 0.5761,
      "step": 12350
    },
    {
      "epoch": 0.44808584686774944,
      "grad_norm": 2.6764831958786974,
      "learning_rate": 1.9195979899497487e-05,
      "loss": 0.0289,
      "step": 12360
    },
    {
      "epoch": 0.4484483758700696,
      "grad_norm": 0.0,
      "learning_rate": 1.9170854271356783e-05,
      "loss": 0.4756,
      "step": 12370
    },
    {
      "epoch": 0.4488109048723898,
      "grad_norm": 11.081247425025257,
      "learning_rate": 1.9145728643216083e-05,
      "loss": 0.7544,
      "step": 12380
    },
    {
      "epoch": 0.44917343387471,
      "grad_norm": 0.0,
      "learning_rate": 1.9120603015075377e-05,
      "loss": 0.357,
      "step": 12390
    },
    {
      "epoch": 0.4495359628770302,
      "grad_norm": 0.6905682113222084,
      "learning_rate": 1.9095477386934673e-05,
      "loss": 0.3746,
      "step": 12400
    },
    {
      "epoch": 0.4498984918793503,
      "grad_norm": 0.40944823054165286,
      "learning_rate": 1.907035175879397e-05,
      "loss": 0.6213,
      "step": 12410
    },
    {
      "epoch": 0.4502610208816705,
      "grad_norm": 0.0,
      "learning_rate": 1.9045226130653266e-05,
      "loss": 0.7172,
      "step": 12420
    },
    {
      "epoch": 0.4506235498839907,
      "grad_norm": 0.0,
      "learning_rate": 1.9020100502512563e-05,
      "loss": 0.1367,
      "step": 12430
    },
    {
      "epoch": 0.4509860788863109,
      "grad_norm": 0.0,
      "learning_rate": 1.899497487437186e-05,
      "loss": 0.2353,
      "step": 12440
    },
    {
      "epoch": 0.45134860788863107,
      "grad_norm": 0.12053897120980209,
      "learning_rate": 1.8969849246231156e-05,
      "loss": 0.0871,
      "step": 12450
    },
    {
      "epoch": 0.45171113689095127,
      "grad_norm": 0.0,
      "learning_rate": 1.8944723618090453e-05,
      "loss": 0.9233,
      "step": 12460
    },
    {
      "epoch": 0.45207366589327147,
      "grad_norm": 0.18408070571381693,
      "learning_rate": 1.891959798994975e-05,
      "loss": 0.2103,
      "step": 12470
    },
    {
      "epoch": 0.45243619489559167,
      "grad_norm": 1.4365098279649338,
      "learning_rate": 1.8894472361809046e-05,
      "loss": 0.191,
      "step": 12480
    },
    {
      "epoch": 0.4527987238979118,
      "grad_norm": 0.0,
      "learning_rate": 1.8869346733668343e-05,
      "loss": 0.6032,
      "step": 12490
    },
    {
      "epoch": 0.453161252900232,
      "grad_norm": 0.0,
      "learning_rate": 1.884422110552764e-05,
      "loss": 0.3561,
      "step": 12500
    },
    {
      "epoch": 0.453161252900232,
      "eval_loss": NaN,
      "eval_runtime": 77.5139,
      "eval_samples_per_second": 8.218,
      "eval_steps_per_second": 1.38,
      "step": 12500
    },
    {
      "epoch": 0.4535237819025522,
      "grad_norm": 0.0,
      "learning_rate": 1.8819095477386936e-05,
      "loss": 0.5361,
      "step": 12510
    },
    {
      "epoch": 0.4538863109048724,
      "grad_norm": 7.25737440020938,
      "learning_rate": 1.8793969849246233e-05,
      "loss": 0.1558,
      "step": 12520
    },
    {
      "epoch": 0.45424883990719256,
      "grad_norm": 0.09248550304660039,
      "learning_rate": 1.876884422110553e-05,
      "loss": 0.1305,
      "step": 12530
    },
    {
      "epoch": 0.45461136890951276,
      "grad_norm": 0.0,
      "learning_rate": 1.8743718592964826e-05,
      "loss": 0.1732,
      "step": 12540
    },
    {
      "epoch": 0.45497389791183296,
      "grad_norm": 0.14105931078238504,
      "learning_rate": 1.8718592964824123e-05,
      "loss": 0.0084,
      "step": 12550
    },
    {
      "epoch": 0.45533642691415316,
      "grad_norm": 0.0,
      "learning_rate": 1.869346733668342e-05,
      "loss": 0.7422,
      "step": 12560
    },
    {
      "epoch": 0.4556989559164733,
      "grad_norm": 0.0,
      "learning_rate": 1.8668341708542712e-05,
      "loss": 0.4633,
      "step": 12570
    },
    {
      "epoch": 0.4560614849187935,
      "grad_norm": 28.98970638298834,
      "learning_rate": 1.8643216080402012e-05,
      "loss": 0.3957,
      "step": 12580
    },
    {
      "epoch": 0.4564240139211137,
      "grad_norm": 22.5886552271423,
      "learning_rate": 1.861809045226131e-05,
      "loss": 0.4504,
      "step": 12590
    },
    {
      "epoch": 0.45678654292343385,
      "grad_norm": 11.148657857405276,
      "learning_rate": 1.8592964824120602e-05,
      "loss": 0.8547,
      "step": 12600
    },
    {
      "epoch": 0.45714907192575405,
      "grad_norm": 18.72491241556828,
      "learning_rate": 1.85678391959799e-05,
      "loss": 0.1145,
      "step": 12610
    },
    {
      "epoch": 0.45751160092807425,
      "grad_norm": 0.0,
      "learning_rate": 1.8542713567839195e-05,
      "loss": 0.0118,
      "step": 12620
    },
    {
      "epoch": 0.45787412993039445,
      "grad_norm": 0.0,
      "learning_rate": 1.8517587939698495e-05,
      "loss": 1.0759,
      "step": 12630
    },
    {
      "epoch": 0.4582366589327146,
      "grad_norm": 14.597582034197211,
      "learning_rate": 1.849246231155779e-05,
      "loss": 0.1393,
      "step": 12640
    },
    {
      "epoch": 0.4585991879350348,
      "grad_norm": 0.0,
      "learning_rate": 1.8467336683417085e-05,
      "loss": 1.5153,
      "step": 12650
    },
    {
      "epoch": 0.458961716937355,
      "grad_norm": 0.03555949401092996,
      "learning_rate": 1.8442211055276382e-05,
      "loss": 0.7747,
      "step": 12660
    },
    {
      "epoch": 0.4593242459396752,
      "grad_norm": 16.020948048326836,
      "learning_rate": 1.841708542713568e-05,
      "loss": 0.1407,
      "step": 12670
    },
    {
      "epoch": 0.45968677494199534,
      "grad_norm": 11.181615891075264,
      "learning_rate": 1.8391959798994975e-05,
      "loss": 0.7117,
      "step": 12680
    },
    {
      "epoch": 0.46004930394431554,
      "grad_norm": 0.0,
      "learning_rate": 1.8366834170854272e-05,
      "loss": 0.6441,
      "step": 12690
    },
    {
      "epoch": 0.46041183294663574,
      "grad_norm": 0.9416068089008062,
      "learning_rate": 1.834170854271357e-05,
      "loss": 0.0505,
      "step": 12700
    },
    {
      "epoch": 0.46077436194895594,
      "grad_norm": 0.0,
      "learning_rate": 1.8316582914572865e-05,
      "loss": 0.0007,
      "step": 12710
    },
    {
      "epoch": 0.4611368909512761,
      "grad_norm": 44.98565716521142,
      "learning_rate": 1.829145728643216e-05,
      "loss": 1.0237,
      "step": 12720
    },
    {
      "epoch": 0.4614994199535963,
      "grad_norm": 0.0,
      "learning_rate": 1.826633165829146e-05,
      "loss": 0.0486,
      "step": 12730
    },
    {
      "epoch": 0.4618619489559165,
      "grad_norm": 22.76817853086367,
      "learning_rate": 1.8241206030150755e-05,
      "loss": 0.1276,
      "step": 12740
    },
    {
      "epoch": 0.4622244779582367,
      "grad_norm": 4.283528856102124,
      "learning_rate": 1.821608040201005e-05,
      "loss": 0.8673,
      "step": 12750
    },
    {
      "epoch": 0.4625870069605568,
      "grad_norm": 0.0,
      "learning_rate": 1.8190954773869348e-05,
      "loss": 0.1951,
      "step": 12760
    },
    {
      "epoch": 0.462949535962877,
      "grad_norm": 0.0,
      "learning_rate": 1.8165829145728645e-05,
      "loss": 0.0852,
      "step": 12770
    },
    {
      "epoch": 0.4633120649651972,
      "grad_norm": 16.974309920159495,
      "learning_rate": 1.814070351758794e-05,
      "loss": 0.7686,
      "step": 12780
    },
    {
      "epoch": 0.4636745939675174,
      "grad_norm": 0.0,
      "learning_rate": 1.8115577889447238e-05,
      "loss": 1.0875,
      "step": 12790
    },
    {
      "epoch": 0.46403712296983757,
      "grad_norm": 7.178671282390303,
      "learning_rate": 1.8090452261306535e-05,
      "loss": 0.6149,
      "step": 12800
    },
    {
      "epoch": 0.46439965197215777,
      "grad_norm": 0.0,
      "learning_rate": 1.806532663316583e-05,
      "loss": 0.4192,
      "step": 12810
    },
    {
      "epoch": 0.46476218097447797,
      "grad_norm": 0.0,
      "learning_rate": 1.8040201005025125e-05,
      "loss": 0.8705,
      "step": 12820
    },
    {
      "epoch": 0.46512470997679817,
      "grad_norm": 0.0,
      "learning_rate": 1.801507537688442e-05,
      "loss": 0.0818,
      "step": 12830
    },
    {
      "epoch": 0.4654872389791183,
      "grad_norm": 0.0,
      "learning_rate": 1.798994974874372e-05,
      "loss": 0.75,
      "step": 12840
    },
    {
      "epoch": 0.4658497679814385,
      "grad_norm": 0.0,
      "learning_rate": 1.7964824120603014e-05,
      "loss": 0.7573,
      "step": 12850
    },
    {
      "epoch": 0.4662122969837587,
      "grad_norm": 0.0,
      "learning_rate": 1.793969849246231e-05,
      "loss": 0.0939,
      "step": 12860
    },
    {
      "epoch": 0.4665748259860789,
      "grad_norm": 0.0,
      "learning_rate": 1.7914572864321608e-05,
      "loss": 0.0,
      "step": 12870
    },
    {
      "epoch": 0.46693735498839906,
      "grad_norm": 0.0,
      "learning_rate": 1.7889447236180908e-05,
      "loss": 0.4384,
      "step": 12880
    },
    {
      "epoch": 0.46729988399071926,
      "grad_norm": 0.0,
      "learning_rate": 1.78643216080402e-05,
      "loss": 1.869,
      "step": 12890
    },
    {
      "epoch": 0.46766241299303946,
      "grad_norm": 0.0,
      "learning_rate": 1.7839195979899497e-05,
      "loss": 0.2012,
      "step": 12900
    },
    {
      "epoch": 0.46802494199535966,
      "grad_norm": 0.47150623299310734,
      "learning_rate": 1.7814070351758794e-05,
      "loss": 0.4775,
      "step": 12910
    },
    {
      "epoch": 0.4683874709976798,
      "grad_norm": 0.0,
      "learning_rate": 1.778894472361809e-05,
      "loss": 0.0694,
      "step": 12920
    },
    {
      "epoch": 0.46875,
      "grad_norm": 0.0,
      "learning_rate": 1.7763819095477387e-05,
      "loss": 0.1257,
      "step": 12930
    },
    {
      "epoch": 0.4691125290023202,
      "grad_norm": 0.0,
      "learning_rate": 1.7738693467336684e-05,
      "loss": 0.0533,
      "step": 12940
    },
    {
      "epoch": 0.46947505800464034,
      "grad_norm": 0.0,
      "learning_rate": 1.771356783919598e-05,
      "loss": 0.006,
      "step": 12950
    },
    {
      "epoch": 0.46983758700696054,
      "grad_norm": 0.0,
      "learning_rate": 1.7688442211055277e-05,
      "loss": 0.8841,
      "step": 12960
    },
    {
      "epoch": 0.47020011600928074,
      "grad_norm": 0.0,
      "learning_rate": 1.7663316582914574e-05,
      "loss": 0.008,
      "step": 12970
    },
    {
      "epoch": 0.47056264501160094,
      "grad_norm": 0.0,
      "learning_rate": 1.763819095477387e-05,
      "loss": 0.7154,
      "step": 12980
    },
    {
      "epoch": 0.4709251740139211,
      "grad_norm": 1.333636751023578,
      "learning_rate": 1.7613065326633167e-05,
      "loss": 0.5038,
      "step": 12990
    },
    {
      "epoch": 0.4712877030162413,
      "grad_norm": 28.609476336180443,
      "learning_rate": 1.7587939698492464e-05,
      "loss": 0.2711,
      "step": 13000
    },
    {
      "epoch": 0.4712877030162413,
      "eval_loss": NaN,
      "eval_runtime": 74.3407,
      "eval_samples_per_second": 8.569,
      "eval_steps_per_second": 1.439,
      "step": 13000
    },
    {
      "epoch": 0.4716502320185615,
      "grad_norm": 0.0,
      "learning_rate": 1.756281407035176e-05,
      "loss": 0.0822,
      "step": 13010
    },
    {
      "epoch": 0.4720127610208817,
      "grad_norm": 0.4900233509864072,
      "learning_rate": 1.7537688442211057e-05,
      "loss": 0.3011,
      "step": 13020
    },
    {
      "epoch": 0.47237529002320183,
      "grad_norm": 0.0,
      "learning_rate": 1.751256281407035e-05,
      "loss": 0.6167,
      "step": 13030
    },
    {
      "epoch": 0.47273781902552203,
      "grad_norm": 0.0,
      "learning_rate": 1.748743718592965e-05,
      "loss": 0.0016,
      "step": 13040
    },
    {
      "epoch": 0.47310034802784223,
      "grad_norm": 16.480411808831473,
      "learning_rate": 1.7462311557788947e-05,
      "loss": 0.8771,
      "step": 13050
    },
    {
      "epoch": 0.47346287703016243,
      "grad_norm": 0.0,
      "learning_rate": 1.7437185929648243e-05,
      "loss": 0.0,
      "step": 13060
    },
    {
      "epoch": 0.4738254060324826,
      "grad_norm": 0.0,
      "learning_rate": 1.7412060301507537e-05,
      "loss": 0.0076,
      "step": 13070
    },
    {
      "epoch": 0.4741879350348028,
      "grad_norm": 1.4116643729448355,
      "learning_rate": 1.7386934673366833e-05,
      "loss": 0.0073,
      "step": 13080
    },
    {
      "epoch": 0.474550464037123,
      "grad_norm": 0.0,
      "learning_rate": 1.7361809045226133e-05,
      "loss": 0.0967,
      "step": 13090
    },
    {
      "epoch": 0.4749129930394432,
      "grad_norm": 0.0,
      "learning_rate": 1.7336683417085427e-05,
      "loss": 0.7475,
      "step": 13100
    },
    {
      "epoch": 0.4752755220417633,
      "grad_norm": 0.0,
      "learning_rate": 1.7311557788944723e-05,
      "loss": 0.3595,
      "step": 13110
    },
    {
      "epoch": 0.4756380510440835,
      "grad_norm": 0.0,
      "learning_rate": 1.728643216080402e-05,
      "loss": 0.0013,
      "step": 13120
    },
    {
      "epoch": 0.4760005800464037,
      "grad_norm": 58.120513939787216,
      "learning_rate": 1.726130653266332e-05,
      "loss": 1.4269,
      "step": 13130
    },
    {
      "epoch": 0.4763631090487239,
      "grad_norm": 0.0,
      "learning_rate": 1.7236180904522613e-05,
      "loss": 0.2108,
      "step": 13140
    },
    {
      "epoch": 0.47672563805104406,
      "grad_norm": 0.031130610144900515,
      "learning_rate": 1.721105527638191e-05,
      "loss": 0.3244,
      "step": 13150
    },
    {
      "epoch": 0.47708816705336426,
      "grad_norm": 0.0,
      "learning_rate": 1.7185929648241206e-05,
      "loss": 0.8577,
      "step": 13160
    },
    {
      "epoch": 0.47745069605568446,
      "grad_norm": 0.7984520136340846,
      "learning_rate": 1.7160804020100503e-05,
      "loss": 0.1631,
      "step": 13170
    },
    {
      "epoch": 0.47781322505800466,
      "grad_norm": 0.0,
      "learning_rate": 1.71356783919598e-05,
      "loss": 0.2813,
      "step": 13180
    },
    {
      "epoch": 0.4781757540603248,
      "grad_norm": 0.0,
      "learning_rate": 1.7110552763819096e-05,
      "loss": 0.0037,
      "step": 13190
    },
    {
      "epoch": 0.478538283062645,
      "grad_norm": 0.0,
      "learning_rate": 1.7085427135678393e-05,
      "loss": 0.0025,
      "step": 13200
    },
    {
      "epoch": 0.4789008120649652,
      "grad_norm": 0.0,
      "learning_rate": 1.706030150753769e-05,
      "loss": 1.6789,
      "step": 13210
    },
    {
      "epoch": 0.4792633410672854,
      "grad_norm": 52.29906441488103,
      "learning_rate": 1.7035175879396986e-05,
      "loss": 0.7391,
      "step": 13220
    },
    {
      "epoch": 0.47962587006960555,
      "grad_norm": 0.0,
      "learning_rate": 1.7010050251256283e-05,
      "loss": 0.3237,
      "step": 13230
    },
    {
      "epoch": 0.47998839907192575,
      "grad_norm": 0.0,
      "learning_rate": 1.698492462311558e-05,
      "loss": 0.0653,
      "step": 13240
    },
    {
      "epoch": 0.48035092807424595,
      "grad_norm": 21.138582276125597,
      "learning_rate": 1.6959798994974876e-05,
      "loss": 0.7482,
      "step": 13250
    },
    {
      "epoch": 0.48071345707656615,
      "grad_norm": 0.28688153159740487,
      "learning_rate": 1.6934673366834172e-05,
      "loss": 0.3447,
      "step": 13260
    },
    {
      "epoch": 0.4810759860788863,
      "grad_norm": 0.0,
      "learning_rate": 1.690954773869347e-05,
      "loss": 1.2458,
      "step": 13270
    },
    {
      "epoch": 0.4814385150812065,
      "grad_norm": 0.0,
      "learning_rate": 1.6884422110552762e-05,
      "loss": 0.0796,
      "step": 13280
    },
    {
      "epoch": 0.4818010440835267,
      "grad_norm": 0.0,
      "learning_rate": 1.685929648241206e-05,
      "loss": 0.5995,
      "step": 13290
    },
    {
      "epoch": 0.48216357308584684,
      "grad_norm": 0.0,
      "learning_rate": 1.683417085427136e-05,
      "loss": 1.0738,
      "step": 13300
    },
    {
      "epoch": 0.48252610208816704,
      "grad_norm": 0.0,
      "learning_rate": 1.6809045226130656e-05,
      "loss": 0.1845,
      "step": 13310
    },
    {
      "epoch": 0.48288863109048724,
      "grad_norm": 0.0,
      "learning_rate": 1.678391959798995e-05,
      "loss": 1.4179,
      "step": 13320
    },
    {
      "epoch": 0.48325116009280744,
      "grad_norm": 0.0,
      "learning_rate": 1.6758793969849245e-05,
      "loss": 0.597,
      "step": 13330
    },
    {
      "epoch": 0.4836136890951276,
      "grad_norm": 0.0,
      "learning_rate": 1.6733668341708545e-05,
      "loss": 0.1647,
      "step": 13340
    },
    {
      "epoch": 0.4839762180974478,
      "grad_norm": 0.17932156951653846,
      "learning_rate": 1.670854271356784e-05,
      "loss": 0.2543,
      "step": 13350
    },
    {
      "epoch": 0.484338747099768,
      "grad_norm": 0.0,
      "learning_rate": 1.6683417085427135e-05,
      "loss": 0.2334,
      "step": 13360
    },
    {
      "epoch": 0.4847012761020882,
      "grad_norm": 0.0,
      "learning_rate": 1.6658291457286432e-05,
      "loss": 0.4633,
      "step": 13370
    },
    {
      "epoch": 0.48506380510440833,
      "grad_norm": 0.0,
      "learning_rate": 1.6633165829145732e-05,
      "loss": 0.177,
      "step": 13380
    },
    {
      "epoch": 0.48542633410672853,
      "grad_norm": 0.15550557064729634,
      "learning_rate": 1.6608040201005025e-05,
      "loss": 0.3908,
      "step": 13390
    },
    {
      "epoch": 0.48578886310904873,
      "grad_norm": 0.0,
      "learning_rate": 1.6582914572864322e-05,
      "loss": 0.4724,
      "step": 13400
    },
    {
      "epoch": 0.48615139211136893,
      "grad_norm": 0.0,
      "learning_rate": 1.655778894472362e-05,
      "loss": 1.3867,
      "step": 13410
    },
    {
      "epoch": 0.4865139211136891,
      "grad_norm": 0.0,
      "learning_rate": 1.6532663316582915e-05,
      "loss": 0.6245,
      "step": 13420
    },
    {
      "epoch": 0.4868764501160093,
      "grad_norm": 0.0,
      "learning_rate": 1.650753768844221e-05,
      "loss": 0.0417,
      "step": 13430
    },
    {
      "epoch": 0.4872389791183295,
      "grad_norm": 0.0,
      "learning_rate": 1.6482412060301508e-05,
      "loss": 0.2423,
      "step": 13440
    },
    {
      "epoch": 0.4876015081206497,
      "grad_norm": 0.0,
      "learning_rate": 1.6457286432160805e-05,
      "loss": 0.2256,
      "step": 13450
    },
    {
      "epoch": 0.4879640371229698,
      "grad_norm": 0.0,
      "learning_rate": 1.64321608040201e-05,
      "loss": 1.1986,
      "step": 13460
    },
    {
      "epoch": 0.48832656612529,
      "grad_norm": 8.799420545747202,
      "learning_rate": 1.6407035175879398e-05,
      "loss": 1.315,
      "step": 13470
    },
    {
      "epoch": 0.4886890951276102,
      "grad_norm": 0.0,
      "learning_rate": 1.6381909547738695e-05,
      "loss": 0.1632,
      "step": 13480
    },
    {
      "epoch": 0.4890516241299304,
      "grad_norm": 0.0,
      "learning_rate": 1.635678391959799e-05,
      "loss": 0.6796,
      "step": 13490
    },
    {
      "epoch": 0.48941415313225056,
      "grad_norm": 36.52525313000496,
      "learning_rate": 1.6331658291457288e-05,
      "loss": 0.4578,
      "step": 13500
    },
    {
      "epoch": 0.48941415313225056,
      "eval_loss": NaN,
      "eval_runtime": 73.4377,
      "eval_samples_per_second": 8.674,
      "eval_steps_per_second": 1.457,
      "step": 13500
    },
    {
      "epoch": 0.48977668213457076,
      "grad_norm": 0.0,
      "learning_rate": 1.6306532663316585e-05,
      "loss": 0.1956,
      "step": 13510
    },
    {
      "epoch": 0.49013921113689096,
      "grad_norm": 0.0,
      "learning_rate": 1.628140703517588e-05,
      "loss": 0.1294,
      "step": 13520
    },
    {
      "epoch": 0.49050174013921116,
      "grad_norm": 0.057945363469671676,
      "learning_rate": 1.6256281407035174e-05,
      "loss": 0.4345,
      "step": 13530
    },
    {
      "epoch": 0.4908642691415313,
      "grad_norm": 0.0,
      "learning_rate": 1.623115577889447e-05,
      "loss": 0.5678,
      "step": 13540
    },
    {
      "epoch": 0.4912267981438515,
      "grad_norm": 1.6448019715514408,
      "learning_rate": 1.620603015075377e-05,
      "loss": 0.0864,
      "step": 13550
    },
    {
      "epoch": 0.4915893271461717,
      "grad_norm": 0.0,
      "learning_rate": 1.6180904522613068e-05,
      "loss": 1.0764,
      "step": 13560
    },
    {
      "epoch": 0.4919518561484919,
      "grad_norm": 0.0,
      "learning_rate": 1.615577889447236e-05,
      "loss": 0.1372,
      "step": 13570
    },
    {
      "epoch": 0.49231438515081205,
      "grad_norm": 34.37193700842211,
      "learning_rate": 1.6130653266331658e-05,
      "loss": 0.4341,
      "step": 13580
    },
    {
      "epoch": 0.49267691415313225,
      "grad_norm": 0.0,
      "learning_rate": 1.6105527638190958e-05,
      "loss": 0.6028,
      "step": 13590
    },
    {
      "epoch": 0.49303944315545245,
      "grad_norm": 0.0,
      "learning_rate": 1.608040201005025e-05,
      "loss": 0.2316,
      "step": 13600
    },
    {
      "epoch": 0.4934019721577726,
      "grad_norm": 36.49272187710859,
      "learning_rate": 1.6055276381909547e-05,
      "loss": 0.4343,
      "step": 13610
    },
    {
      "epoch": 0.4937645011600928,
      "grad_norm": 0.0,
      "learning_rate": 1.6030150753768844e-05,
      "loss": 0.1101,
      "step": 13620
    },
    {
      "epoch": 0.494127030162413,
      "grad_norm": 0.0,
      "learning_rate": 1.6005025125628144e-05,
      "loss": 0.1879,
      "step": 13630
    },
    {
      "epoch": 0.4944895591647332,
      "grad_norm": 33.18283387336271,
      "learning_rate": 1.5979899497487437e-05,
      "loss": 1.1115,
      "step": 13640
    },
    {
      "epoch": 0.49485208816705334,
      "grad_norm": 0.0,
      "learning_rate": 1.5954773869346734e-05,
      "loss": 0.1786,
      "step": 13650
    },
    {
      "epoch": 0.49521461716937354,
      "grad_norm": 5.311766629929722,
      "learning_rate": 1.592964824120603e-05,
      "loss": 0.2672,
      "step": 13660
    },
    {
      "epoch": 0.49557714617169374,
      "grad_norm": 0.0,
      "learning_rate": 1.5904522613065327e-05,
      "loss": 0.0444,
      "step": 13670
    },
    {
      "epoch": 0.49593967517401394,
      "grad_norm": 0.0,
      "learning_rate": 1.5879396984924624e-05,
      "loss": 0.1428,
      "step": 13680
    },
    {
      "epoch": 0.4963022041763341,
      "grad_norm": 0.0,
      "learning_rate": 1.585427135678392e-05,
      "loss": 0.3802,
      "step": 13690
    },
    {
      "epoch": 0.4966647331786543,
      "grad_norm": 0.0,
      "learning_rate": 1.5829145728643217e-05,
      "loss": 0.6166,
      "step": 13700
    },
    {
      "epoch": 0.4970272621809745,
      "grad_norm": 0.18078862612883345,
      "learning_rate": 1.5804020100502514e-05,
      "loss": 0.1112,
      "step": 13710
    },
    {
      "epoch": 0.4973897911832947,
      "grad_norm": 0.0,
      "learning_rate": 1.577889447236181e-05,
      "loss": 0.1935,
      "step": 13720
    },
    {
      "epoch": 0.4977523201856148,
      "grad_norm": 0.0,
      "learning_rate": 1.5753768844221107e-05,
      "loss": 0.6239,
      "step": 13730
    },
    {
      "epoch": 0.498114849187935,
      "grad_norm": 0.0,
      "learning_rate": 1.5728643216080403e-05,
      "loss": 0.0949,
      "step": 13740
    },
    {
      "epoch": 0.4984773781902552,
      "grad_norm": 0.0,
      "learning_rate": 1.57035175879397e-05,
      "loss": 0.6097,
      "step": 13750
    },
    {
      "epoch": 0.4988399071925754,
      "grad_norm": 0.0,
      "learning_rate": 1.5678391959798997e-05,
      "loss": 0.3328,
      "step": 13760
    },
    {
      "epoch": 0.49920243619489557,
      "grad_norm": 0.0,
      "learning_rate": 1.5653266331658293e-05,
      "loss": 0.3126,
      "step": 13770
    },
    {
      "epoch": 0.49956496519721577,
      "grad_norm": 0.0,
      "learning_rate": 1.5628140703517587e-05,
      "loss": 0.2524,
      "step": 13780
    },
    {
      "epoch": 0.49992749419953597,
      "grad_norm": 0.0,
      "learning_rate": 1.5603015075376883e-05,
      "loss": 0.2984,
      "step": 13790
    },
    {
      "epoch": 0.5002900232018561,
      "grad_norm": 0.0,
      "learning_rate": 1.5577889447236183e-05,
      "loss": 0.9774,
      "step": 13800
    },
    {
      "epoch": 0.5006525522041764,
      "grad_norm": 0.0,
      "learning_rate": 1.555276381909548e-05,
      "loss": 0.5328,
      "step": 13810
    },
    {
      "epoch": 0.5010150812064965,
      "grad_norm": 0.0,
      "learning_rate": 1.5527638190954773e-05,
      "loss": 0.2251,
      "step": 13820
    },
    {
      "epoch": 0.5013776102088167,
      "grad_norm": 3.2949082714041937,
      "learning_rate": 1.550251256281407e-05,
      "loss": 1.5498,
      "step": 13830
    },
    {
      "epoch": 0.5017401392111369,
      "grad_norm": 0.0,
      "learning_rate": 1.547738693467337e-05,
      "loss": 0.6665,
      "step": 13840
    },
    {
      "epoch": 0.5021026682134571,
      "grad_norm": 0.0,
      "learning_rate": 1.5452261306532663e-05,
      "loss": 0.5144,
      "step": 13850
    },
    {
      "epoch": 0.5024651972157773,
      "grad_norm": 0.0,
      "learning_rate": 1.542713567839196e-05,
      "loss": 0.0136,
      "step": 13860
    },
    {
      "epoch": 0.5028277262180975,
      "grad_norm": 0.0,
      "learning_rate": 1.5402010050251256e-05,
      "loss": 0.001,
      "step": 13870
    },
    {
      "epoch": 0.5031902552204176,
      "grad_norm": 0.0,
      "learning_rate": 1.5376884422110556e-05,
      "loss": 0.3968,
      "step": 13880
    },
    {
      "epoch": 0.5035527842227379,
      "grad_norm": 0.0,
      "learning_rate": 1.535175879396985e-05,
      "loss": 1.062,
      "step": 13890
    },
    {
      "epoch": 0.503915313225058,
      "grad_norm": 0.0,
      "learning_rate": 1.5326633165829146e-05,
      "loss": 0.3872,
      "step": 13900
    },
    {
      "epoch": 0.5042778422273781,
      "grad_norm": 16.375736132666486,
      "learning_rate": 1.5301507537688443e-05,
      "loss": 0.4067,
      "step": 13910
    },
    {
      "epoch": 0.5046403712296984,
      "grad_norm": 0.0,
      "learning_rate": 1.527638190954774e-05,
      "loss": 0.4135,
      "step": 13920
    },
    {
      "epoch": 0.5050029002320185,
      "grad_norm": 0.0,
      "learning_rate": 1.5251256281407036e-05,
      "loss": 0.2688,
      "step": 13930
    },
    {
      "epoch": 0.5053654292343387,
      "grad_norm": 0.0,
      "learning_rate": 1.5226130653266332e-05,
      "loss": 0.3767,
      "step": 13940
    },
    {
      "epoch": 0.505727958236659,
      "grad_norm": 0.0,
      "learning_rate": 1.5201005025125627e-05,
      "loss": 0.6383,
      "step": 13950
    },
    {
      "epoch": 0.5060904872389791,
      "grad_norm": 5.013201261633971,
      "learning_rate": 1.5175879396984927e-05,
      "loss": 0.3623,
      "step": 13960
    },
    {
      "epoch": 0.5064530162412993,
      "grad_norm": 0.0,
      "learning_rate": 1.5150753768844222e-05,
      "loss": 0.3492,
      "step": 13970
    },
    {
      "epoch": 0.5068155452436195,
      "grad_norm": 0.21763528624310247,
      "learning_rate": 1.5125628140703519e-05,
      "loss": 0.4117,
      "step": 13980
    },
    {
      "epoch": 0.5071780742459396,
      "grad_norm": 0.0,
      "learning_rate": 1.5100502512562814e-05,
      "loss": 0.2485,
      "step": 13990
    },
    {
      "epoch": 0.5075406032482599,
      "grad_norm": 0.0,
      "learning_rate": 1.507537688442211e-05,
      "loss": 0.8872,
      "step": 14000
    },
    {
      "epoch": 0.5075406032482599,
      "eval_loss": NaN,
      "eval_runtime": 81.7333,
      "eval_samples_per_second": 7.794,
      "eval_steps_per_second": 1.309,
      "step": 14000
    },
    {
      "epoch": 0.50790313225058,
      "grad_norm": 39.61180804904092,
      "learning_rate": 1.5050251256281409e-05,
      "loss": 0.4141,
      "step": 14010
    },
    {
      "epoch": 0.5082656612529002,
      "grad_norm": 0.0,
      "learning_rate": 1.5025125628140704e-05,
      "loss": 0.2983,
      "step": 14020
    },
    {
      "epoch": 0.5086281902552204,
      "grad_norm": 15.456052928983993,
      "learning_rate": 1.5e-05,
      "loss": 1.2628,
      "step": 14030
    },
    {
      "epoch": 0.5089907192575406,
      "grad_norm": 0.0,
      "learning_rate": 1.4974874371859295e-05,
      "loss": 0.2176,
      "step": 14040
    },
    {
      "epoch": 0.5093532482598608,
      "grad_norm": 7.3072691899173945,
      "learning_rate": 1.4949748743718595e-05,
      "loss": 0.4845,
      "step": 14050
    },
    {
      "epoch": 0.509715777262181,
      "grad_norm": 0.0,
      "learning_rate": 1.492462311557789e-05,
      "loss": 0.1347,
      "step": 14060
    },
    {
      "epoch": 0.5100783062645011,
      "grad_norm": 0.0,
      "learning_rate": 1.4899497487437187e-05,
      "loss": 0.4034,
      "step": 14070
    },
    {
      "epoch": 0.5104408352668214,
      "grad_norm": 0.0,
      "learning_rate": 1.4874371859296482e-05,
      "loss": 0.1042,
      "step": 14080
    },
    {
      "epoch": 0.5108033642691415,
      "grad_norm": 6.647958381862258,
      "learning_rate": 1.484924623115578e-05,
      "loss": 2.0191,
      "step": 14090
    },
    {
      "epoch": 0.5111658932714617,
      "grad_norm": 45.63952572709044,
      "learning_rate": 1.4824120603015077e-05,
      "loss": 0.1707,
      "step": 14100
    },
    {
      "epoch": 0.5115284222737819,
      "grad_norm": 0.0,
      "learning_rate": 1.4798994974874372e-05,
      "loss": 0.006,
      "step": 14110
    },
    {
      "epoch": 0.5118909512761021,
      "grad_norm": 6.01004268688206,
      "learning_rate": 1.4773869346733668e-05,
      "loss": 1.0982,
      "step": 14120
    },
    {
      "epoch": 0.5122534802784223,
      "grad_norm": 0.0,
      "learning_rate": 1.4748743718592967e-05,
      "loss": 0.0664,
      "step": 14130
    },
    {
      "epoch": 0.5126160092807425,
      "grad_norm": 0.0,
      "learning_rate": 1.4723618090452263e-05,
      "loss": 0.0074,
      "step": 14140
    },
    {
      "epoch": 0.5129785382830626,
      "grad_norm": 0.0,
      "learning_rate": 1.4698492462311558e-05,
      "loss": 0.2334,
      "step": 14150
    },
    {
      "epoch": 0.5133410672853829,
      "grad_norm": 23.827946976794,
      "learning_rate": 1.4673366834170855e-05,
      "loss": 0.6425,
      "step": 14160
    },
    {
      "epoch": 0.513703596287703,
      "grad_norm": 0.9134801003659007,
      "learning_rate": 1.4648241206030153e-05,
      "loss": 0.2776,
      "step": 14170
    },
    {
      "epoch": 0.5140661252900232,
      "grad_norm": 0.0,
      "learning_rate": 1.4623115577889448e-05,
      "loss": 1.0908,
      "step": 14180
    },
    {
      "epoch": 0.5144286542923434,
      "grad_norm": 0.8297420045582952,
      "learning_rate": 1.4597989949748745e-05,
      "loss": 0.6211,
      "step": 14190
    },
    {
      "epoch": 0.5147911832946636,
      "grad_norm": 250.94122039583294,
      "learning_rate": 1.457286432160804e-05,
      "loss": 0.9188,
      "step": 14200
    },
    {
      "epoch": 0.5151537122969838,
      "grad_norm": 0.0,
      "learning_rate": 1.454773869346734e-05,
      "loss": 0.0884,
      "step": 14210
    },
    {
      "epoch": 0.515516241299304,
      "grad_norm": 1.5435052252935275,
      "learning_rate": 1.4522613065326634e-05,
      "loss": 0.5949,
      "step": 14220
    },
    {
      "epoch": 0.5158787703016241,
      "grad_norm": 0.0,
      "learning_rate": 1.4497487437185931e-05,
      "loss": 0.4039,
      "step": 14230
    },
    {
      "epoch": 0.5162412993039444,
      "grad_norm": 0.0,
      "learning_rate": 1.4472361809045226e-05,
      "loss": 0.8221,
      "step": 14240
    },
    {
      "epoch": 0.5166038283062645,
      "grad_norm": 0.0,
      "learning_rate": 1.4447236180904523e-05,
      "loss": 0.2534,
      "step": 14250
    },
    {
      "epoch": 0.5169663573085846,
      "grad_norm": 33.19753261727443,
      "learning_rate": 1.4422110552763821e-05,
      "loss": 0.5098,
      "step": 14260
    },
    {
      "epoch": 0.5173288863109049,
      "grad_norm": 0.3399954709284321,
      "learning_rate": 1.4396984924623116e-05,
      "loss": 0.1003,
      "step": 14270
    },
    {
      "epoch": 0.517691415313225,
      "grad_norm": 0.0,
      "learning_rate": 1.4371859296482413e-05,
      "loss": 0.3149,
      "step": 14280
    },
    {
      "epoch": 0.5180539443155452,
      "grad_norm": 0.0,
      "learning_rate": 1.4346733668341707e-05,
      "loss": 0.3627,
      "step": 14290
    },
    {
      "epoch": 0.5184164733178654,
      "grad_norm": 0.0,
      "learning_rate": 1.4321608040201007e-05,
      "loss": 1.1499,
      "step": 14300
    },
    {
      "epoch": 0.5187790023201856,
      "grad_norm": 0.0,
      "learning_rate": 1.4296482412060302e-05,
      "loss": 0.4843,
      "step": 14310
    },
    {
      "epoch": 0.5191415313225058,
      "grad_norm": 9.080800907926267,
      "learning_rate": 1.4271356783919599e-05,
      "loss": 0.8814,
      "step": 14320
    },
    {
      "epoch": 0.519504060324826,
      "grad_norm": 0.0,
      "learning_rate": 1.4246231155778894e-05,
      "loss": 0.7219,
      "step": 14330
    },
    {
      "epoch": 0.5198665893271461,
      "grad_norm": 0.0,
      "learning_rate": 1.4221105527638192e-05,
      "loss": 0.2681,
      "step": 14340
    },
    {
      "epoch": 0.5202291183294664,
      "grad_norm": 0.0,
      "learning_rate": 1.4195979899497489e-05,
      "loss": 0.139,
      "step": 14350
    },
    {
      "epoch": 0.5205916473317865,
      "grad_norm": 0.0,
      "learning_rate": 1.4170854271356784e-05,
      "loss": 0.4061,
      "step": 14360
    },
    {
      "epoch": 0.5209541763341067,
      "grad_norm": 0.0,
      "learning_rate": 1.414572864321608e-05,
      "loss": 0.0,
      "step": 14370
    },
    {
      "epoch": 0.5213167053364269,
      "grad_norm": 0.0,
      "learning_rate": 1.4120603015075379e-05,
      "loss": 1.6939,
      "step": 14380
    },
    {
      "epoch": 0.5216792343387471,
      "grad_norm": 26.187568755503417,
      "learning_rate": 1.4095477386934675e-05,
      "loss": 0.0822,
      "step": 14390
    },
    {
      "epoch": 0.5220417633410673,
      "grad_norm": 0.644994372816453,
      "learning_rate": 1.407035175879397e-05,
      "loss": 0.1448,
      "step": 14400
    },
    {
      "epoch": 0.5224042923433875,
      "grad_norm": 0.0,
      "learning_rate": 1.4045226130653267e-05,
      "loss": 0.5307,
      "step": 14410
    },
    {
      "epoch": 0.5227668213457076,
      "grad_norm": 0.0,
      "learning_rate": 1.4020100502512565e-05,
      "loss": 0.6655,
      "step": 14420
    },
    {
      "epoch": 0.5231293503480279,
      "grad_norm": 0.0,
      "learning_rate": 1.399497487437186e-05,
      "loss": 0.1986,
      "step": 14430
    },
    {
      "epoch": 0.523491879350348,
      "grad_norm": 30.884687008314696,
      "learning_rate": 1.3969849246231157e-05,
      "loss": 0.2854,
      "step": 14440
    },
    {
      "epoch": 0.5238544083526682,
      "grad_norm": 0.0,
      "learning_rate": 1.3944723618090452e-05,
      "loss": 0.2211,
      "step": 14450
    },
    {
      "epoch": 0.5242169373549884,
      "grad_norm": 0.2009641074426021,
      "learning_rate": 1.3919597989949748e-05,
      "loss": 0.1707,
      "step": 14460
    },
    {
      "epoch": 0.5245794663573086,
      "grad_norm": 2.1487743876495164,
      "learning_rate": 1.3894472361809047e-05,
      "loss": 0.242,
      "step": 14470
    },
    {
      "epoch": 0.5249419953596288,
      "grad_norm": 22.185453250666303,
      "learning_rate": 1.3869346733668343e-05,
      "loss": 0.6098,
      "step": 14480
    },
    {
      "epoch": 0.525304524361949,
      "grad_norm": 0.3434700367677589,
      "learning_rate": 1.3844221105527638e-05,
      "loss": 0.0963,
      "step": 14490
    },
    {
      "epoch": 0.5256670533642691,
      "grad_norm": 0.0,
      "learning_rate": 1.3819095477386935e-05,
      "loss": 0.231,
      "step": 14500
    },
    {
      "epoch": 0.5256670533642691,
      "eval_loss": NaN,
      "eval_runtime": 80.5579,
      "eval_samples_per_second": 7.907,
      "eval_steps_per_second": 1.328,
      "step": 14500
    },
    {
      "epoch": 0.5260295823665894,
      "grad_norm": 6.774368662116321,
      "learning_rate": 1.3793969849246233e-05,
      "loss": 0.3458,
      "step": 14510
    },
    {
      "epoch": 0.5263921113689095,
      "grad_norm": 0.0,
      "learning_rate": 1.3768844221105528e-05,
      "loss": 0.2429,
      "step": 14520
    },
    {
      "epoch": 0.5267546403712297,
      "grad_norm": 0.0,
      "learning_rate": 1.3743718592964825e-05,
      "loss": 0.4168,
      "step": 14530
    },
    {
      "epoch": 0.5271171693735499,
      "grad_norm": 0.0,
      "learning_rate": 1.371859296482412e-05,
      "loss": 0.8368,
      "step": 14540
    },
    {
      "epoch": 0.52747969837587,
      "grad_norm": 0.0,
      "learning_rate": 1.369346733668342e-05,
      "loss": 1.3079,
      "step": 14550
    },
    {
      "epoch": 0.5278422273781903,
      "grad_norm": 0.1269493689348207,
      "learning_rate": 1.3668341708542715e-05,
      "loss": 0.4007,
      "step": 14560
    },
    {
      "epoch": 0.5282047563805105,
      "grad_norm": 0.0,
      "learning_rate": 1.3643216080402011e-05,
      "loss": 0.1447,
      "step": 14570
    },
    {
      "epoch": 0.5285672853828306,
      "grad_norm": 0.0,
      "learning_rate": 1.3618090452261306e-05,
      "loss": 0.0117,
      "step": 14580
    },
    {
      "epoch": 0.5289298143851509,
      "grad_norm": 0.0,
      "learning_rate": 1.3592964824120604e-05,
      "loss": 0.3373,
      "step": 14590
    },
    {
      "epoch": 0.529292343387471,
      "grad_norm": 29.04079855921719,
      "learning_rate": 1.3567839195979901e-05,
      "loss": 0.279,
      "step": 14600
    },
    {
      "epoch": 0.5296548723897911,
      "grad_norm": 0.0,
      "learning_rate": 1.3542713567839196e-05,
      "loss": 0.4585,
      "step": 14610
    },
    {
      "epoch": 0.5300174013921114,
      "grad_norm": 0.0,
      "learning_rate": 1.3517587939698493e-05,
      "loss": 0.096,
      "step": 14620
    },
    {
      "epoch": 0.5303799303944315,
      "grad_norm": 17.375512863384063,
      "learning_rate": 1.3492462311557791e-05,
      "loss": 0.4755,
      "step": 14630
    },
    {
      "epoch": 0.5307424593967517,
      "grad_norm": 0.2878439970312569,
      "learning_rate": 1.3467336683417087e-05,
      "loss": 0.3567,
      "step": 14640
    },
    {
      "epoch": 0.5311049883990719,
      "grad_norm": 0.0,
      "learning_rate": 1.3442211055276382e-05,
      "loss": 0.068,
      "step": 14650
    },
    {
      "epoch": 0.5314675174013921,
      "grad_norm": 0.0,
      "learning_rate": 1.3417085427135679e-05,
      "loss": 1.3221,
      "step": 14660
    },
    {
      "epoch": 0.5318300464037123,
      "grad_norm": 0.0,
      "learning_rate": 1.3391959798994977e-05,
      "loss": 0.1514,
      "step": 14670
    },
    {
      "epoch": 0.5321925754060325,
      "grad_norm": 0.0,
      "learning_rate": 1.3366834170854272e-05,
      "loss": 0.2378,
      "step": 14680
    },
    {
      "epoch": 0.5325551044083526,
      "grad_norm": 9.655193184609457,
      "learning_rate": 1.3341708542713569e-05,
      "loss": 0.09,
      "step": 14690
    },
    {
      "epoch": 0.5329176334106729,
      "grad_norm": 0.0,
      "learning_rate": 1.3316582914572864e-05,
      "loss": 0.9124,
      "step": 14700
    },
    {
      "epoch": 0.533280162412993,
      "grad_norm": 0.0,
      "learning_rate": 1.329145728643216e-05,
      "loss": 0.3639,
      "step": 14710
    },
    {
      "epoch": 0.5336426914153132,
      "grad_norm": 0.0,
      "learning_rate": 1.3266331658291459e-05,
      "loss": 0.0989,
      "step": 14720
    },
    {
      "epoch": 0.5340052204176334,
      "grad_norm": 14.445459326930925,
      "learning_rate": 1.3241206030150755e-05,
      "loss": 0.1759,
      "step": 14730
    },
    {
      "epoch": 0.5343677494199536,
      "grad_norm": 0.0,
      "learning_rate": 1.321608040201005e-05,
      "loss": 0.0484,
      "step": 14740
    },
    {
      "epoch": 0.5347302784222738,
      "grad_norm": 0.0,
      "learning_rate": 1.3190954773869347e-05,
      "loss": 0.0024,
      "step": 14750
    },
    {
      "epoch": 0.535092807424594,
      "grad_norm": 0.0,
      "learning_rate": 1.3165829145728645e-05,
      "loss": 0.4311,
      "step": 14760
    },
    {
      "epoch": 0.5354553364269141,
      "grad_norm": 0.0,
      "learning_rate": 1.314070351758794e-05,
      "loss": 0.0786,
      "step": 14770
    },
    {
      "epoch": 0.5358178654292344,
      "grad_norm": 51.315554491913076,
      "learning_rate": 1.3115577889447237e-05,
      "loss": 0.7791,
      "step": 14780
    },
    {
      "epoch": 0.5361803944315545,
      "grad_norm": 0.0,
      "learning_rate": 1.3090452261306532e-05,
      "loss": 0.193,
      "step": 14790
    },
    {
      "epoch": 0.5365429234338747,
      "grad_norm": 6.952228479772579,
      "learning_rate": 1.306532663316583e-05,
      "loss": 0.2002,
      "step": 14800
    },
    {
      "epoch": 0.5369054524361949,
      "grad_norm": 0.06206116432164915,
      "learning_rate": 1.3040201005025127e-05,
      "loss": 0.0002,
      "step": 14810
    },
    {
      "epoch": 0.5372679814385151,
      "grad_norm": 0.0,
      "learning_rate": 1.3015075376884423e-05,
      "loss": 0.45,
      "step": 14820
    },
    {
      "epoch": 0.5376305104408353,
      "grad_norm": 0.0,
      "learning_rate": 1.2989949748743718e-05,
      "loss": 0.3801,
      "step": 14830
    },
    {
      "epoch": 0.5379930394431555,
      "grad_norm": 0.0,
      "learning_rate": 1.2964824120603017e-05,
      "loss": 0.4021,
      "step": 14840
    },
    {
      "epoch": 0.5383555684454756,
      "grad_norm": 0.5689470850939495,
      "learning_rate": 1.2939698492462313e-05,
      "loss": 0.7879,
      "step": 14850
    },
    {
      "epoch": 0.5387180974477959,
      "grad_norm": 0.0,
      "learning_rate": 1.2914572864321608e-05,
      "loss": 0.3757,
      "step": 14860
    },
    {
      "epoch": 0.539080626450116,
      "grad_norm": 25.089838580588754,
      "learning_rate": 1.2889447236180905e-05,
      "loss": 0.7296,
      "step": 14870
    },
    {
      "epoch": 0.5394431554524362,
      "grad_norm": 0.0,
      "learning_rate": 1.2864321608040203e-05,
      "loss": 0.2842,
      "step": 14880
    },
    {
      "epoch": 0.5398056844547564,
      "grad_norm": 0.0,
      "learning_rate": 1.2839195979899498e-05,
      "loss": 0.0012,
      "step": 14890
    },
    {
      "epoch": 0.5401682134570766,
      "grad_norm": 0.0,
      "learning_rate": 1.2814070351758795e-05,
      "loss": 0.1658,
      "step": 14900
    },
    {
      "epoch": 0.5405307424593968,
      "grad_norm": 0.0,
      "learning_rate": 1.2788944723618091e-05,
      "loss": 0.0022,
      "step": 14910
    },
    {
      "epoch": 0.540893271461717,
      "grad_norm": 0.0,
      "learning_rate": 1.2763819095477386e-05,
      "loss": 0.2202,
      "step": 14920
    },
    {
      "epoch": 0.5412558004640371,
      "grad_norm": 0.0,
      "learning_rate": 1.2738693467336684e-05,
      "loss": 0.0,
      "step": 14930
    },
    {
      "epoch": 0.5416183294663574,
      "grad_norm": 0.0,
      "learning_rate": 1.2713567839195981e-05,
      "loss": 0.5989,
      "step": 14940
    },
    {
      "epoch": 0.5419808584686775,
      "grad_norm": 8.07914352636645,
      "learning_rate": 1.2688442211055276e-05,
      "loss": 0.1384,
      "step": 14950
    },
    {
      "epoch": 0.5423433874709976,
      "grad_norm": 0.0,
      "learning_rate": 1.2663316582914573e-05,
      "loss": 0.6267,
      "step": 14960
    },
    {
      "epoch": 0.5427059164733179,
      "grad_norm": 40.66319268402092,
      "learning_rate": 1.2638190954773871e-05,
      "loss": 0.4363,
      "step": 14970
    },
    {
      "epoch": 0.543068445475638,
      "grad_norm": 0.0,
      "learning_rate": 1.2613065326633166e-05,
      "loss": 0.0837,
      "step": 14980
    },
    {
      "epoch": 0.5434309744779582,
      "grad_norm": 0.0,
      "learning_rate": 1.2587939698492462e-05,
      "loss": 0.3968,
      "step": 14990
    },
    {
      "epoch": 0.5437935034802784,
      "grad_norm": 0.0,
      "learning_rate": 1.2562814070351759e-05,
      "loss": 0.0176,
      "step": 15000
    },
    {
      "epoch": 0.5437935034802784,
      "eval_loss": NaN,
      "eval_runtime": 74.7523,
      "eval_samples_per_second": 8.521,
      "eval_steps_per_second": 1.431,
      "step": 15000
    },
    {
      "epoch": 0.5441560324825986,
      "grad_norm": 0.0,
      "learning_rate": 1.2537688442211057e-05,
      "loss": 0.3154,
      "step": 15010
    },
    {
      "epoch": 0.5445185614849188,
      "grad_norm": 5.853010540854802,
      "learning_rate": 1.2512562814070352e-05,
      "loss": 0.4278,
      "step": 15020
    },
    {
      "epoch": 0.544881090487239,
      "grad_norm": 0.0,
      "learning_rate": 1.2487437185929649e-05,
      "loss": 0.2622,
      "step": 15030
    },
    {
      "epoch": 0.5452436194895591,
      "grad_norm": 0.0,
      "learning_rate": 1.2462311557788946e-05,
      "loss": 0.1224,
      "step": 15040
    },
    {
      "epoch": 0.5456061484918794,
      "grad_norm": 21.0359480033213,
      "learning_rate": 1.2437185929648242e-05,
      "loss": 0.4187,
      "step": 15050
    },
    {
      "epoch": 0.5459686774941995,
      "grad_norm": 0.0,
      "learning_rate": 1.2412060301507539e-05,
      "loss": 0.3665,
      "step": 15060
    },
    {
      "epoch": 0.5463312064965197,
      "grad_norm": 33.833115249707646,
      "learning_rate": 1.2386934673366835e-05,
      "loss": 0.2728,
      "step": 15070
    },
    {
      "epoch": 0.5466937354988399,
      "grad_norm": 0.0,
      "learning_rate": 1.2361809045226132e-05,
      "loss": 0.3774,
      "step": 15080
    },
    {
      "epoch": 0.5470562645011601,
      "grad_norm": 0.0,
      "learning_rate": 1.2336683417085427e-05,
      "loss": 0.3523,
      "step": 15090
    },
    {
      "epoch": 0.5474187935034803,
      "grad_norm": 0.0,
      "learning_rate": 1.2311557788944725e-05,
      "loss": 0.4944,
      "step": 15100
    },
    {
      "epoch": 0.5477813225058005,
      "grad_norm": 8.887036395421967,
      "learning_rate": 1.228643216080402e-05,
      "loss": 0.4621,
      "step": 15110
    },
    {
      "epoch": 0.5481438515081206,
      "grad_norm": 0.0,
      "learning_rate": 1.2261306532663318e-05,
      "loss": 0.4291,
      "step": 15120
    },
    {
      "epoch": 0.5485063805104409,
      "grad_norm": 2.407413944278982,
      "learning_rate": 1.2236180904522613e-05,
      "loss": 0.2448,
      "step": 15130
    },
    {
      "epoch": 0.548868909512761,
      "grad_norm": 11.521196153847468,
      "learning_rate": 1.221105527638191e-05,
      "loss": 0.8528,
      "step": 15140
    },
    {
      "epoch": 0.5492314385150812,
      "grad_norm": 0.0,
      "learning_rate": 1.2185929648241207e-05,
      "loss": 0.1525,
      "step": 15150
    },
    {
      "epoch": 0.5495939675174014,
      "grad_norm": 8.889036013127395,
      "learning_rate": 1.2160804020100503e-05,
      "loss": 0.1699,
      "step": 15160
    },
    {
      "epoch": 0.5499564965197216,
      "grad_norm": 0.0,
      "learning_rate": 1.21356783919598e-05,
      "loss": 0.9756,
      "step": 15170
    },
    {
      "epoch": 0.5503190255220418,
      "grad_norm": 0.0,
      "learning_rate": 1.2110552763819095e-05,
      "loss": 0.364,
      "step": 15180
    },
    {
      "epoch": 0.550681554524362,
      "grad_norm": 0.07383634846921781,
      "learning_rate": 1.2085427135678393e-05,
      "loss": 0.0109,
      "step": 15190
    },
    {
      "epoch": 0.5510440835266821,
      "grad_norm": 0.0,
      "learning_rate": 1.2060301507537688e-05,
      "loss": 0.0965,
      "step": 15200
    },
    {
      "epoch": 0.5514066125290024,
      "grad_norm": 43.73393957446693,
      "learning_rate": 1.2035175879396986e-05,
      "loss": 0.9378,
      "step": 15210
    },
    {
      "epoch": 0.5517691415313225,
      "grad_norm": 7.928748645544801,
      "learning_rate": 1.2010050251256281e-05,
      "loss": 0.144,
      "step": 15220
    },
    {
      "epoch": 0.5521316705336426,
      "grad_norm": 0.0,
      "learning_rate": 1.1984924623115578e-05,
      "loss": 0.3939,
      "step": 15230
    },
    {
      "epoch": 0.5524941995359629,
      "grad_norm": 0.0,
      "learning_rate": 1.1959798994974875e-05,
      "loss": 0.5506,
      "step": 15240
    },
    {
      "epoch": 0.552856728538283,
      "grad_norm": 0.0,
      "learning_rate": 1.1934673366834171e-05,
      "loss": 0.0021,
      "step": 15250
    },
    {
      "epoch": 0.5532192575406032,
      "grad_norm": 0.0,
      "learning_rate": 1.1909547738693468e-05,
      "loss": 0.0659,
      "step": 15260
    },
    {
      "epoch": 0.5535817865429234,
      "grad_norm": 0.0,
      "learning_rate": 1.1884422110552764e-05,
      "loss": 0.7667,
      "step": 15270
    },
    {
      "epoch": 0.5539443155452436,
      "grad_norm": 1.7275538295634398,
      "learning_rate": 1.1859296482412061e-05,
      "loss": 0.2556,
      "step": 15280
    },
    {
      "epoch": 0.5543068445475638,
      "grad_norm": 18.040755861945268,
      "learning_rate": 1.1834170854271358e-05,
      "loss": 0.288,
      "step": 15290
    },
    {
      "epoch": 0.554669373549884,
      "grad_norm": 0.0,
      "learning_rate": 1.1809045226130654e-05,
      "loss": 0.1274,
      "step": 15300
    },
    {
      "epoch": 0.5550319025522041,
      "grad_norm": 0.0,
      "learning_rate": 1.1783919597989951e-05,
      "loss": 0.0,
      "step": 15310
    },
    {
      "epoch": 0.5553944315545244,
      "grad_norm": 0.0,
      "learning_rate": 1.1758793969849246e-05,
      "loss": 1.0964,
      "step": 15320
    },
    {
      "epoch": 0.5557569605568445,
      "grad_norm": 0.0,
      "learning_rate": 1.1733668341708544e-05,
      "loss": 0.0054,
      "step": 15330
    },
    {
      "epoch": 0.5561194895591647,
      "grad_norm": 0.0,
      "learning_rate": 1.1708542713567839e-05,
      "loss": 0.0462,
      "step": 15340
    },
    {
      "epoch": 0.5564820185614849,
      "grad_norm": 6.444178108031862,
      "learning_rate": 1.1683417085427137e-05,
      "loss": 0.5259,
      "step": 15350
    },
    {
      "epoch": 0.5568445475638051,
      "grad_norm": 7.999876498222732,
      "learning_rate": 1.1658291457286432e-05,
      "loss": 0.2752,
      "step": 15360
    },
    {
      "epoch": 0.5572070765661253,
      "grad_norm": 0.0,
      "learning_rate": 1.163316582914573e-05,
      "loss": 0.2498,
      "step": 15370
    },
    {
      "epoch": 0.5575696055684455,
      "grad_norm": 0.18146970357064632,
      "learning_rate": 1.1608040201005026e-05,
      "loss": 0.0939,
      "step": 15380
    },
    {
      "epoch": 0.5579321345707656,
      "grad_norm": 0.0,
      "learning_rate": 1.1582914572864322e-05,
      "loss": 0.2286,
      "step": 15390
    },
    {
      "epoch": 0.5582946635730859,
      "grad_norm": 0.0,
      "learning_rate": 1.1557788944723619e-05,
      "loss": 0.0927,
      "step": 15400
    },
    {
      "epoch": 0.558657192575406,
      "grad_norm": 0.0,
      "learning_rate": 1.1532663316582914e-05,
      "loss": 0.1413,
      "step": 15410
    },
    {
      "epoch": 0.5590197215777262,
      "grad_norm": 0.0,
      "learning_rate": 1.1507537688442212e-05,
      "loss": 0.0012,
      "step": 15420
    },
    {
      "epoch": 0.5593822505800464,
      "grad_norm": 16.94152468903146,
      "learning_rate": 1.1482412060301507e-05,
      "loss": 0.1657,
      "step": 15430
    },
    {
      "epoch": 0.5597447795823666,
      "grad_norm": 35.39783832394024,
      "learning_rate": 1.1457286432160805e-05,
      "loss": 0.4581,
      "step": 15440
    },
    {
      "epoch": 0.5601073085846868,
      "grad_norm": 45.613103115017836,
      "learning_rate": 1.14321608040201e-05,
      "loss": 1.1654,
      "step": 15450
    },
    {
      "epoch": 0.560469837587007,
      "grad_norm": 0.0,
      "learning_rate": 1.1407035175879399e-05,
      "loss": 1.3769,
      "step": 15460
    },
    {
      "epoch": 0.5608323665893271,
      "grad_norm": 0.0,
      "learning_rate": 1.1381909547738693e-05,
      "loss": 0.4429,
      "step": 15470
    },
    {
      "epoch": 0.5611948955916474,
      "grad_norm": 0.0,
      "learning_rate": 1.135678391959799e-05,
      "loss": 0.501,
      "step": 15480
    },
    {
      "epoch": 0.5615574245939675,
      "grad_norm": 0.0,
      "learning_rate": 1.1331658291457287e-05,
      "loss": 0.0118,
      "step": 15490
    },
    {
      "epoch": 0.5619199535962877,
      "grad_norm": 0.0,
      "learning_rate": 1.1306532663316583e-05,
      "loss": 0.0614,
      "step": 15500
    },
    {
      "epoch": 0.5619199535962877,
      "eval_loss": NaN,
      "eval_runtime": 67.5779,
      "eval_samples_per_second": 9.426,
      "eval_steps_per_second": 1.583,
      "step": 15500
    },
    {
      "epoch": 0.5622824825986079,
      "grad_norm": 14.877231462581031,
      "learning_rate": 1.128140703517588e-05,
      "loss": 0.83,
      "step": 15510
    },
    {
      "epoch": 0.5626450116009281,
      "grad_norm": 0.0,
      "learning_rate": 1.1256281407035177e-05,
      "loss": 0.1797,
      "step": 15520
    },
    {
      "epoch": 0.5630075406032483,
      "grad_norm": 0.0,
      "learning_rate": 1.1231155778894473e-05,
      "loss": 0.502,
      "step": 15530
    },
    {
      "epoch": 0.5633700696055685,
      "grad_norm": 5.6325150198298095,
      "learning_rate": 1.120603015075377e-05,
      "loss": 0.02,
      "step": 15540
    },
    {
      "epoch": 0.5637325986078886,
      "grad_norm": 0.0,
      "learning_rate": 1.1180904522613066e-05,
      "loss": 0.373,
      "step": 15550
    },
    {
      "epoch": 0.5640951276102089,
      "grad_norm": 0.0,
      "learning_rate": 1.1155778894472363e-05,
      "loss": 0.4988,
      "step": 15560
    },
    {
      "epoch": 0.564457656612529,
      "grad_norm": 8.246365758185446,
      "learning_rate": 1.1130653266331658e-05,
      "loss": 0.9852,
      "step": 15570
    },
    {
      "epoch": 0.5648201856148491,
      "grad_norm": 10.869741286468857,
      "learning_rate": 1.1105527638190956e-05,
      "loss": 0.3119,
      "step": 15580
    },
    {
      "epoch": 0.5651827146171694,
      "grad_norm": 0.0,
      "learning_rate": 1.1080402010050251e-05,
      "loss": 0.0007,
      "step": 15590
    },
    {
      "epoch": 0.5655452436194895,
      "grad_norm": 54.422518747987034,
      "learning_rate": 1.105527638190955e-05,
      "loss": 0.5123,
      "step": 15600
    },
    {
      "epoch": 0.5659077726218097,
      "grad_norm": 0.0,
      "learning_rate": 1.1030150753768844e-05,
      "loss": 0.2722,
      "step": 15610
    },
    {
      "epoch": 0.56627030162413,
      "grad_norm": 0.0,
      "learning_rate": 1.1005025125628141e-05,
      "loss": 0.4757,
      "step": 15620
    },
    {
      "epoch": 0.5666328306264501,
      "grad_norm": 0.0,
      "learning_rate": 1.0979899497487438e-05,
      "loss": 0.7834,
      "step": 15630
    },
    {
      "epoch": 0.5669953596287703,
      "grad_norm": 0.0,
      "learning_rate": 1.0954773869346734e-05,
      "loss": 0.0046,
      "step": 15640
    },
    {
      "epoch": 0.5673578886310905,
      "grad_norm": 0.0,
      "learning_rate": 1.0929648241206031e-05,
      "loss": 0.8358,
      "step": 15650
    },
    {
      "epoch": 0.5677204176334106,
      "grad_norm": 0.0,
      "learning_rate": 1.0904522613065326e-05,
      "loss": 0.1784,
      "step": 15660
    },
    {
      "epoch": 0.5680829466357309,
      "grad_norm": 9.039011012979984,
      "learning_rate": 1.0879396984924624e-05,
      "loss": 0.7163,
      "step": 15670
    },
    {
      "epoch": 0.568445475638051,
      "grad_norm": 0.0,
      "learning_rate": 1.0854271356783919e-05,
      "loss": 0.5689,
      "step": 15680
    },
    {
      "epoch": 0.5688080046403712,
      "grad_norm": 3.7948413316127856,
      "learning_rate": 1.0829145728643217e-05,
      "loss": 0.7514,
      "step": 15690
    },
    {
      "epoch": 0.5691705336426914,
      "grad_norm": 0.0,
      "learning_rate": 1.0804020100502512e-05,
      "loss": 1.0156,
      "step": 15700
    },
    {
      "epoch": 0.5695330626450116,
      "grad_norm": 0.0,
      "learning_rate": 1.077889447236181e-05,
      "loss": 1.1496,
      "step": 15710
    },
    {
      "epoch": 0.5698955916473318,
      "grad_norm": 0.0,
      "learning_rate": 1.0753768844221106e-05,
      "loss": 0.182,
      "step": 15720
    },
    {
      "epoch": 0.570258120649652,
      "grad_norm": 5.7249995202476605,
      "learning_rate": 1.0728643216080402e-05,
      "loss": 0.534,
      "step": 15730
    },
    {
      "epoch": 0.5706206496519721,
      "grad_norm": 0.0,
      "learning_rate": 1.0703517587939699e-05,
      "loss": 0.6129,
      "step": 15740
    },
    {
      "epoch": 0.5709831786542924,
      "grad_norm": 0.2783612003743001,
      "learning_rate": 1.0678391959798995e-05,
      "loss": 0.1808,
      "step": 15750
    },
    {
      "epoch": 0.5713457076566125,
      "grad_norm": 15.181672159405368,
      "learning_rate": 1.0653266331658292e-05,
      "loss": 0.4759,
      "step": 15760
    },
    {
      "epoch": 0.5717082366589327,
      "grad_norm": 0.0,
      "learning_rate": 1.0628140703517589e-05,
      "loss": 0.0565,
      "step": 15770
    },
    {
      "epoch": 0.5720707656612529,
      "grad_norm": 0.0,
      "learning_rate": 1.0603015075376885e-05,
      "loss": 0.4016,
      "step": 15780
    },
    {
      "epoch": 0.5724332946635731,
      "grad_norm": 0.0,
      "learning_rate": 1.0577889447236182e-05,
      "loss": 0.6675,
      "step": 15790
    },
    {
      "epoch": 0.5727958236658933,
      "grad_norm": 0.0,
      "learning_rate": 1.0552763819095479e-05,
      "loss": 0.4304,
      "step": 15800
    },
    {
      "epoch": 0.5731583526682135,
      "grad_norm": 0.0,
      "learning_rate": 1.0527638190954775e-05,
      "loss": 0.1701,
      "step": 15810
    },
    {
      "epoch": 0.5735208816705336,
      "grad_norm": 0.0,
      "learning_rate": 1.050251256281407e-05,
      "loss": 1.2058,
      "step": 15820
    },
    {
      "epoch": 0.5738834106728539,
      "grad_norm": 0.0,
      "learning_rate": 1.0477386934673368e-05,
      "loss": 0.011,
      "step": 15830
    },
    {
      "epoch": 0.574245939675174,
      "grad_norm": 0.0,
      "learning_rate": 1.0452261306532663e-05,
      "loss": 0.1068,
      "step": 15840
    },
    {
      "epoch": 0.5746084686774942,
      "grad_norm": 0.0,
      "learning_rate": 1.042713567839196e-05,
      "loss": 0.3736,
      "step": 15850
    },
    {
      "epoch": 0.5749709976798144,
      "grad_norm": 0.0,
      "learning_rate": 1.0402010050251257e-05,
      "loss": 0.4609,
      "step": 15860
    },
    {
      "epoch": 0.5753335266821346,
      "grad_norm": 0.0,
      "learning_rate": 1.0376884422110553e-05,
      "loss": 0.8461,
      "step": 15870
    },
    {
      "epoch": 0.5756960556844548,
      "grad_norm": 0.49019805044123477,
      "learning_rate": 1.035175879396985e-05,
      "loss": 0.3033,
      "step": 15880
    },
    {
      "epoch": 0.576058584686775,
      "grad_norm": 0.0,
      "learning_rate": 1.0326633165829146e-05,
      "loss": 0.3171,
      "step": 15890
    },
    {
      "epoch": 0.5764211136890951,
      "grad_norm": 18.843305440185098,
      "learning_rate": 1.0301507537688443e-05,
      "loss": 0.794,
      "step": 15900
    },
    {
      "epoch": 0.5767836426914154,
      "grad_norm": 0.0,
      "learning_rate": 1.0276381909547738e-05,
      "loss": 0.5807,
      "step": 15910
    },
    {
      "epoch": 0.5771461716937355,
      "grad_norm": 0.0,
      "learning_rate": 1.0251256281407036e-05,
      "loss": 0.1357,
      "step": 15920
    },
    {
      "epoch": 0.5775087006960556,
      "grad_norm": 0.0,
      "learning_rate": 1.0226130653266331e-05,
      "loss": 0.3952,
      "step": 15930
    },
    {
      "epoch": 0.5778712296983759,
      "grad_norm": 1.4956968094659284,
      "learning_rate": 1.020100502512563e-05,
      "loss": 0.1032,
      "step": 15940
    },
    {
      "epoch": 0.578233758700696,
      "grad_norm": 47.18264668750048,
      "learning_rate": 1.0175879396984924e-05,
      "loss": 0.1081,
      "step": 15950
    },
    {
      "epoch": 0.5785962877030162,
      "grad_norm": 0.0,
      "learning_rate": 1.0150753768844223e-05,
      "loss": 0.0,
      "step": 15960
    },
    {
      "epoch": 0.5789588167053364,
      "grad_norm": 11.567007804772333,
      "learning_rate": 1.0125628140703518e-05,
      "loss": 0.6784,
      "step": 15970
    },
    {
      "epoch": 0.5793213457076566,
      "grad_norm": 0.0,
      "learning_rate": 1.0100502512562814e-05,
      "loss": 0.9746,
      "step": 15980
    },
    {
      "epoch": 0.5796838747099768,
      "grad_norm": 0.1330100581669951,
      "learning_rate": 1.0075376884422111e-05,
      "loss": 0.1112,
      "step": 15990
    },
    {
      "epoch": 0.580046403712297,
      "grad_norm": 0.0,
      "learning_rate": 1.0050251256281408e-05,
      "loss": 0.0485,
      "step": 16000
    },
    {
      "epoch": 0.580046403712297,
      "eval_loss": NaN,
      "eval_runtime": 67.3777,
      "eval_samples_per_second": 9.454,
      "eval_steps_per_second": 1.588,
      "step": 16000
    },
    {
      "epoch": 0.5804089327146171,
      "grad_norm": 0.0,
      "learning_rate": 1.0025125628140704e-05,
      "loss": 0.9424,
      "step": 16010
    },
    {
      "epoch": 0.5807714617169374,
      "grad_norm": 0.27141485078719735,
      "learning_rate": 1e-05,
      "loss": 0.747,
      "step": 16020
    },
    {
      "epoch": 0.5811339907192575,
      "grad_norm": 0.0,
      "learning_rate": 9.974874371859297e-06,
      "loss": 0.0256,
      "step": 16030
    },
    {
      "epoch": 0.5814965197215777,
      "grad_norm": 1.471664459007972,
      "learning_rate": 9.949748743718594e-06,
      "loss": 0.1756,
      "step": 16040
    },
    {
      "epoch": 0.5818590487238979,
      "grad_norm": 0.0,
      "learning_rate": 9.92462311557789e-06,
      "loss": 0.4134,
      "step": 16050
    },
    {
      "epoch": 0.5822215777262181,
      "grad_norm": 0.0,
      "learning_rate": 9.899497487437187e-06,
      "loss": 0.1197,
      "step": 16060
    },
    {
      "epoch": 0.5825841067285383,
      "grad_norm": 44.8079343036755,
      "learning_rate": 9.874371859296482e-06,
      "loss": 0.8275,
      "step": 16070
    },
    {
      "epoch": 0.5829466357308585,
      "grad_norm": 0.0,
      "learning_rate": 9.849246231155779e-06,
      "loss": 0.0677,
      "step": 16080
    },
    {
      "epoch": 0.5833091647331786,
      "grad_norm": 0.0,
      "learning_rate": 9.824120603015075e-06,
      "loss": 0.2556,
      "step": 16090
    },
    {
      "epoch": 0.5836716937354989,
      "grad_norm": 0.0,
      "learning_rate": 9.798994974874372e-06,
      "loss": 0.2159,
      "step": 16100
    },
    {
      "epoch": 0.584034222737819,
      "grad_norm": 0.0,
      "learning_rate": 9.773869346733669e-06,
      "loss": 0.2085,
      "step": 16110
    },
    {
      "epoch": 0.5843967517401392,
      "grad_norm": 0.0,
      "learning_rate": 9.748743718592965e-06,
      "loss": 0.0859,
      "step": 16120
    },
    {
      "epoch": 0.5847592807424594,
      "grad_norm": 0.0,
      "learning_rate": 9.723618090452262e-06,
      "loss": 1.0855,
      "step": 16130
    },
    {
      "epoch": 0.5851218097447796,
      "grad_norm": 0.0,
      "learning_rate": 9.698492462311559e-06,
      "loss": 0.0893,
      "step": 16140
    },
    {
      "epoch": 0.5854843387470998,
      "grad_norm": 0.0,
      "learning_rate": 9.673366834170855e-06,
      "loss": 0.0218,
      "step": 16150
    },
    {
      "epoch": 0.58584686774942,
      "grad_norm": 6.049021101014409,
      "learning_rate": 9.64824120603015e-06,
      "loss": 0.6089,
      "step": 16160
    },
    {
      "epoch": 0.5862093967517401,
      "grad_norm": 0.0,
      "learning_rate": 9.623115577889448e-06,
      "loss": 0.076,
      "step": 16170
    },
    {
      "epoch": 0.5865719257540604,
      "grad_norm": 9.490769570021707,
      "learning_rate": 9.597989949748743e-06,
      "loss": 0.4687,
      "step": 16180
    },
    {
      "epoch": 0.5869344547563805,
      "grad_norm": 5.751384734225661,
      "learning_rate": 9.572864321608042e-06,
      "loss": 0.5986,
      "step": 16190
    },
    {
      "epoch": 0.5872969837587007,
      "grad_norm": 0.5145056741881668,
      "learning_rate": 9.547738693467337e-06,
      "loss": 0.1474,
      "step": 16200
    },
    {
      "epoch": 0.5876595127610209,
      "grad_norm": 0.14291945191186517,
      "learning_rate": 9.522613065326633e-06,
      "loss": 0.0433,
      "step": 16210
    },
    {
      "epoch": 0.588022041763341,
      "grad_norm": 0.0,
      "learning_rate": 9.49748743718593e-06,
      "loss": 0.8863,
      "step": 16220
    },
    {
      "epoch": 0.5883845707656613,
      "grad_norm": 6.9455041848196775,
      "learning_rate": 9.472361809045226e-06,
      "loss": 0.437,
      "step": 16230
    },
    {
      "epoch": 0.5887470997679815,
      "grad_norm": 0.0,
      "learning_rate": 9.447236180904523e-06,
      "loss": 0.0221,
      "step": 16240
    },
    {
      "epoch": 0.5891096287703016,
      "grad_norm": 0.0,
      "learning_rate": 9.42211055276382e-06,
      "loss": 0.6336,
      "step": 16250
    },
    {
      "epoch": 0.5894721577726219,
      "grad_norm": 0.0,
      "learning_rate": 9.396984924623116e-06,
      "loss": 0.2427,
      "step": 16260
    },
    {
      "epoch": 0.589834686774942,
      "grad_norm": 0.0,
      "learning_rate": 9.371859296482413e-06,
      "loss": 0.0659,
      "step": 16270
    },
    {
      "epoch": 0.5901972157772621,
      "grad_norm": 0.0,
      "learning_rate": 9.34673366834171e-06,
      "loss": 0.945,
      "step": 16280
    },
    {
      "epoch": 0.5905597447795824,
      "grad_norm": 0.0,
      "learning_rate": 9.321608040201006e-06,
      "loss": 0.4899,
      "step": 16290
    },
    {
      "epoch": 0.5909222737819025,
      "grad_norm": 11.90235208298855,
      "learning_rate": 9.296482412060301e-06,
      "loss": 0.051,
      "step": 16300
    },
    {
      "epoch": 0.5912848027842227,
      "grad_norm": 0.0,
      "learning_rate": 9.271356783919598e-06,
      "loss": 0.3388,
      "step": 16310
    },
    {
      "epoch": 0.5916473317865429,
      "grad_norm": 0.0,
      "learning_rate": 9.246231155778894e-06,
      "loss": 0.1213,
      "step": 16320
    },
    {
      "epoch": 0.5920098607888631,
      "grad_norm": 8.758104331388854,
      "learning_rate": 9.221105527638191e-06,
      "loss": 0.2858,
      "step": 16330
    },
    {
      "epoch": 0.5923723897911833,
      "grad_norm": 0.0,
      "learning_rate": 9.195979899497488e-06,
      "loss": 0.6196,
      "step": 16340
    },
    {
      "epoch": 0.5927349187935035,
      "grad_norm": 0.0,
      "learning_rate": 9.170854271356784e-06,
      "loss": 0.1781,
      "step": 16350
    },
    {
      "epoch": 0.5930974477958236,
      "grad_norm": 0.0,
      "learning_rate": 9.14572864321608e-06,
      "loss": 0.0339,
      "step": 16360
    },
    {
      "epoch": 0.5934599767981439,
      "grad_norm": 0.0,
      "learning_rate": 9.120603015075377e-06,
      "loss": 0.345,
      "step": 16370
    },
    {
      "epoch": 0.593822505800464,
      "grad_norm": 0.0,
      "learning_rate": 9.095477386934674e-06,
      "loss": 0.6541,
      "step": 16380
    },
    {
      "epoch": 0.5941850348027842,
      "grad_norm": 0.0,
      "learning_rate": 9.07035175879397e-06,
      "loss": 0.3045,
      "step": 16390
    },
    {
      "epoch": 0.5945475638051044,
      "grad_norm": 0.2689029031309197,
      "learning_rate": 9.045226130653267e-06,
      "loss": 0.1452,
      "step": 16400
    },
    {
      "epoch": 0.5949100928074246,
      "grad_norm": 6.01273552003062,
      "learning_rate": 9.020100502512562e-06,
      "loss": 0.5421,
      "step": 16410
    },
    {
      "epoch": 0.5952726218097448,
      "grad_norm": 0.0,
      "learning_rate": 8.99497487437186e-06,
      "loss": 0.0112,
      "step": 16420
    },
    {
      "epoch": 0.595635150812065,
      "grad_norm": 0.0,
      "learning_rate": 8.969849246231155e-06,
      "loss": 0.0045,
      "step": 16430
    },
    {
      "epoch": 0.5959976798143851,
      "grad_norm": 0.0,
      "learning_rate": 8.944723618090454e-06,
      "loss": 0.2904,
      "step": 16440
    },
    {
      "epoch": 0.5963602088167054,
      "grad_norm": 0.0,
      "learning_rate": 8.919597989949749e-06,
      "loss": 0.263,
      "step": 16450
    },
    {
      "epoch": 0.5967227378190255,
      "grad_norm": 0.0,
      "learning_rate": 8.894472361809045e-06,
      "loss": 0.1738,
      "step": 16460
    },
    {
      "epoch": 0.5970852668213457,
      "grad_norm": 0.0,
      "learning_rate": 8.869346733668342e-06,
      "loss": 1.0003,
      "step": 16470
    },
    {
      "epoch": 0.5974477958236659,
      "grad_norm": 0.0,
      "learning_rate": 8.844221105527639e-06,
      "loss": 0.4407,
      "step": 16480
    },
    {
      "epoch": 0.5978103248259861,
      "grad_norm": 0.0,
      "learning_rate": 8.819095477386935e-06,
      "loss": 1.2739,
      "step": 16490
    },
    {
      "epoch": 0.5981728538283063,
      "grad_norm": 0.0,
      "learning_rate": 8.793969849246232e-06,
      "loss": 0.0033,
      "step": 16500
    },
    {
      "epoch": 0.5981728538283063,
      "eval_loss": NaN,
      "eval_runtime": 67.3478,
      "eval_samples_per_second": 9.458,
      "eval_steps_per_second": 1.589,
      "step": 16500
    },
    {
      "epoch": 0.5985353828306265,
      "grad_norm": 0.0,
      "learning_rate": 8.768844221105528e-06,
      "loss": 0.4177,
      "step": 16510
    },
    {
      "epoch": 0.5988979118329466,
      "grad_norm": 18.327335740678798,
      "learning_rate": 8.743718592964825e-06,
      "loss": 0.2041,
      "step": 16520
    },
    {
      "epoch": 0.5992604408352669,
      "grad_norm": 25.80968720487099,
      "learning_rate": 8.718592964824122e-06,
      "loss": 0.1984,
      "step": 16530
    },
    {
      "epoch": 0.599622969837587,
      "grad_norm": 0.0,
      "learning_rate": 8.693467336683417e-06,
      "loss": 0.1187,
      "step": 16540
    },
    {
      "epoch": 0.5999854988399071,
      "grad_norm": 21.864438717239505,
      "learning_rate": 8.668341708542713e-06,
      "loss": 0.3283,
      "step": 16550
    },
    {
      "epoch": 0.6003480278422274,
      "grad_norm": 0.0,
      "learning_rate": 8.64321608040201e-06,
      "loss": 0.4615,
      "step": 16560
    },
    {
      "epoch": 0.6007105568445475,
      "grad_norm": 154.54027084388068,
      "learning_rate": 8.618090452261306e-06,
      "loss": 0.2083,
      "step": 16570
    },
    {
      "epoch": 0.6010730858468677,
      "grad_norm": 0.0,
      "learning_rate": 8.592964824120603e-06,
      "loss": 0.3173,
      "step": 16580
    },
    {
      "epoch": 0.601435614849188,
      "grad_norm": 0.0,
      "learning_rate": 8.5678391959799e-06,
      "loss": 0.1012,
      "step": 16590
    },
    {
      "epoch": 0.6017981438515081,
      "grad_norm": 0.0,
      "learning_rate": 8.542713567839196e-06,
      "loss": 0.1948,
      "step": 16600
    },
    {
      "epoch": 0.6021606728538283,
      "grad_norm": 0.0,
      "learning_rate": 8.517587939698493e-06,
      "loss": 0.2607,
      "step": 16610
    },
    {
      "epoch": 0.6025232018561485,
      "grad_norm": 0.0,
      "learning_rate": 8.49246231155779e-06,
      "loss": 0.2838,
      "step": 16620
    },
    {
      "epoch": 0.6028857308584686,
      "grad_norm": 0.0,
      "learning_rate": 8.467336683417086e-06,
      "loss": 0.0078,
      "step": 16630
    },
    {
      "epoch": 0.6032482598607889,
      "grad_norm": 0.0,
      "learning_rate": 8.442211055276381e-06,
      "loss": 0.0019,
      "step": 16640
    },
    {
      "epoch": 0.603610788863109,
      "grad_norm": 0.0,
      "learning_rate": 8.41708542713568e-06,
      "loss": 0.6372,
      "step": 16650
    },
    {
      "epoch": 0.6039733178654292,
      "grad_norm": 0.0,
      "learning_rate": 8.391959798994974e-06,
      "loss": 0.0026,
      "step": 16660
    },
    {
      "epoch": 0.6043358468677494,
      "grad_norm": 0.0,
      "learning_rate": 8.366834170854273e-06,
      "loss": 0.5119,
      "step": 16670
    },
    {
      "epoch": 0.6046983758700696,
      "grad_norm": 0.48555775796688777,
      "learning_rate": 8.341708542713568e-06,
      "loss": 0.6565,
      "step": 16680
    },
    {
      "epoch": 0.6050609048723898,
      "grad_norm": 23.89517589707897,
      "learning_rate": 8.316582914572866e-06,
      "loss": 0.8649,
      "step": 16690
    },
    {
      "epoch": 0.60542343387471,
      "grad_norm": 0.0,
      "learning_rate": 8.291457286432161e-06,
      "loss": 0.5358,
      "step": 16700
    },
    {
      "epoch": 0.6057859628770301,
      "grad_norm": 8.092294923047604,
      "learning_rate": 8.266331658291457e-06,
      "loss": 0.0962,
      "step": 16710
    },
    {
      "epoch": 0.6061484918793504,
      "grad_norm": 0.0,
      "learning_rate": 8.241206030150754e-06,
      "loss": 0.4658,
      "step": 16720
    },
    {
      "epoch": 0.6065110208816705,
      "grad_norm": 0.0,
      "learning_rate": 8.21608040201005e-06,
      "loss": 0.2314,
      "step": 16730
    },
    {
      "epoch": 0.6068735498839907,
      "grad_norm": 60.36693624980069,
      "learning_rate": 8.190954773869347e-06,
      "loss": 0.9459,
      "step": 16740
    },
    {
      "epoch": 0.6072360788863109,
      "grad_norm": 0.0,
      "learning_rate": 8.165829145728644e-06,
      "loss": 0.0,
      "step": 16750
    },
    {
      "epoch": 0.6075986078886311,
      "grad_norm": 0.0,
      "learning_rate": 8.14070351758794e-06,
      "loss": 0.4652,
      "step": 16760
    },
    {
      "epoch": 0.6079611368909513,
      "grad_norm": 4.500897847780732,
      "learning_rate": 8.115577889447236e-06,
      "loss": 0.0793,
      "step": 16770
    },
    {
      "epoch": 0.6083236658932715,
      "grad_norm": 0.0,
      "learning_rate": 8.090452261306534e-06,
      "loss": 0.0045,
      "step": 16780
    },
    {
      "epoch": 0.6086861948955916,
      "grad_norm": 0.0,
      "learning_rate": 8.065326633165829e-06,
      "loss": 0.0992,
      "step": 16790
    },
    {
      "epoch": 0.6090487238979119,
      "grad_norm": 0.0,
      "learning_rate": 8.040201005025125e-06,
      "loss": 0.2009,
      "step": 16800
    },
    {
      "epoch": 0.609411252900232,
      "grad_norm": 0.22070010360405085,
      "learning_rate": 8.015075376884422e-06,
      "loss": 0.4171,
      "step": 16810
    },
    {
      "epoch": 0.6097737819025522,
      "grad_norm": 0.0,
      "learning_rate": 7.989949748743719e-06,
      "loss": 0.3301,
      "step": 16820
    },
    {
      "epoch": 0.6101363109048724,
      "grad_norm": 0.0,
      "learning_rate": 7.964824120603015e-06,
      "loss": 0.7737,
      "step": 16830
    },
    {
      "epoch": 0.6104988399071926,
      "grad_norm": 0.0,
      "learning_rate": 7.939698492462312e-06,
      "loss": 0.5097,
      "step": 16840
    },
    {
      "epoch": 0.6108613689095128,
      "grad_norm": 0.0,
      "learning_rate": 7.914572864321608e-06,
      "loss": 0.066,
      "step": 16850
    },
    {
      "epoch": 0.611223897911833,
      "grad_norm": 0.0,
      "learning_rate": 7.889447236180905e-06,
      "loss": 0.0276,
      "step": 16860
    },
    {
      "epoch": 0.6115864269141531,
      "grad_norm": 0.0,
      "learning_rate": 7.864321608040202e-06,
      "loss": 0.6852,
      "step": 16870
    },
    {
      "epoch": 0.6119489559164734,
      "grad_norm": 0.0,
      "learning_rate": 7.839195979899498e-06,
      "loss": 0.978,
      "step": 16880
    },
    {
      "epoch": 0.6123114849187935,
      "grad_norm": 0.0,
      "learning_rate": 7.814070351758793e-06,
      "loss": 0.0159,
      "step": 16890
    },
    {
      "epoch": 0.6126740139211136,
      "grad_norm": 0.0,
      "learning_rate": 7.788944723618092e-06,
      "loss": 0.5451,
      "step": 16900
    },
    {
      "epoch": 0.6130365429234339,
      "grad_norm": 0.0,
      "learning_rate": 7.763819095477387e-06,
      "loss": 0.1437,
      "step": 16910
    },
    {
      "epoch": 0.613399071925754,
      "grad_norm": 0.0,
      "learning_rate": 7.738693467336685e-06,
      "loss": 0.6282,
      "step": 16920
    },
    {
      "epoch": 0.6137616009280742,
      "grad_norm": 0.0,
      "learning_rate": 7.71356783919598e-06,
      "loss": 1.0663,
      "step": 16930
    },
    {
      "epoch": 0.6141241299303944,
      "grad_norm": 0.0,
      "learning_rate": 7.688442211055278e-06,
      "loss": 0.0015,
      "step": 16940
    },
    {
      "epoch": 0.6144866589327146,
      "grad_norm": 24.254625646139644,
      "learning_rate": 7.663316582914573e-06,
      "loss": 0.518,
      "step": 16950
    },
    {
      "epoch": 0.6148491879350348,
      "grad_norm": 18.06680869484192,
      "learning_rate": 7.63819095477387e-06,
      "loss": 0.5032,
      "step": 16960
    },
    {
      "epoch": 0.615211716937355,
      "grad_norm": 3.9854497918472087,
      "learning_rate": 7.613065326633166e-06,
      "loss": 0.0956,
      "step": 16970
    },
    {
      "epoch": 0.6155742459396751,
      "grad_norm": 0.0,
      "learning_rate": 7.587939698492464e-06,
      "loss": 0.1183,
      "step": 16980
    },
    {
      "epoch": 0.6159367749419954,
      "grad_norm": 0.0,
      "learning_rate": 7.5628140703517595e-06,
      "loss": 1.6572,
      "step": 16990
    },
    {
      "epoch": 0.6162993039443155,
      "grad_norm": 0.5196122414695263,
      "learning_rate": 7.537688442211055e-06,
      "loss": 0.2334,
      "step": 17000
    },
    {
      "epoch": 0.6162993039443155,
      "eval_loss": NaN,
      "eval_runtime": 67.5263,
      "eval_samples_per_second": 9.433,
      "eval_steps_per_second": 1.585,
      "step": 17000
    },
    {
      "epoch": 0.6166618329466357,
      "grad_norm": 0.0,
      "learning_rate": 7.512562814070352e-06,
      "loss": 0.9827,
      "step": 17010
    },
    {
      "epoch": 0.6170243619489559,
      "grad_norm": 0.0,
      "learning_rate": 7.487437185929648e-06,
      "loss": 0.4269,
      "step": 17020
    },
    {
      "epoch": 0.6173868909512761,
      "grad_norm": 0.0,
      "learning_rate": 7.462311557788945e-06,
      "loss": 0.7398,
      "step": 17030
    },
    {
      "epoch": 0.6177494199535963,
      "grad_norm": 0.0,
      "learning_rate": 7.437185929648241e-06,
      "loss": 0.4038,
      "step": 17040
    },
    {
      "epoch": 0.6181119489559165,
      "grad_norm": 0.0,
      "learning_rate": 7.412060301507538e-06,
      "loss": 0.2015,
      "step": 17050
    },
    {
      "epoch": 0.6184744779582366,
      "grad_norm": 0.0,
      "learning_rate": 7.386934673366834e-06,
      "loss": 0.0009,
      "step": 17060
    },
    {
      "epoch": 0.6188370069605569,
      "grad_norm": 42.30850989772182,
      "learning_rate": 7.361809045226132e-06,
      "loss": 0.3503,
      "step": 17070
    },
    {
      "epoch": 0.619199535962877,
      "grad_norm": 18.77159319774538,
      "learning_rate": 7.336683417085427e-06,
      "loss": 0.2708,
      "step": 17080
    },
    {
      "epoch": 0.6195620649651972,
      "grad_norm": 0.0,
      "learning_rate": 7.311557788944724e-06,
      "loss": 0.1257,
      "step": 17090
    },
    {
      "epoch": 0.6199245939675174,
      "grad_norm": 27.832556190224988,
      "learning_rate": 7.28643216080402e-06,
      "loss": 0.3161,
      "step": 17100
    },
    {
      "epoch": 0.6202871229698376,
      "grad_norm": 0.0,
      "learning_rate": 7.261306532663317e-06,
      "loss": 0.0052,
      "step": 17110
    },
    {
      "epoch": 0.6206496519721578,
      "grad_norm": 0.0,
      "learning_rate": 7.236180904522613e-06,
      "loss": 0.1914,
      "step": 17120
    },
    {
      "epoch": 0.621012180974478,
      "grad_norm": 0.0,
      "learning_rate": 7.2110552763819105e-06,
      "loss": 0.7724,
      "step": 17130
    },
    {
      "epoch": 0.6213747099767981,
      "grad_norm": 16.236433264012103,
      "learning_rate": 7.185929648241206e-06,
      "loss": 0.712,
      "step": 17140
    },
    {
      "epoch": 0.6217372389791184,
      "grad_norm": 13.82598522462832,
      "learning_rate": 7.160804020100504e-06,
      "loss": 0.0436,
      "step": 17150
    },
    {
      "epoch": 0.6220997679814385,
      "grad_norm": 0.0,
      "learning_rate": 7.1356783919597995e-06,
      "loss": 0.1911,
      "step": 17160
    },
    {
      "epoch": 0.6224622969837587,
      "grad_norm": 0.857058993562491,
      "learning_rate": 7.110552763819096e-06,
      "loss": 0.3257,
      "step": 17170
    },
    {
      "epoch": 0.6228248259860789,
      "grad_norm": 0.0,
      "learning_rate": 7.085427135678392e-06,
      "loss": 0.9498,
      "step": 17180
    },
    {
      "epoch": 0.6231873549883991,
      "grad_norm": 0.0,
      "learning_rate": 7.060301507537689e-06,
      "loss": 0.4346,
      "step": 17190
    },
    {
      "epoch": 0.6235498839907193,
      "grad_norm": 8.178111043764362,
      "learning_rate": 7.035175879396985e-06,
      "loss": 0.2156,
      "step": 17200
    },
    {
      "epoch": 0.6239124129930395,
      "grad_norm": 0.0,
      "learning_rate": 7.010050251256283e-06,
      "loss": 0.3382,
      "step": 17210
    },
    {
      "epoch": 0.6242749419953596,
      "grad_norm": 0.5065246096259369,
      "learning_rate": 6.984924623115578e-06,
      "loss": 0.3485,
      "step": 17220
    },
    {
      "epoch": 0.6246374709976799,
      "grad_norm": 0.0,
      "learning_rate": 6.959798994974874e-06,
      "loss": 0.8254,
      "step": 17230
    },
    {
      "epoch": 0.625,
      "grad_norm": 0.0,
      "learning_rate": 6.934673366834172e-06,
      "loss": 0.2353,
      "step": 17240
    },
    {
      "epoch": 0.6253625290023201,
      "grad_norm": 0.0,
      "learning_rate": 6.909547738693467e-06,
      "loss": 0.0052,
      "step": 17250
    },
    {
      "epoch": 0.6257250580046404,
      "grad_norm": 0.37825357127095277,
      "learning_rate": 6.884422110552764e-06,
      "loss": 0.0883,
      "step": 17260
    },
    {
      "epoch": 0.6260875870069605,
      "grad_norm": 0.0,
      "learning_rate": 6.85929648241206e-06,
      "loss": 0.7282,
      "step": 17270
    },
    {
      "epoch": 0.6264501160092807,
      "grad_norm": 0.0,
      "learning_rate": 6.834170854271357e-06,
      "loss": 0.0,
      "step": 17280
    },
    {
      "epoch": 0.6268126450116009,
      "grad_norm": 0.0,
      "learning_rate": 6.809045226130653e-06,
      "loss": 0.0018,
      "step": 17290
    },
    {
      "epoch": 0.6271751740139211,
      "grad_norm": 0.0,
      "learning_rate": 6.7839195979899505e-06,
      "loss": 0.5231,
      "step": 17300
    },
    {
      "epoch": 0.6275377030162413,
      "grad_norm": 0.0,
      "learning_rate": 6.758793969849246e-06,
      "loss": 0.1644,
      "step": 17310
    },
    {
      "epoch": 0.6279002320185615,
      "grad_norm": 0.0,
      "learning_rate": 6.733668341708544e-06,
      "loss": 0.1056,
      "step": 17320
    },
    {
      "epoch": 0.6282627610208816,
      "grad_norm": 0.0,
      "learning_rate": 6.7085427135678395e-06,
      "loss": 0.8647,
      "step": 17330
    },
    {
      "epoch": 0.6286252900232019,
      "grad_norm": 0.0,
      "learning_rate": 6.683417085427136e-06,
      "loss": 0.1098,
      "step": 17340
    },
    {
      "epoch": 0.628987819025522,
      "grad_norm": 27.704961295246267,
      "learning_rate": 6.658291457286432e-06,
      "loss": 0.0913,
      "step": 17350
    },
    {
      "epoch": 0.6293503480278422,
      "grad_norm": 0.0,
      "learning_rate": 6.633165829145729e-06,
      "loss": 0.6047,
      "step": 17360
    },
    {
      "epoch": 0.6297128770301624,
      "grad_norm": 7.642339283978782,
      "learning_rate": 6.608040201005025e-06,
      "loss": 0.396,
      "step": 17370
    },
    {
      "epoch": 0.6300754060324826,
      "grad_norm": 13.954582112642305,
      "learning_rate": 6.582914572864323e-06,
      "loss": 0.6263,
      "step": 17380
    },
    {
      "epoch": 0.6304379350348028,
      "grad_norm": 7.355099742220875,
      "learning_rate": 6.557788944723618e-06,
      "loss": 0.3045,
      "step": 17390
    },
    {
      "epoch": 0.630800464037123,
      "grad_norm": 14.401212725965673,
      "learning_rate": 6.532663316582915e-06,
      "loss": 0.6003,
      "step": 17400
    },
    {
      "epoch": 0.6311629930394431,
      "grad_norm": 4.858989737101612,
      "learning_rate": 6.507537688442212e-06,
      "loss": 0.3145,
      "step": 17410
    },
    {
      "epoch": 0.6315255220417634,
      "grad_norm": 43.65847429686117,
      "learning_rate": 6.482412060301508e-06,
      "loss": 0.3185,
      "step": 17420
    },
    {
      "epoch": 0.6318880510440835,
      "grad_norm": 1.324731463085034,
      "learning_rate": 6.457286432160804e-06,
      "loss": 0.4224,
      "step": 17430
    },
    {
      "epoch": 0.6322505800464037,
      "grad_norm": 0.0,
      "learning_rate": 6.4321608040201015e-06,
      "loss": 0.0844,
      "step": 17440
    },
    {
      "epoch": 0.6326131090487239,
      "grad_norm": 23.44249686316898,
      "learning_rate": 6.407035175879397e-06,
      "loss": 0.1196,
      "step": 17450
    },
    {
      "epoch": 0.6329756380510441,
      "grad_norm": 1.643527850670306,
      "learning_rate": 6.381909547738693e-06,
      "loss": 0.3371,
      "step": 17460
    },
    {
      "epoch": 0.6333381670533643,
      "grad_norm": 0.0,
      "learning_rate": 6.3567839195979905e-06,
      "loss": 0.0293,
      "step": 17470
    },
    {
      "epoch": 0.6337006960556845,
      "grad_norm": 0.22118775152088102,
      "learning_rate": 6.331658291457286e-06,
      "loss": 0.6826,
      "step": 17480
    },
    {
      "epoch": 0.6340632250580046,
      "grad_norm": 0.7271288643456072,
      "learning_rate": 6.306532663316583e-06,
      "loss": 0.1189,
      "step": 17490
    },
    {
      "epoch": 0.6344257540603249,
      "grad_norm": 0.0,
      "learning_rate": 6.2814070351758795e-06,
      "loss": 0.0,
      "step": 17500
    },
    {
      "epoch": 0.6344257540603249,
      "eval_loss": NaN,
      "eval_runtime": 67.3105,
      "eval_samples_per_second": 9.464,
      "eval_steps_per_second": 1.59,
      "step": 17500
    },
    {
      "epoch": 0.634788283062645,
      "grad_norm": 13.510471380157782,
      "learning_rate": 6.256281407035176e-06,
      "loss": 0.9625,
      "step": 17510
    },
    {
      "epoch": 0.6351508120649652,
      "grad_norm": 0.0,
      "learning_rate": 6.231155778894473e-06,
      "loss": 0.2051,
      "step": 17520
    },
    {
      "epoch": 0.6355133410672854,
      "grad_norm": 0.0,
      "learning_rate": 6.206030150753769e-06,
      "loss": 0.0722,
      "step": 17530
    },
    {
      "epoch": 0.6358758700696056,
      "grad_norm": 0.2581389268023005,
      "learning_rate": 6.180904522613066e-06,
      "loss": 0.1062,
      "step": 17540
    },
    {
      "epoch": 0.6362383990719258,
      "grad_norm": 4.617712104027664,
      "learning_rate": 6.155778894472363e-06,
      "loss": 0.9658,
      "step": 17550
    },
    {
      "epoch": 0.636600928074246,
      "grad_norm": 0.0,
      "learning_rate": 6.130653266331659e-06,
      "loss": 0.4004,
      "step": 17560
    },
    {
      "epoch": 0.6369634570765661,
      "grad_norm": 0.0,
      "learning_rate": 6.105527638190955e-06,
      "loss": 1.1402,
      "step": 17570
    },
    {
      "epoch": 0.6373259860788864,
      "grad_norm": 1.0051992083252272,
      "learning_rate": 6.080402010050252e-06,
      "loss": 0.4922,
      "step": 17580
    },
    {
      "epoch": 0.6376885150812065,
      "grad_norm": 0.0,
      "learning_rate": 6.055276381909547e-06,
      "loss": 0.3673,
      "step": 17590
    },
    {
      "epoch": 0.6380510440835266,
      "grad_norm": 0.4286434667930615,
      "learning_rate": 6.030150753768844e-06,
      "loss": 0.0576,
      "step": 17600
    },
    {
      "epoch": 0.6384135730858469,
      "grad_norm": 52.64704574599842,
      "learning_rate": 6.005025125628141e-06,
      "loss": 0.9905,
      "step": 17610
    },
    {
      "epoch": 0.638776102088167,
      "grad_norm": 0.0,
      "learning_rate": 5.979899497487437e-06,
      "loss": 0.3478,
      "step": 17620
    },
    {
      "epoch": 0.6391386310904872,
      "grad_norm": 0.0,
      "learning_rate": 5.954773869346734e-06,
      "loss": 0.2611,
      "step": 17630
    },
    {
      "epoch": 0.6395011600928074,
      "grad_norm": 0.0,
      "learning_rate": 5.9296482412060305e-06,
      "loss": 0.1017,
      "step": 17640
    },
    {
      "epoch": 0.6398636890951276,
      "grad_norm": 0.0,
      "learning_rate": 5.904522613065327e-06,
      "loss": 1.0919,
      "step": 17650
    },
    {
      "epoch": 0.6402262180974478,
      "grad_norm": 0.0,
      "learning_rate": 5.879396984924623e-06,
      "loss": 0.6399,
      "step": 17660
    },
    {
      "epoch": 0.640588747099768,
      "grad_norm": 0.0,
      "learning_rate": 5.8542713567839195e-06,
      "loss": 0.3394,
      "step": 17670
    },
    {
      "epoch": 0.6409512761020881,
      "grad_norm": 0.0,
      "learning_rate": 5.829145728643216e-06,
      "loss": 0.4477,
      "step": 17680
    },
    {
      "epoch": 0.6413138051044084,
      "grad_norm": 0.0,
      "learning_rate": 5.804020100502513e-06,
      "loss": 0.5085,
      "step": 17690
    },
    {
      "epoch": 0.6416763341067285,
      "grad_norm": 0.0,
      "learning_rate": 5.778894472361809e-06,
      "loss": 0.5896,
      "step": 17700
    },
    {
      "epoch": 0.6420388631090487,
      "grad_norm": 29.979560501307596,
      "learning_rate": 5.753768844221106e-06,
      "loss": 0.3559,
      "step": 17710
    },
    {
      "epoch": 0.6424013921113689,
      "grad_norm": 28.631505768272017,
      "learning_rate": 5.728643216080403e-06,
      "loss": 0.3967,
      "step": 17720
    },
    {
      "epoch": 0.6427639211136891,
      "grad_norm": 0.0,
      "learning_rate": 5.703517587939699e-06,
      "loss": 0.1592,
      "step": 17730
    },
    {
      "epoch": 0.6431264501160093,
      "grad_norm": 0.0,
      "learning_rate": 5.678391959798995e-06,
      "loss": 0.0,
      "step": 17740
    },
    {
      "epoch": 0.6434889791183295,
      "grad_norm": 35.98021747856296,
      "learning_rate": 5.653266331658292e-06,
      "loss": 0.3822,
      "step": 17750
    },
    {
      "epoch": 0.6438515081206496,
      "grad_norm": 0.0,
      "learning_rate": 5.628140703517588e-06,
      "loss": 0.775,
      "step": 17760
    },
    {
      "epoch": 0.6442140371229699,
      "grad_norm": 19.9108678231438,
      "learning_rate": 5.603015075376885e-06,
      "loss": 0.3167,
      "step": 17770
    },
    {
      "epoch": 0.64457656612529,
      "grad_norm": 0.0,
      "learning_rate": 5.5778894472361815e-06,
      "loss": 0.0622,
      "step": 17780
    },
    {
      "epoch": 0.6449390951276102,
      "grad_norm": 0.0,
      "learning_rate": 5.552763819095478e-06,
      "loss": 0.007,
      "step": 17790
    },
    {
      "epoch": 0.6453016241299304,
      "grad_norm": 29.700595384788794,
      "learning_rate": 5.527638190954775e-06,
      "loss": 0.0913,
      "step": 17800
    },
    {
      "epoch": 0.6456641531322506,
      "grad_norm": 37.20243758552237,
      "learning_rate": 5.5025125628140705e-06,
      "loss": 0.7823,
      "step": 17810
    },
    {
      "epoch": 0.6460266821345708,
      "grad_norm": 0.0,
      "learning_rate": 5.477386934673367e-06,
      "loss": 0.363,
      "step": 17820
    },
    {
      "epoch": 0.646389211136891,
      "grad_norm": 0.0,
      "learning_rate": 5.452261306532663e-06,
      "loss": 0.6683,
      "step": 17830
    },
    {
      "epoch": 0.6467517401392111,
      "grad_norm": 26.511929112267676,
      "learning_rate": 5.4271356783919595e-06,
      "loss": 0.2528,
      "step": 17840
    },
    {
      "epoch": 0.6471142691415314,
      "grad_norm": 0.0,
      "learning_rate": 5.402010050251256e-06,
      "loss": 0.304,
      "step": 17850
    },
    {
      "epoch": 0.6474767981438515,
      "grad_norm": 0.0,
      "learning_rate": 5.376884422110553e-06,
      "loss": 0.0953,
      "step": 17860
    },
    {
      "epoch": 0.6478393271461717,
      "grad_norm": 0.1070151692861266,
      "learning_rate": 5.351758793969849e-06,
      "loss": 0.814,
      "step": 17870
    },
    {
      "epoch": 0.6482018561484919,
      "grad_norm": 0.0,
      "learning_rate": 5.326633165829146e-06,
      "loss": 0.082,
      "step": 17880
    },
    {
      "epoch": 0.648564385150812,
      "grad_norm": 0.0,
      "learning_rate": 5.301507537688443e-06,
      "loss": 0.0149,
      "step": 17890
    },
    {
      "epoch": 0.6489269141531323,
      "grad_norm": 0.19687779704635014,
      "learning_rate": 5.276381909547739e-06,
      "loss": 0.1532,
      "step": 17900
    },
    {
      "epoch": 0.6492894431554525,
      "grad_norm": 0.0,
      "learning_rate": 5.251256281407035e-06,
      "loss": 0.4685,
      "step": 17910
    },
    {
      "epoch": 0.6496519721577726,
      "grad_norm": 0.0,
      "learning_rate": 5.226130653266332e-06,
      "loss": 0.0989,
      "step": 17920
    },
    {
      "epoch": 0.6500145011600929,
      "grad_norm": 19.06023055778748,
      "learning_rate": 5.201005025125628e-06,
      "loss": 0.1861,
      "step": 17930
    },
    {
      "epoch": 0.650377030162413,
      "grad_norm": 0.0,
      "learning_rate": 5.175879396984925e-06,
      "loss": 0.3376,
      "step": 17940
    },
    {
      "epoch": 0.6507395591647331,
      "grad_norm": 1.9774834217673907,
      "learning_rate": 5.1507537688442215e-06,
      "loss": 0.2989,
      "step": 17950
    },
    {
      "epoch": 0.6511020881670534,
      "grad_norm": 17.255151836265544,
      "learning_rate": 5.125628140703518e-06,
      "loss": 0.173,
      "step": 17960
    },
    {
      "epoch": 0.6514646171693735,
      "grad_norm": 0.0,
      "learning_rate": 5.100502512562815e-06,
      "loss": 0.2536,
      "step": 17970
    },
    {
      "epoch": 0.6518271461716937,
      "grad_norm": 0.0,
      "learning_rate": 5.075376884422111e-06,
      "loss": 0.0515,
      "step": 17980
    },
    {
      "epoch": 0.6521896751740139,
      "grad_norm": 0.24153274043153045,
      "learning_rate": 5.050251256281407e-06,
      "loss": 0.0162,
      "step": 17990
    },
    {
      "epoch": 0.6525522041763341,
      "grad_norm": 14.095218556561177,
      "learning_rate": 5.025125628140704e-06,
      "loss": 0.1681,
      "step": 18000
    },
    {
      "epoch": 0.6525522041763341,
      "eval_loss": NaN,
      "eval_runtime": 67.3078,
      "eval_samples_per_second": 9.464,
      "eval_steps_per_second": 1.59,
      "step": 18000
    },
    {
      "epoch": 0.6529147331786543,
      "grad_norm": 5.8260854471045045,
      "learning_rate": 5e-06,
      "loss": 0.0156,
      "step": 18010
    },
    {
      "epoch": 0.6532772621809745,
      "grad_norm": 0.0,
      "learning_rate": 4.974874371859297e-06,
      "loss": 0.1851,
      "step": 18020
    },
    {
      "epoch": 0.6536397911832946,
      "grad_norm": 7.489527193229557,
      "learning_rate": 4.949748743718594e-06,
      "loss": 0.0841,
      "step": 18030
    },
    {
      "epoch": 0.6540023201856149,
      "grad_norm": 0.0,
      "learning_rate": 4.9246231155778894e-06,
      "loss": 0.0656,
      "step": 18040
    },
    {
      "epoch": 0.654364849187935,
      "grad_norm": 0.0,
      "learning_rate": 4.899497487437186e-06,
      "loss": 0.0058,
      "step": 18050
    },
    {
      "epoch": 0.6547273781902552,
      "grad_norm": 0.0,
      "learning_rate": 4.874371859296483e-06,
      "loss": 0.1907,
      "step": 18060
    },
    {
      "epoch": 0.6550899071925754,
      "grad_norm": 0.0,
      "learning_rate": 4.849246231155779e-06,
      "loss": 0.3488,
      "step": 18070
    },
    {
      "epoch": 0.6554524361948956,
      "grad_norm": 12.544665074292412,
      "learning_rate": 4.824120603015075e-06,
      "loss": 0.9573,
      "step": 18080
    },
    {
      "epoch": 0.6558149651972158,
      "grad_norm": 0.0,
      "learning_rate": 4.798994974874372e-06,
      "loss": 0.1305,
      "step": 18090
    },
    {
      "epoch": 0.656177494199536,
      "grad_norm": 0.0,
      "learning_rate": 4.773869346733668e-06,
      "loss": 0.5159,
      "step": 18100
    },
    {
      "epoch": 0.6565400232018561,
      "grad_norm": 0.0,
      "learning_rate": 4.748743718592965e-06,
      "loss": 0.3149,
      "step": 18110
    },
    {
      "epoch": 0.6569025522041764,
      "grad_norm": 24.042390897300415,
      "learning_rate": 4.7236180904522615e-06,
      "loss": 0.1514,
      "step": 18120
    },
    {
      "epoch": 0.6572650812064965,
      "grad_norm": 0.0,
      "learning_rate": 4.698492462311558e-06,
      "loss": 0.0888,
      "step": 18130
    },
    {
      "epoch": 0.6576276102088167,
      "grad_norm": 0.0,
      "learning_rate": 4.673366834170855e-06,
      "loss": 0.02,
      "step": 18140
    },
    {
      "epoch": 0.6579901392111369,
      "grad_norm": 0.0,
      "learning_rate": 4.6482412060301506e-06,
      "loss": 0.1819,
      "step": 18150
    },
    {
      "epoch": 0.6583526682134571,
      "grad_norm": 0.0,
      "learning_rate": 4.623115577889447e-06,
      "loss": 0.0441,
      "step": 18160
    },
    {
      "epoch": 0.6587151972157773,
      "grad_norm": 0.0,
      "learning_rate": 4.597989949748744e-06,
      "loss": 0.1304,
      "step": 18170
    },
    {
      "epoch": 0.6590777262180975,
      "grad_norm": 0.0,
      "learning_rate": 4.57286432160804e-06,
      "loss": 0.4629,
      "step": 18180
    },
    {
      "epoch": 0.6594402552204176,
      "grad_norm": 0.0,
      "learning_rate": 4.547738693467337e-06,
      "loss": 0.003,
      "step": 18190
    },
    {
      "epoch": 0.6598027842227379,
      "grad_norm": 0.0,
      "learning_rate": 4.522613065326634e-06,
      "loss": 0.0104,
      "step": 18200
    },
    {
      "epoch": 0.660165313225058,
      "grad_norm": 5.247994902864168,
      "learning_rate": 4.49748743718593e-06,
      "loss": 0.2331,
      "step": 18210
    },
    {
      "epoch": 0.6605278422273781,
      "grad_norm": 0.0,
      "learning_rate": 4.472361809045227e-06,
      "loss": 0.2705,
      "step": 18220
    },
    {
      "epoch": 0.6608903712296984,
      "grad_norm": 9.810008127440529,
      "learning_rate": 4.447236180904523e-06,
      "loss": 0.3784,
      "step": 18230
    },
    {
      "epoch": 0.6612529002320185,
      "grad_norm": 20.044786280508205,
      "learning_rate": 4.422110552763819e-06,
      "loss": 0.2113,
      "step": 18240
    },
    {
      "epoch": 0.6616154292343387,
      "grad_norm": 0.5177625507489447,
      "learning_rate": 4.396984924623116e-06,
      "loss": 0.0009,
      "step": 18250
    },
    {
      "epoch": 0.661977958236659,
      "grad_norm": 7.465259199094695,
      "learning_rate": 4.3718592964824125e-06,
      "loss": 0.1808,
      "step": 18260
    },
    {
      "epoch": 0.6623404872389791,
      "grad_norm": 0.0,
      "learning_rate": 4.346733668341708e-06,
      "loss": 0.2424,
      "step": 18270
    },
    {
      "epoch": 0.6627030162412993,
      "grad_norm": 0.0,
      "learning_rate": 4.321608040201005e-06,
      "loss": 0.1627,
      "step": 18280
    },
    {
      "epoch": 0.6630655452436195,
      "grad_norm": 3.9206161606438297,
      "learning_rate": 4.2964824120603016e-06,
      "loss": 0.5057,
      "step": 18290
    },
    {
      "epoch": 0.6634280742459396,
      "grad_norm": 0.0,
      "learning_rate": 4.271356783919598e-06,
      "loss": 0.5046,
      "step": 18300
    },
    {
      "epoch": 0.6637906032482599,
      "grad_norm": 14.246177829989062,
      "learning_rate": 4.246231155778895e-06,
      "loss": 0.4327,
      "step": 18310
    },
    {
      "epoch": 0.66415313225058,
      "grad_norm": 0.0,
      "learning_rate": 4.2211055276381906e-06,
      "loss": 0.6758,
      "step": 18320
    },
    {
      "epoch": 0.6645156612529002,
      "grad_norm": 0.0,
      "learning_rate": 4.195979899497487e-06,
      "loss": 0.1319,
      "step": 18330
    },
    {
      "epoch": 0.6648781902552204,
      "grad_norm": 0.0,
      "learning_rate": 4.170854271356784e-06,
      "loss": 0.0,
      "step": 18340
    },
    {
      "epoch": 0.6652407192575406,
      "grad_norm": 0.0,
      "learning_rate": 4.1457286432160804e-06,
      "loss": 0.4338,
      "step": 18350
    },
    {
      "epoch": 0.6656032482598608,
      "grad_norm": 4.521181060965724,
      "learning_rate": 4.120603015075377e-06,
      "loss": 0.0235,
      "step": 18360
    },
    {
      "epoch": 0.665965777262181,
      "grad_norm": 0.0,
      "learning_rate": 4.095477386934674e-06,
      "loss": 0.4236,
      "step": 18370
    },
    {
      "epoch": 0.6663283062645011,
      "grad_norm": 40.45518142465267,
      "learning_rate": 4.07035175879397e-06,
      "loss": 0.6809,
      "step": 18380
    },
    {
      "epoch": 0.6666908352668214,
      "grad_norm": 0.0,
      "learning_rate": 4.045226130653267e-06,
      "loss": 0.2126,
      "step": 18390
    },
    {
      "epoch": 0.6670533642691415,
      "grad_norm": 0.0,
      "learning_rate": 4.020100502512563e-06,
      "loss": 0.2339,
      "step": 18400
    },
    {
      "epoch": 0.6674158932714617,
      "grad_norm": 0.0,
      "learning_rate": 3.994974874371859e-06,
      "loss": 0.3149,
      "step": 18410
    },
    {
      "epoch": 0.6677784222737819,
      "grad_norm": 0.0,
      "learning_rate": 3.969849246231156e-06,
      "loss": 0.1007,
      "step": 18420
    },
    {
      "epoch": 0.6681409512761021,
      "grad_norm": 0.0,
      "learning_rate": 3.9447236180904526e-06,
      "loss": 0.0543,
      "step": 18430
    },
    {
      "epoch": 0.6685034802784223,
      "grad_norm": 0.5442430924155529,
      "learning_rate": 3.919597989949749e-06,
      "loss": 0.4819,
      "step": 18440
    },
    {
      "epoch": 0.6688660092807425,
      "grad_norm": 0.0,
      "learning_rate": 3.894472361809046e-06,
      "loss": 0.1027,
      "step": 18450
    },
    {
      "epoch": 0.6692285382830626,
      "grad_norm": 0.0,
      "learning_rate": 3.869346733668342e-06,
      "loss": 0.0132,
      "step": 18460
    },
    {
      "epoch": 0.6695910672853829,
      "grad_norm": 0.0,
      "learning_rate": 3.844221105527639e-06,
      "loss": 0.285,
      "step": 18470
    },
    {
      "epoch": 0.669953596287703,
      "grad_norm": 0.0,
      "learning_rate": 3.819095477386935e-06,
      "loss": 0.4633,
      "step": 18480
    },
    {
      "epoch": 0.6703161252900232,
      "grad_norm": 0.0,
      "learning_rate": 3.793969849246232e-06,
      "loss": 0.0,
      "step": 18490
    },
    {
      "epoch": 0.6706786542923434,
      "grad_norm": 0.0,
      "learning_rate": 3.7688442211055276e-06,
      "loss": 0.2404,
      "step": 18500
    },
    {
      "epoch": 0.6706786542923434,
      "eval_loss": NaN,
      "eval_runtime": 88.5995,
      "eval_samples_per_second": 7.19,
      "eval_steps_per_second": 1.208,
      "step": 18500
    },
    {
      "epoch": 0.6710411832946636,
      "grad_norm": 14.135645812765164,
      "learning_rate": 3.743718592964824e-06,
      "loss": 0.1106,
      "step": 18510
    },
    {
      "epoch": 0.6714037122969838,
      "grad_norm": 0.0,
      "learning_rate": 3.7185929648241204e-06,
      "loss": 0.2361,
      "step": 18520
    },
    {
      "epoch": 0.671766241299304,
      "grad_norm": 0.0,
      "learning_rate": 3.693467336683417e-06,
      "loss": 0.0054,
      "step": 18530
    },
    {
      "epoch": 0.6721287703016241,
      "grad_norm": 5.283602760416685,
      "learning_rate": 3.6683417085427137e-06,
      "loss": 0.4525,
      "step": 18540
    },
    {
      "epoch": 0.6724912993039444,
      "grad_norm": 0.0,
      "learning_rate": 3.64321608040201e-06,
      "loss": 0.4282,
      "step": 18550
    },
    {
      "epoch": 0.6728538283062645,
      "grad_norm": 0.0,
      "learning_rate": 3.6180904522613065e-06,
      "loss": 0.331,
      "step": 18560
    },
    {
      "epoch": 0.6732163573085846,
      "grad_norm": 0.0,
      "learning_rate": 3.592964824120603e-06,
      "loss": 0.0366,
      "step": 18570
    },
    {
      "epoch": 0.6735788863109049,
      "grad_norm": 0.0,
      "learning_rate": 3.5678391959798997e-06,
      "loss": 0.0146,
      "step": 18580
    },
    {
      "epoch": 0.673941415313225,
      "grad_norm": 0.0,
      "learning_rate": 3.542713567839196e-06,
      "loss": 0.2718,
      "step": 18590
    },
    {
      "epoch": 0.6743039443155452,
      "grad_norm": 0.0,
      "learning_rate": 3.5175879396984926e-06,
      "loss": 0.358,
      "step": 18600
    },
    {
      "epoch": 0.6746664733178654,
      "grad_norm": 14.935966636452907,
      "learning_rate": 3.492462311557789e-06,
      "loss": 0.0536,
      "step": 18610
    },
    {
      "epoch": 0.6750290023201856,
      "grad_norm": 0.0,
      "learning_rate": 3.467336683417086e-06,
      "loss": 0.15,
      "step": 18620
    },
    {
      "epoch": 0.6753915313225058,
      "grad_norm": 0.0,
      "learning_rate": 3.442211055276382e-06,
      "loss": 0.3341,
      "step": 18630
    },
    {
      "epoch": 0.675754060324826,
      "grad_norm": 43.83982826143583,
      "learning_rate": 3.4170854271356786e-06,
      "loss": 0.8841,
      "step": 18640
    },
    {
      "epoch": 0.6761165893271461,
      "grad_norm": 0.0,
      "learning_rate": 3.3919597989949752e-06,
      "loss": 0.2065,
      "step": 18650
    },
    {
      "epoch": 0.6764791183294664,
      "grad_norm": 0.0,
      "learning_rate": 3.366834170854272e-06,
      "loss": 0.2061,
      "step": 18660
    },
    {
      "epoch": 0.6768416473317865,
      "grad_norm": 0.0,
      "learning_rate": 3.341708542713568e-06,
      "loss": 0.0348,
      "step": 18670
    },
    {
      "epoch": 0.6772041763341067,
      "grad_norm": 21.912189369589473,
      "learning_rate": 3.3165829145728647e-06,
      "loss": 1.7622,
      "step": 18680
    },
    {
      "epoch": 0.6775667053364269,
      "grad_norm": 0.0,
      "learning_rate": 3.2914572864321613e-06,
      "loss": 0.4277,
      "step": 18690
    },
    {
      "epoch": 0.6779292343387471,
      "grad_norm": 0.0,
      "learning_rate": 3.2663316582914575e-06,
      "loss": 0.7876,
      "step": 18700
    },
    {
      "epoch": 0.6782917633410673,
      "grad_norm": 20.2805939319926,
      "learning_rate": 3.241206030150754e-06,
      "loss": 0.1898,
      "step": 18710
    },
    {
      "epoch": 0.6786542923433875,
      "grad_norm": 33.45727547524697,
      "learning_rate": 3.2160804020100507e-06,
      "loss": 0.2013,
      "step": 18720
    },
    {
      "epoch": 0.6790168213457076,
      "grad_norm": 0.0,
      "learning_rate": 3.1909547738693465e-06,
      "loss": 0.0,
      "step": 18730
    },
    {
      "epoch": 0.6793793503480279,
      "grad_norm": 21.6322933532868,
      "learning_rate": 3.165829145728643e-06,
      "loss": 0.3157,
      "step": 18740
    },
    {
      "epoch": 0.679741879350348,
      "grad_norm": 0.0,
      "learning_rate": 3.1407035175879398e-06,
      "loss": 0.7563,
      "step": 18750
    },
    {
      "epoch": 0.6801044083526682,
      "grad_norm": 0.0,
      "learning_rate": 3.1155778894472364e-06,
      "loss": 0.2035,
      "step": 18760
    },
    {
      "epoch": 0.6804669373549884,
      "grad_norm": 0.0,
      "learning_rate": 3.090452261306533e-06,
      "loss": 0.54,
      "step": 18770
    },
    {
      "epoch": 0.6808294663573086,
      "grad_norm": 0.0,
      "learning_rate": 3.0653266331658296e-06,
      "loss": 0.447,
      "step": 18780
    },
    {
      "epoch": 0.6811919953596288,
      "grad_norm": 0.0,
      "learning_rate": 3.040201005025126e-06,
      "loss": 0.0279,
      "step": 18790
    },
    {
      "epoch": 0.681554524361949,
      "grad_norm": 0.0,
      "learning_rate": 3.015075376884422e-06,
      "loss": 1.5854,
      "step": 18800
    },
    {
      "epoch": 0.6819170533642691,
      "grad_norm": 0.0,
      "learning_rate": 2.9899497487437186e-06,
      "loss": 0.2656,
      "step": 18810
    },
    {
      "epoch": 0.6822795823665894,
      "grad_norm": 14.680008686281383,
      "learning_rate": 2.9648241206030153e-06,
      "loss": 0.713,
      "step": 18820
    },
    {
      "epoch": 0.6826421113689095,
      "grad_norm": 0.0,
      "learning_rate": 2.9396984924623115e-06,
      "loss": 0.7451,
      "step": 18830
    },
    {
      "epoch": 0.6830046403712297,
      "grad_norm": 0.0,
      "learning_rate": 2.914572864321608e-06,
      "loss": 0.4811,
      "step": 18840
    },
    {
      "epoch": 0.6833671693735499,
      "grad_norm": 0.0,
      "learning_rate": 2.8894472361809047e-06,
      "loss": 0.0862,
      "step": 18850
    },
    {
      "epoch": 0.68372969837587,
      "grad_norm": 0.09017279224428297,
      "learning_rate": 2.8643216080402013e-06,
      "loss": 0.6009,
      "step": 18860
    },
    {
      "epoch": 0.6840922273781903,
      "grad_norm": 0.0,
      "learning_rate": 2.8391959798994975e-06,
      "loss": 0.0011,
      "step": 18870
    },
    {
      "epoch": 0.6844547563805105,
      "grad_norm": 39.31478530718437,
      "learning_rate": 2.814070351758794e-06,
      "loss": 0.19,
      "step": 18880
    },
    {
      "epoch": 0.6848172853828306,
      "grad_norm": 0.0,
      "learning_rate": 2.7889447236180908e-06,
      "loss": 0.2365,
      "step": 18890
    },
    {
      "epoch": 0.6851798143851509,
      "grad_norm": 7.104192232177316,
      "learning_rate": 2.7638190954773874e-06,
      "loss": 0.138,
      "step": 18900
    },
    {
      "epoch": 0.685542343387471,
      "grad_norm": 25.816020586940052,
      "learning_rate": 2.7386934673366836e-06,
      "loss": 0.331,
      "step": 18910
    },
    {
      "epoch": 0.6859048723897911,
      "grad_norm": 9.191825004405876,
      "learning_rate": 2.7135678391959798e-06,
      "loss": 0.1457,
      "step": 18920
    },
    {
      "epoch": 0.6862674013921114,
      "grad_norm": 0.0,
      "learning_rate": 2.6884422110552764e-06,
      "loss": 0.5526,
      "step": 18930
    },
    {
      "epoch": 0.6866299303944315,
      "grad_norm": 0.0,
      "learning_rate": 2.663316582914573e-06,
      "loss": 0.5668,
      "step": 18940
    },
    {
      "epoch": 0.6869924593967517,
      "grad_norm": 0.0,
      "learning_rate": 2.6381909547738696e-06,
      "loss": 0.0358,
      "step": 18950
    },
    {
      "epoch": 0.6873549883990719,
      "grad_norm": 0.0,
      "learning_rate": 2.613065326633166e-06,
      "loss": 0.47,
      "step": 18960
    },
    {
      "epoch": 0.6877175174013921,
      "grad_norm": 0.0,
      "learning_rate": 2.5879396984924625e-06,
      "loss": 0.7434,
      "step": 18970
    },
    {
      "epoch": 0.6880800464037123,
      "grad_norm": 0.9086168884847303,
      "learning_rate": 2.562814070351759e-06,
      "loss": 0.0492,
      "step": 18980
    },
    {
      "epoch": 0.6884425754060325,
      "grad_norm": 0.0,
      "learning_rate": 2.5376884422110557e-06,
      "loss": 0.6408,
      "step": 18990
    },
    {
      "epoch": 0.6888051044083526,
      "grad_norm": 20.01106261429225,
      "learning_rate": 2.512562814070352e-06,
      "loss": 0.8537,
      "step": 19000
    },
    {
      "epoch": 0.6888051044083526,
      "eval_loss": NaN,
      "eval_runtime": 67.4614,
      "eval_samples_per_second": 9.442,
      "eval_steps_per_second": 1.586,
      "step": 19000
    },
    {
      "epoch": 0.6891676334106729,
      "grad_norm": 0.0,
      "learning_rate": 2.4874371859296485e-06,
      "loss": 0.1886,
      "step": 19010
    },
    {
      "epoch": 0.689530162412993,
      "grad_norm": 0.0,
      "learning_rate": 2.4623115577889447e-06,
      "loss": 0.1402,
      "step": 19020
    },
    {
      "epoch": 0.6898926914153132,
      "grad_norm": 0.0,
      "learning_rate": 2.4371859296482413e-06,
      "loss": 0.3891,
      "step": 19030
    },
    {
      "epoch": 0.6902552204176334,
      "grad_norm": 0.368070534885132,
      "learning_rate": 2.4120603015075375e-06,
      "loss": 0.0012,
      "step": 19040
    },
    {
      "epoch": 0.6906177494199536,
      "grad_norm": 29.853021302028626,
      "learning_rate": 2.386934673366834e-06,
      "loss": 0.7298,
      "step": 19050
    },
    {
      "epoch": 0.6909802784222738,
      "grad_norm": 0.0,
      "learning_rate": 2.3618090452261308e-06,
      "loss": 0.0429,
      "step": 19060
    },
    {
      "epoch": 0.691342807424594,
      "grad_norm": 4.870966881367086,
      "learning_rate": 2.3366834170854274e-06,
      "loss": 0.0081,
      "step": 19070
    },
    {
      "epoch": 0.6917053364269141,
      "grad_norm": 0.0,
      "learning_rate": 2.3115577889447236e-06,
      "loss": 0.9046,
      "step": 19080
    },
    {
      "epoch": 0.6920678654292344,
      "grad_norm": 0.0,
      "learning_rate": 2.28643216080402e-06,
      "loss": 0.5974,
      "step": 19090
    },
    {
      "epoch": 0.6924303944315545,
      "grad_norm": 0.0793593526984009,
      "learning_rate": 2.261306532663317e-06,
      "loss": 0.1331,
      "step": 19100
    },
    {
      "epoch": 0.6927929234338747,
      "grad_norm": 0.0,
      "learning_rate": 2.2361809045226135e-06,
      "loss": 0.007,
      "step": 19110
    },
    {
      "epoch": 0.6931554524361949,
      "grad_norm": 0.0,
      "learning_rate": 2.2110552763819096e-06,
      "loss": 0.2449,
      "step": 19120
    },
    {
      "epoch": 0.6935179814385151,
      "grad_norm": 0.0,
      "learning_rate": 2.1859296482412063e-06,
      "loss": 0.6593,
      "step": 19130
    },
    {
      "epoch": 0.6938805104408353,
      "grad_norm": 33.102088922236085,
      "learning_rate": 2.1608040201005025e-06,
      "loss": 0.9949,
      "step": 19140
    },
    {
      "epoch": 0.6942430394431555,
      "grad_norm": 0.0,
      "learning_rate": 2.135678391959799e-06,
      "loss": 0.4354,
      "step": 19150
    },
    {
      "epoch": 0.6946055684454756,
      "grad_norm": 9.697273295880652,
      "learning_rate": 2.1105527638190953e-06,
      "loss": 0.1305,
      "step": 19160
    },
    {
      "epoch": 0.6949680974477959,
      "grad_norm": 0.0,
      "learning_rate": 2.085427135678392e-06,
      "loss": 0.1492,
      "step": 19170
    },
    {
      "epoch": 0.695330626450116,
      "grad_norm": 0.0,
      "learning_rate": 2.0603015075376885e-06,
      "loss": 0.721,
      "step": 19180
    },
    {
      "epoch": 0.6956931554524362,
      "grad_norm": 0.0,
      "learning_rate": 2.035175879396985e-06,
      "loss": 0.0,
      "step": 19190
    },
    {
      "epoch": 0.6960556844547564,
      "grad_norm": 0.4836121212084293,
      "learning_rate": 2.0100502512562813e-06,
      "loss": 0.2374,
      "step": 19200
    },
    {
      "epoch": 0.6964182134570766,
      "grad_norm": 0.0,
      "learning_rate": 1.984924623115578e-06,
      "loss": 0.1176,
      "step": 19210
    },
    {
      "epoch": 0.6967807424593968,
      "grad_norm": 0.0,
      "learning_rate": 1.9597989949748746e-06,
      "loss": 0.3528,
      "step": 19220
    },
    {
      "epoch": 0.697143271461717,
      "grad_norm": 0.0,
      "learning_rate": 1.934673366834171e-06,
      "loss": 0.863,
      "step": 19230
    },
    {
      "epoch": 0.6975058004640371,
      "grad_norm": 0.0,
      "learning_rate": 1.9095477386934674e-06,
      "loss": 0.0561,
      "step": 19240
    },
    {
      "epoch": 0.6978683294663574,
      "grad_norm": 6.0909304624930485,
      "learning_rate": 1.8844221105527638e-06,
      "loss": 0.0247,
      "step": 19250
    },
    {
      "epoch": 0.6982308584686775,
      "grad_norm": 0.0,
      "learning_rate": 1.8592964824120602e-06,
      "loss": 0.5623,
      "step": 19260
    },
    {
      "epoch": 0.6985933874709976,
      "grad_norm": 0.0,
      "learning_rate": 1.8341708542713568e-06,
      "loss": 0.0347,
      "step": 19270
    },
    {
      "epoch": 0.6989559164733179,
      "grad_norm": 0.0,
      "learning_rate": 1.8090452261306533e-06,
      "loss": 0.3542,
      "step": 19280
    },
    {
      "epoch": 0.699318445475638,
      "grad_norm": 0.0,
      "learning_rate": 1.7839195979899499e-06,
      "loss": 0.7446,
      "step": 19290
    },
    {
      "epoch": 0.6996809744779582,
      "grad_norm": 0.0,
      "learning_rate": 1.7587939698492463e-06,
      "loss": 0.0013,
      "step": 19300
    },
    {
      "epoch": 0.7000435034802784,
      "grad_norm": 0.0,
      "learning_rate": 1.733668341708543e-06,
      "loss": 0.3203,
      "step": 19310
    },
    {
      "epoch": 0.7004060324825986,
      "grad_norm": 0.0,
      "learning_rate": 1.7085427135678393e-06,
      "loss": 0.0,
      "step": 19320
    },
    {
      "epoch": 0.7007685614849188,
      "grad_norm": 0.0,
      "learning_rate": 1.683417085427136e-06,
      "loss": 0.0034,
      "step": 19330
    },
    {
      "epoch": 0.701131090487239,
      "grad_norm": 0.03670983371122472,
      "learning_rate": 1.6582914572864323e-06,
      "loss": 0.2675,
      "step": 19340
    },
    {
      "epoch": 0.7014936194895591,
      "grad_norm": 11.987665194744515,
      "learning_rate": 1.6331658291457288e-06,
      "loss": 0.0872,
      "step": 19350
    },
    {
      "epoch": 0.7018561484918794,
      "grad_norm": 0.0,
      "learning_rate": 1.6080402010050254e-06,
      "loss": 0.1584,
      "step": 19360
    },
    {
      "epoch": 0.7022186774941995,
      "grad_norm": 64.08410458871607,
      "learning_rate": 1.5829145728643216e-06,
      "loss": 1.1458,
      "step": 19370
    },
    {
      "epoch": 0.7025812064965197,
      "grad_norm": 0.0,
      "learning_rate": 1.5577889447236182e-06,
      "loss": 0.1318,
      "step": 19380
    },
    {
      "epoch": 0.7029437354988399,
      "grad_norm": 0.0,
      "learning_rate": 1.5326633165829148e-06,
      "loss": 0.2262,
      "step": 19390
    },
    {
      "epoch": 0.7033062645011601,
      "grad_norm": 0.0,
      "learning_rate": 1.507537688442211e-06,
      "loss": 0.2441,
      "step": 19400
    },
    {
      "epoch": 0.7036687935034803,
      "grad_norm": 0.0,
      "learning_rate": 1.4824120603015076e-06,
      "loss": 0.1683,
      "step": 19410
    },
    {
      "epoch": 0.7040313225058005,
      "grad_norm": 0.2878034726320745,
      "learning_rate": 1.457286432160804e-06,
      "loss": 0.2542,
      "step": 19420
    },
    {
      "epoch": 0.7043938515081206,
      "grad_norm": 17.529096556132572,
      "learning_rate": 1.4321608040201007e-06,
      "loss": 0.3441,
      "step": 19430
    },
    {
      "epoch": 0.7047563805104409,
      "grad_norm": 0.0,
      "learning_rate": 1.407035175879397e-06,
      "loss": 0.3306,
      "step": 19440
    },
    {
      "epoch": 0.705118909512761,
      "grad_norm": 0.0,
      "learning_rate": 1.3819095477386937e-06,
      "loss": 0.1434,
      "step": 19450
    },
    {
      "epoch": 0.7054814385150812,
      "grad_norm": 0.0,
      "learning_rate": 1.3567839195979899e-06,
      "loss": 0.8986,
      "step": 19460
    },
    {
      "epoch": 0.7058439675174014,
      "grad_norm": 4.300129493715245,
      "learning_rate": 1.3316582914572865e-06,
      "loss": 0.0254,
      "step": 19470
    },
    {
      "epoch": 0.7062064965197216,
      "grad_norm": 1.5241979021751464,
      "learning_rate": 1.306532663316583e-06,
      "loss": 0.2645,
      "step": 19480
    },
    {
      "epoch": 0.7065690255220418,
      "grad_norm": 46.88093191633193,
      "learning_rate": 1.2814070351758795e-06,
      "loss": 0.3899,
      "step": 19490
    },
    {
      "epoch": 0.706931554524362,
      "grad_norm": 0.0,
      "learning_rate": 1.256281407035176e-06,
      "loss": 0.4635,
      "step": 19500
    },
    {
      "epoch": 0.706931554524362,
      "eval_loss": NaN,
      "eval_runtime": 67.4633,
      "eval_samples_per_second": 9.442,
      "eval_steps_per_second": 1.586,
      "step": 19500
    },
    {
      "epoch": 0.7072940835266821,
      "grad_norm": 5.170468787479507,
      "learning_rate": 1.2311557788944724e-06,
      "loss": 0.057,
      "step": 19510
    },
    {
      "epoch": 0.7076566125290024,
      "grad_norm": 0.0,
      "learning_rate": 1.2060301507537688e-06,
      "loss": 0.0206,
      "step": 19520
    },
    {
      "epoch": 0.7080191415313225,
      "grad_norm": 0.4711214319955841,
      "learning_rate": 1.1809045226130654e-06,
      "loss": 0.0025,
      "step": 19530
    },
    {
      "epoch": 0.7083816705336426,
      "grad_norm": 0.0,
      "learning_rate": 1.1557788944723618e-06,
      "loss": 0.1652,
      "step": 19540
    },
    {
      "epoch": 0.7087441995359629,
      "grad_norm": 8.60665224640946,
      "learning_rate": 1.1306532663316584e-06,
      "loss": 0.5229,
      "step": 19550
    },
    {
      "epoch": 0.709106728538283,
      "grad_norm": 0.0,
      "learning_rate": 1.1055276381909548e-06,
      "loss": 0.8009,
      "step": 19560
    },
    {
      "epoch": 0.7094692575406032,
      "grad_norm": 0.5981738523186487,
      "learning_rate": 1.0804020100502512e-06,
      "loss": 0.3844,
      "step": 19570
    },
    {
      "epoch": 0.7098317865429234,
      "grad_norm": 0.0,
      "learning_rate": 1.0552763819095476e-06,
      "loss": 0.0633,
      "step": 19580
    },
    {
      "epoch": 0.7101943155452436,
      "grad_norm": 16.229205633009755,
      "learning_rate": 1.0301507537688443e-06,
      "loss": 0.1812,
      "step": 19590
    },
    {
      "epoch": 0.7105568445475638,
      "grad_norm": 0.0,
      "learning_rate": 1.0050251256281407e-06,
      "loss": 0.2556,
      "step": 19600
    },
    {
      "epoch": 0.710919373549884,
      "grad_norm": 8.283782226352454,
      "learning_rate": 9.798994974874373e-07,
      "loss": 0.2896,
      "step": 19610
    },
    {
      "epoch": 0.7112819025522041,
      "grad_norm": 0.0,
      "learning_rate": 9.547738693467337e-07,
      "loss": 0.0,
      "step": 19620
    },
    {
      "epoch": 0.7116444315545244,
      "grad_norm": 0.0,
      "learning_rate": 9.296482412060301e-07,
      "loss": 0.2364,
      "step": 19630
    },
    {
      "epoch": 0.7120069605568445,
      "grad_norm": 0.0,
      "learning_rate": 9.045226130653266e-07,
      "loss": 0.3512,
      "step": 19640
    },
    {
      "epoch": 0.7123694895591647,
      "grad_norm": 0.0,
      "learning_rate": 8.793969849246231e-07,
      "loss": 0.9559,
      "step": 19650
    },
    {
      "epoch": 0.7127320185614849,
      "grad_norm": 0.0,
      "learning_rate": 8.542713567839197e-07,
      "loss": 0.9634,
      "step": 19660
    },
    {
      "epoch": 0.7130945475638051,
      "grad_norm": 0.0,
      "learning_rate": 8.291457286432162e-07,
      "loss": 0.1805,
      "step": 19670
    },
    {
      "epoch": 0.7134570765661253,
      "grad_norm": 0.0,
      "learning_rate": 8.040201005025127e-07,
      "loss": 1.1769,
      "step": 19680
    },
    {
      "epoch": 0.7138196055684455,
      "grad_norm": 0.0,
      "learning_rate": 7.788944723618091e-07,
      "loss": 1.2987,
      "step": 19690
    },
    {
      "epoch": 0.7141821345707656,
      "grad_norm": 0.0,
      "learning_rate": 7.537688442211055e-07,
      "loss": 0.1175,
      "step": 19700
    },
    {
      "epoch": 0.7145446635730859,
      "grad_norm": 0.0,
      "learning_rate": 7.28643216080402e-07,
      "loss": 0.0916,
      "step": 19710
    },
    {
      "epoch": 0.714907192575406,
      "grad_norm": 9.649522728062488,
      "learning_rate": 7.035175879396985e-07,
      "loss": 0.4656,
      "step": 19720
    },
    {
      "epoch": 0.7152697215777262,
      "grad_norm": 0.0,
      "learning_rate": 6.783919597989949e-07,
      "loss": 0.633,
      "step": 19730
    },
    {
      "epoch": 0.7156322505800464,
      "grad_norm": 0.09119960583825953,
      "learning_rate": 6.532663316582915e-07,
      "loss": 0.0013,
      "step": 19740
    },
    {
      "epoch": 0.7159947795823666,
      "grad_norm": 24.38390011792489,
      "learning_rate": 6.28140703517588e-07,
      "loss": 0.0351,
      "step": 19750
    },
    {
      "epoch": 0.7163573085846868,
      "grad_norm": 0.0,
      "learning_rate": 6.030150753768844e-07,
      "loss": 0.0365,
      "step": 19760
    },
    {
      "epoch": 0.716719837587007,
      "grad_norm": 0.0,
      "learning_rate": 5.778894472361809e-07,
      "loss": 0.4158,
      "step": 19770
    },
    {
      "epoch": 0.7170823665893271,
      "grad_norm": 0.0,
      "learning_rate": 5.527638190954774e-07,
      "loss": 0.0987,
      "step": 19780
    },
    {
      "epoch": 0.7174448955916474,
      "grad_norm": 21.68680556007248,
      "learning_rate": 5.276381909547738e-07,
      "loss": 0.2941,
      "step": 19790
    },
    {
      "epoch": 0.7178074245939675,
      "grad_norm": 0.24606002849057554,
      "learning_rate": 5.025125628140703e-07,
      "loss": 0.2037,
      "step": 19800
    },
    {
      "epoch": 0.7181699535962877,
      "grad_norm": 0.0,
      "learning_rate": 4.773869346733669e-07,
      "loss": 0.7749,
      "step": 19810
    },
    {
      "epoch": 0.7185324825986079,
      "grad_norm": 0.0,
      "learning_rate": 4.522613065326633e-07,
      "loss": 0.0697,
      "step": 19820
    },
    {
      "epoch": 0.7188950116009281,
      "grad_norm": 25.521335427671467,
      "learning_rate": 4.2713567839195983e-07,
      "loss": 0.479,
      "step": 19830
    },
    {
      "epoch": 0.7192575406032483,
      "grad_norm": 0.22670030513584297,
      "learning_rate": 4.0201005025125634e-07,
      "loss": 0.0076,
      "step": 19840
    },
    {
      "epoch": 0.7196200696055685,
      "grad_norm": 0.0,
      "learning_rate": 3.7688442211055275e-07,
      "loss": 0.0047,
      "step": 19850
    },
    {
      "epoch": 0.7199825986078886,
      "grad_norm": 0.0,
      "learning_rate": 3.5175879396984927e-07,
      "loss": 0.4312,
      "step": 19860
    },
    {
      "epoch": 0.7203451276102089,
      "grad_norm": 0.0,
      "learning_rate": 3.2663316582914573e-07,
      "loss": 0.4997,
      "step": 19870
    },
    {
      "epoch": 0.720707656612529,
      "grad_norm": 11.681165641206562,
      "learning_rate": 3.015075376884422e-07,
      "loss": 0.4204,
      "step": 19880
    },
    {
      "epoch": 0.7210701856148491,
      "grad_norm": 0.14411476414991625,
      "learning_rate": 2.763819095477387e-07,
      "loss": 0.0721,
      "step": 19890
    },
    {
      "epoch": 0.7214327146171694,
      "grad_norm": 0.0,
      "learning_rate": 2.5125628140703517e-07,
      "loss": 1.3455,
      "step": 19900
    },
    {
      "epoch": 0.7217952436194895,
      "grad_norm": 0.7422531098929885,
      "learning_rate": 2.2613065326633166e-07,
      "loss": 0.3342,
      "step": 19910
    },
    {
      "epoch": 0.7221577726218097,
      "grad_norm": 0.0,
      "learning_rate": 2.0100502512562817e-07,
      "loss": 0.0705,
      "step": 19920
    },
    {
      "epoch": 0.72252030162413,
      "grad_norm": 0.0,
      "learning_rate": 1.7587939698492463e-07,
      "loss": 0.4116,
      "step": 19930
    },
    {
      "epoch": 0.7228828306264501,
      "grad_norm": 0.0,
      "learning_rate": 1.507537688442211e-07,
      "loss": 1.1828,
      "step": 19940
    },
    {
      "epoch": 0.7232453596287703,
      "grad_norm": 0.0,
      "learning_rate": 1.2562814070351758e-07,
      "loss": 0.0057,
      "step": 19950
    },
    {
      "epoch": 0.7236078886310905,
      "grad_norm": 0.0,
      "learning_rate": 1.0050251256281409e-07,
      "loss": 0.0088,
      "step": 19960
    },
    {
      "epoch": 0.7239704176334106,
      "grad_norm": 0.0,
      "learning_rate": 7.537688442211055e-08,
      "loss": 0.606,
      "step": 19970
    },
    {
      "epoch": 0.7243329466357309,
      "grad_norm": 0.0,
      "learning_rate": 5.025125628140704e-08,
      "loss": 0.1546,
      "step": 19980
    },
    {
      "epoch": 0.724695475638051,
      "grad_norm": 0.0,
      "learning_rate": 2.512562814070352e-08,
      "loss": 0.1548,
      "step": 19990
    },
    {
      "epoch": 0.7250580046403712,
      "grad_norm": 0.0,
      "learning_rate": 0.0,
      "loss": 0.3417,
      "step": 20000
    },
    {
      "epoch": 0.7250580046403712,
      "eval_loss": NaN,
      "eval_runtime": 67.5337,
      "eval_samples_per_second": 9.432,
      "eval_steps_per_second": 1.584,
      "step": 20000
    }
  ],
  "logging_steps": 10,
  "max_steps": 20000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1541280890880000.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
