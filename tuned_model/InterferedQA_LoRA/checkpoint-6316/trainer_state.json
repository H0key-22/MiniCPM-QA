{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 6316,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0015832805573147563,
      "grad_norm": 13.23730839778858,
      "learning_rate": 5e-06,
      "loss": 0.8836,
      "step": 10
    },
    {
      "epoch": 0.0031665611146295125,
      "grad_norm": 8.97361490511667,
      "learning_rate": 1e-05,
      "loss": 0.5857,
      "step": 20
    },
    {
      "epoch": 0.004749841671944269,
      "grad_norm": 6.962192888866075,
      "learning_rate": 1.5e-05,
      "loss": 0.3371,
      "step": 30
    },
    {
      "epoch": 0.006333122229259025,
      "grad_norm": 5.591099798554615,
      "learning_rate": 2e-05,
      "loss": 0.326,
      "step": 40
    },
    {
      "epoch": 0.007916402786573781,
      "grad_norm": 3.6353830738574118,
      "learning_rate": 2.5e-05,
      "loss": 0.2285,
      "step": 50
    },
    {
      "epoch": 0.009499683343888538,
      "grad_norm": 7.924878516003145,
      "learning_rate": 3e-05,
      "loss": 0.37,
      "step": 60
    },
    {
      "epoch": 0.011082963901203294,
      "grad_norm": 4.584701033468178,
      "learning_rate": 3.5e-05,
      "loss": 0.293,
      "step": 70
    },
    {
      "epoch": 0.01266624445851805,
      "grad_norm": 4.328552225008267,
      "learning_rate": 4e-05,
      "loss": 0.2871,
      "step": 80
    },
    {
      "epoch": 0.014249525015832806,
      "grad_norm": 7.746960197617308,
      "learning_rate": 4.5e-05,
      "loss": 0.2586,
      "step": 90
    },
    {
      "epoch": 0.015832805573147563,
      "grad_norm": 4.873686784763313,
      "learning_rate": 5e-05,
      "loss": 0.3141,
      "step": 100
    },
    {
      "epoch": 0.01741608613046232,
      "grad_norm": 9.301857006114803,
      "learning_rate": 4.991956241956242e-05,
      "loss": 0.209,
      "step": 110
    },
    {
      "epoch": 0.018999366687777075,
      "grad_norm": 5.5495256994532065,
      "learning_rate": 4.983912483912484e-05,
      "loss": 0.2773,
      "step": 120
    },
    {
      "epoch": 0.02058264724509183,
      "grad_norm": 8.13303951712454,
      "learning_rate": 4.9758687258687257e-05,
      "loss": 0.263,
      "step": 130
    },
    {
      "epoch": 0.022165927802406588,
      "grad_norm": 7.410845268523297,
      "learning_rate": 4.967824967824968e-05,
      "loss": 0.2644,
      "step": 140
    },
    {
      "epoch": 0.023749208359721344,
      "grad_norm": 9.59139538427441,
      "learning_rate": 4.95978120978121e-05,
      "loss": 0.2361,
      "step": 150
    },
    {
      "epoch": 0.0253324889170361,
      "grad_norm": 7.818674074043696,
      "learning_rate": 4.951737451737452e-05,
      "loss": 0.3081,
      "step": 160
    },
    {
      "epoch": 0.026915769474350856,
      "grad_norm": 5.8163967401492105,
      "learning_rate": 4.943693693693694e-05,
      "loss": 0.1972,
      "step": 170
    },
    {
      "epoch": 0.028499050031665613,
      "grad_norm": 4.903425241763404,
      "learning_rate": 4.935649935649936e-05,
      "loss": 0.2159,
      "step": 180
    },
    {
      "epoch": 0.03008233058898037,
      "grad_norm": 6.5444077825176015,
      "learning_rate": 4.927606177606178e-05,
      "loss": 0.2948,
      "step": 190
    },
    {
      "epoch": 0.031665611146295125,
      "grad_norm": 6.4182177894089225,
      "learning_rate": 4.9195624195624197e-05,
      "loss": 0.2092,
      "step": 200
    },
    {
      "epoch": 0.03324889170360988,
      "grad_norm": 6.756912647820263,
      "learning_rate": 4.911518661518662e-05,
      "loss": 0.2028,
      "step": 210
    },
    {
      "epoch": 0.03483217226092464,
      "grad_norm": 8.441121094356474,
      "learning_rate": 4.903474903474904e-05,
      "loss": 0.4018,
      "step": 220
    },
    {
      "epoch": 0.036415452818239394,
      "grad_norm": 7.74863397188019,
      "learning_rate": 4.895431145431146e-05,
      "loss": 0.217,
      "step": 230
    },
    {
      "epoch": 0.03799873337555415,
      "grad_norm": 3.9854314861962625,
      "learning_rate": 4.8873873873873876e-05,
      "loss": 0.3153,
      "step": 240
    },
    {
      "epoch": 0.039582013932868906,
      "grad_norm": 6.0590766601145205,
      "learning_rate": 4.8793436293436294e-05,
      "loss": 0.2281,
      "step": 250
    },
    {
      "epoch": 0.04116529449018366,
      "grad_norm": 3.867854390296213,
      "learning_rate": 4.871299871299871e-05,
      "loss": 0.2717,
      "step": 260
    },
    {
      "epoch": 0.04274857504749842,
      "grad_norm": 3.9921650447325905,
      "learning_rate": 4.863256113256113e-05,
      "loss": 0.2105,
      "step": 270
    },
    {
      "epoch": 0.044331855604813175,
      "grad_norm": 7.257923663286878,
      "learning_rate": 4.8552123552123555e-05,
      "loss": 0.2639,
      "step": 280
    },
    {
      "epoch": 0.04591513616212793,
      "grad_norm": 6.345448834932644,
      "learning_rate": 4.847168597168598e-05,
      "loss": 0.2085,
      "step": 290
    },
    {
      "epoch": 0.04749841671944269,
      "grad_norm": 5.2062883355056195,
      "learning_rate": 4.83912483912484e-05,
      "loss": 0.2859,
      "step": 300
    },
    {
      "epoch": 0.049081697276757444,
      "grad_norm": 7.523439781687738,
      "learning_rate": 4.8310810810810816e-05,
      "loss": 0.2565,
      "step": 310
    },
    {
      "epoch": 0.0506649778340722,
      "grad_norm": 6.282674902998529,
      "learning_rate": 4.8230373230373234e-05,
      "loss": 0.2064,
      "step": 320
    },
    {
      "epoch": 0.052248258391386956,
      "grad_norm": 5.162358220626625,
      "learning_rate": 4.814993564993565e-05,
      "loss": 0.3514,
      "step": 330
    },
    {
      "epoch": 0.05383153894870171,
      "grad_norm": 4.8047504203832325,
      "learning_rate": 4.806949806949807e-05,
      "loss": 0.2323,
      "step": 340
    },
    {
      "epoch": 0.05541481950601647,
      "grad_norm": 2.9162999785482238,
      "learning_rate": 4.798906048906049e-05,
      "loss": 0.2242,
      "step": 350
    },
    {
      "epoch": 0.056998100063331225,
      "grad_norm": 6.4690598860519275,
      "learning_rate": 4.790862290862291e-05,
      "loss": 0.251,
      "step": 360
    },
    {
      "epoch": 0.05858138062064598,
      "grad_norm": 8.460788714931423,
      "learning_rate": 4.782818532818533e-05,
      "loss": 0.2158,
      "step": 370
    },
    {
      "epoch": 0.06016466117796074,
      "grad_norm": 5.984660567599051,
      "learning_rate": 4.774774774774775e-05,
      "loss": 0.1876,
      "step": 380
    },
    {
      "epoch": 0.061747941735275494,
      "grad_norm": 4.343007634896865,
      "learning_rate": 4.766731016731017e-05,
      "loss": 0.1805,
      "step": 390
    },
    {
      "epoch": 0.06333122229259025,
      "grad_norm": 9.609145941756763,
      "learning_rate": 4.758687258687259e-05,
      "loss": 0.2132,
      "step": 400
    },
    {
      "epoch": 0.064914502849905,
      "grad_norm": 8.600702088551587,
      "learning_rate": 4.750643500643501e-05,
      "loss": 0.1766,
      "step": 410
    },
    {
      "epoch": 0.06649778340721976,
      "grad_norm": 14.294205479939569,
      "learning_rate": 4.742599742599743e-05,
      "loss": 0.2784,
      "step": 420
    },
    {
      "epoch": 0.06808106396453452,
      "grad_norm": 9.874184490282959,
      "learning_rate": 4.734555984555985e-05,
      "loss": 0.2696,
      "step": 430
    },
    {
      "epoch": 0.06966434452184928,
      "grad_norm": 4.868168862052549,
      "learning_rate": 4.726512226512227e-05,
      "loss": 0.2801,
      "step": 440
    },
    {
      "epoch": 0.07124762507916403,
      "grad_norm": 5.688698778519092,
      "learning_rate": 4.718468468468469e-05,
      "loss": 0.2549,
      "step": 450
    },
    {
      "epoch": 0.07283090563647879,
      "grad_norm": 4.420582289163788,
      "learning_rate": 4.710424710424711e-05,
      "loss": 0.2005,
      "step": 460
    },
    {
      "epoch": 0.07441418619379354,
      "grad_norm": 4.037083626172724,
      "learning_rate": 4.7023809523809525e-05,
      "loss": 0.2032,
      "step": 470
    },
    {
      "epoch": 0.0759974667511083,
      "grad_norm": 12.706261504506289,
      "learning_rate": 4.694337194337194e-05,
      "loss": 0.1989,
      "step": 480
    },
    {
      "epoch": 0.07758074730842306,
      "grad_norm": 9.52221972320694,
      "learning_rate": 4.686293436293436e-05,
      "loss": 0.2149,
      "step": 490
    },
    {
      "epoch": 0.07916402786573781,
      "grad_norm": 6.732771751225609,
      "learning_rate": 4.6782496782496786e-05,
      "loss": 0.2827,
      "step": 500
    },
    {
      "epoch": 0.07916402786573781,
      "eval_loss": 0.26637667417526245,
      "eval_runtime": 306.0995,
      "eval_samples_per_second": 9.752,
      "eval_steps_per_second": 1.627,
      "step": 500
    },
    {
      "epoch": 0.08074730842305257,
      "grad_norm": 5.284415656259924,
      "learning_rate": 4.6702059202059204e-05,
      "loss": 0.1775,
      "step": 510
    },
    {
      "epoch": 0.08233058898036733,
      "grad_norm": 6.257029128363044,
      "learning_rate": 4.662162162162162e-05,
      "loss": 0.2226,
      "step": 520
    },
    {
      "epoch": 0.08391386953768208,
      "grad_norm": 6.449091576767021,
      "learning_rate": 4.654118404118405e-05,
      "loss": 0.2013,
      "step": 530
    },
    {
      "epoch": 0.08549715009499684,
      "grad_norm": 4.781890427326829,
      "learning_rate": 4.6460746460746465e-05,
      "loss": 0.2162,
      "step": 540
    },
    {
      "epoch": 0.0870804306523116,
      "grad_norm": 6.305823695250759,
      "learning_rate": 4.638030888030888e-05,
      "loss": 0.2247,
      "step": 550
    },
    {
      "epoch": 0.08866371120962635,
      "grad_norm": 2.964369101344559,
      "learning_rate": 4.62998712998713e-05,
      "loss": 0.2493,
      "step": 560
    },
    {
      "epoch": 0.0902469917669411,
      "grad_norm": 3.725166107160853,
      "learning_rate": 4.621943371943372e-05,
      "loss": 0.2234,
      "step": 570
    },
    {
      "epoch": 0.09183027232425586,
      "grad_norm": 3.8804778481229536,
      "learning_rate": 4.6138996138996144e-05,
      "loss": 0.1764,
      "step": 580
    },
    {
      "epoch": 0.09341355288157062,
      "grad_norm": 6.02673993451528,
      "learning_rate": 4.605855855855856e-05,
      "loss": 0.1427,
      "step": 590
    },
    {
      "epoch": 0.09499683343888538,
      "grad_norm": 7.3475241195423004,
      "learning_rate": 4.597812097812098e-05,
      "loss": 0.1766,
      "step": 600
    },
    {
      "epoch": 0.09658011399620013,
      "grad_norm": 11.519274936746642,
      "learning_rate": 4.58976833976834e-05,
      "loss": 0.131,
      "step": 610
    },
    {
      "epoch": 0.09816339455351489,
      "grad_norm": 8.91772920451384,
      "learning_rate": 4.5817245817245816e-05,
      "loss": 0.2501,
      "step": 620
    },
    {
      "epoch": 0.09974667511082964,
      "grad_norm": 13.591200596068697,
      "learning_rate": 4.5736808236808234e-05,
      "loss": 0.2234,
      "step": 630
    },
    {
      "epoch": 0.1013299556681444,
      "grad_norm": 9.872481399174717,
      "learning_rate": 4.565637065637066e-05,
      "loss": 0.1518,
      "step": 640
    },
    {
      "epoch": 0.10291323622545916,
      "grad_norm": 7.386736824905173,
      "learning_rate": 4.5575933075933084e-05,
      "loss": 0.1718,
      "step": 650
    },
    {
      "epoch": 0.10449651678277391,
      "grad_norm": 9.247238159267813,
      "learning_rate": 4.54954954954955e-05,
      "loss": 0.2223,
      "step": 660
    },
    {
      "epoch": 0.10607979734008867,
      "grad_norm": 4.633511109452098,
      "learning_rate": 4.541505791505792e-05,
      "loss": 0.2047,
      "step": 670
    },
    {
      "epoch": 0.10766307789740343,
      "grad_norm": 8.53402899449646,
      "learning_rate": 4.533462033462034e-05,
      "loss": 0.2755,
      "step": 680
    },
    {
      "epoch": 0.10924635845471818,
      "grad_norm": 8.657002660757323,
      "learning_rate": 4.5254182754182756e-05,
      "loss": 0.2126,
      "step": 690
    },
    {
      "epoch": 0.11082963901203294,
      "grad_norm": 3.597634115575571,
      "learning_rate": 4.5173745173745174e-05,
      "loss": 0.2677,
      "step": 700
    },
    {
      "epoch": 0.1124129195693477,
      "grad_norm": 11.421167604847055,
      "learning_rate": 4.509330759330759e-05,
      "loss": 0.1968,
      "step": 710
    },
    {
      "epoch": 0.11399620012666245,
      "grad_norm": 6.567888354729056,
      "learning_rate": 4.501287001287002e-05,
      "loss": 0.1836,
      "step": 720
    },
    {
      "epoch": 0.1155794806839772,
      "grad_norm": 3.371999466431056,
      "learning_rate": 4.4932432432432435e-05,
      "loss": 0.2579,
      "step": 730
    },
    {
      "epoch": 0.11716276124129196,
      "grad_norm": 12.114322955853163,
      "learning_rate": 4.485199485199485e-05,
      "loss": 0.1826,
      "step": 740
    },
    {
      "epoch": 0.11874604179860672,
      "grad_norm": 13.061733095572002,
      "learning_rate": 4.477155727155727e-05,
      "loss": 0.1399,
      "step": 750
    },
    {
      "epoch": 0.12032932235592148,
      "grad_norm": 8.224207933313158,
      "learning_rate": 4.4691119691119696e-05,
      "loss": 0.1565,
      "step": 760
    },
    {
      "epoch": 0.12191260291323623,
      "grad_norm": 17.19430706823164,
      "learning_rate": 4.4610682110682114e-05,
      "loss": 0.2263,
      "step": 770
    },
    {
      "epoch": 0.12349588347055099,
      "grad_norm": 22.9064884771863,
      "learning_rate": 4.453024453024453e-05,
      "loss": 0.0985,
      "step": 780
    },
    {
      "epoch": 0.12507916402786573,
      "grad_norm": 4.419493772075713,
      "learning_rate": 4.444980694980696e-05,
      "loss": 0.132,
      "step": 790
    },
    {
      "epoch": 0.1266624445851805,
      "grad_norm": 11.208014577046077,
      "learning_rate": 4.4369369369369375e-05,
      "loss": 0.2884,
      "step": 800
    },
    {
      "epoch": 0.12824572514249524,
      "grad_norm": 7.089885179803194,
      "learning_rate": 4.428893178893179e-05,
      "loss": 0.251,
      "step": 810
    },
    {
      "epoch": 0.12982900569981,
      "grad_norm": 6.894657952978829,
      "learning_rate": 4.420849420849421e-05,
      "loss": 0.1783,
      "step": 820
    },
    {
      "epoch": 0.13141228625712476,
      "grad_norm": 14.702975038256236,
      "learning_rate": 4.412805662805663e-05,
      "loss": 0.2595,
      "step": 830
    },
    {
      "epoch": 0.13299556681443953,
      "grad_norm": 1.735181328919885,
      "learning_rate": 4.404761904761905e-05,
      "loss": 0.1777,
      "step": 840
    },
    {
      "epoch": 0.13457884737175427,
      "grad_norm": 5.696638206796256,
      "learning_rate": 4.3967181467181465e-05,
      "loss": 0.2079,
      "step": 850
    },
    {
      "epoch": 0.13616212792906904,
      "grad_norm": 23.234599601722078,
      "learning_rate": 4.3886743886743883e-05,
      "loss": 0.2948,
      "step": 860
    },
    {
      "epoch": 0.13774540848638378,
      "grad_norm": 5.859274413199122,
      "learning_rate": 4.380630630630631e-05,
      "loss": 0.2523,
      "step": 870
    },
    {
      "epoch": 0.13932868904369855,
      "grad_norm": 6.697606516094656,
      "learning_rate": 4.3725868725868726e-05,
      "loss": 0.1996,
      "step": 880
    },
    {
      "epoch": 0.1409119696010133,
      "grad_norm": 8.88346180014793,
      "learning_rate": 4.364543114543115e-05,
      "loss": 0.2281,
      "step": 890
    },
    {
      "epoch": 0.14249525015832806,
      "grad_norm": 11.676381743716673,
      "learning_rate": 4.356499356499357e-05,
      "loss": 0.2028,
      "step": 900
    },
    {
      "epoch": 0.1440785307156428,
      "grad_norm": 10.91582778930135,
      "learning_rate": 4.348455598455599e-05,
      "loss": 0.2527,
      "step": 910
    },
    {
      "epoch": 0.14566181127295758,
      "grad_norm": 7.113481547066738,
      "learning_rate": 4.3404118404118405e-05,
      "loss": 0.173,
      "step": 920
    },
    {
      "epoch": 0.14724509183027232,
      "grad_norm": 1.9428533614145873,
      "learning_rate": 4.3323680823680823e-05,
      "loss": 0.1233,
      "step": 930
    },
    {
      "epoch": 0.1488283723875871,
      "grad_norm": 10.27868286363252,
      "learning_rate": 4.324324324324325e-05,
      "loss": 0.194,
      "step": 940
    },
    {
      "epoch": 0.15041165294490183,
      "grad_norm": 8.423341527868686,
      "learning_rate": 4.3162805662805666e-05,
      "loss": 0.1871,
      "step": 950
    },
    {
      "epoch": 0.1519949335022166,
      "grad_norm": 11.141619665997322,
      "learning_rate": 4.3082368082368084e-05,
      "loss": 0.1559,
      "step": 960
    },
    {
      "epoch": 0.15357821405953134,
      "grad_norm": 6.755345241440639,
      "learning_rate": 4.30019305019305e-05,
      "loss": 0.152,
      "step": 970
    },
    {
      "epoch": 0.1551614946168461,
      "grad_norm": 10.40382590712952,
      "learning_rate": 4.292149292149292e-05,
      "loss": 0.2311,
      "step": 980
    },
    {
      "epoch": 0.15674477517416086,
      "grad_norm": 11.243998643417033,
      "learning_rate": 4.284105534105534e-05,
      "loss": 0.2267,
      "step": 990
    },
    {
      "epoch": 0.15832805573147563,
      "grad_norm": 8.554203218312932,
      "learning_rate": 4.276061776061776e-05,
      "loss": 0.2319,
      "step": 1000
    },
    {
      "epoch": 0.15832805573147563,
      "eval_loss": 0.24407514929771423,
      "eval_runtime": 303.7186,
      "eval_samples_per_second": 9.828,
      "eval_steps_per_second": 1.64,
      "step": 1000
    },
    {
      "epoch": 0.15991133628879037,
      "grad_norm": 5.3270282231795765,
      "learning_rate": 4.268018018018018e-05,
      "loss": 0.1717,
      "step": 1010
    },
    {
      "epoch": 0.16149461684610514,
      "grad_norm": 10.042251590983048,
      "learning_rate": 4.2599742599742606e-05,
      "loss": 0.2577,
      "step": 1020
    },
    {
      "epoch": 0.16307789740341988,
      "grad_norm": 4.1233672176152,
      "learning_rate": 4.2519305019305024e-05,
      "loss": 0.1656,
      "step": 1030
    },
    {
      "epoch": 0.16466117796073465,
      "grad_norm": 9.649760315443478,
      "learning_rate": 4.243886743886744e-05,
      "loss": 0.234,
      "step": 1040
    },
    {
      "epoch": 0.1662444585180494,
      "grad_norm": 7.7388252171093,
      "learning_rate": 4.235842985842986e-05,
      "loss": 0.2044,
      "step": 1050
    },
    {
      "epoch": 0.16782773907536416,
      "grad_norm": 12.96610654064057,
      "learning_rate": 4.227799227799228e-05,
      "loss": 0.1488,
      "step": 1060
    },
    {
      "epoch": 0.1694110196326789,
      "grad_norm": 1.9060968431325256,
      "learning_rate": 4.2197554697554697e-05,
      "loss": 0.1434,
      "step": 1070
    },
    {
      "epoch": 0.17099430018999368,
      "grad_norm": 9.401181296934553,
      "learning_rate": 4.2117117117117115e-05,
      "loss": 0.1171,
      "step": 1080
    },
    {
      "epoch": 0.17257758074730842,
      "grad_norm": 2.9319262279685687,
      "learning_rate": 4.203667953667954e-05,
      "loss": 0.1624,
      "step": 1090
    },
    {
      "epoch": 0.1741608613046232,
      "grad_norm": 19.45698929364579,
      "learning_rate": 4.195624195624196e-05,
      "loss": 0.1293,
      "step": 1100
    },
    {
      "epoch": 0.17574414186193793,
      "grad_norm": 3.5392174423691625,
      "learning_rate": 4.1875804375804376e-05,
      "loss": 0.212,
      "step": 1110
    },
    {
      "epoch": 0.1773274224192527,
      "grad_norm": 29.50078620509545,
      "learning_rate": 4.17953667953668e-05,
      "loss": 0.3031,
      "step": 1120
    },
    {
      "epoch": 0.17891070297656744,
      "grad_norm": 5.369510597645519,
      "learning_rate": 4.171492921492922e-05,
      "loss": 0.2925,
      "step": 1130
    },
    {
      "epoch": 0.1804939835338822,
      "grad_norm": 7.259846282256408,
      "learning_rate": 4.1634491634491637e-05,
      "loss": 0.1563,
      "step": 1140
    },
    {
      "epoch": 0.18207726409119696,
      "grad_norm": 3.0100322508747563,
      "learning_rate": 4.1554054054054055e-05,
      "loss": 0.244,
      "step": 1150
    },
    {
      "epoch": 0.18366054464851173,
      "grad_norm": 9.150778948870624,
      "learning_rate": 4.147361647361648e-05,
      "loss": 0.2009,
      "step": 1160
    },
    {
      "epoch": 0.18524382520582647,
      "grad_norm": 6.363778504109429,
      "learning_rate": 4.13931788931789e-05,
      "loss": 0.2408,
      "step": 1170
    },
    {
      "epoch": 0.18682710576314124,
      "grad_norm": 2.365927181319647,
      "learning_rate": 4.1312741312741316e-05,
      "loss": 0.2186,
      "step": 1180
    },
    {
      "epoch": 0.18841038632045598,
      "grad_norm": 3.7561710444576626,
      "learning_rate": 4.1232303732303734e-05,
      "loss": 0.1742,
      "step": 1190
    },
    {
      "epoch": 0.18999366687777075,
      "grad_norm": 4.691954060634491,
      "learning_rate": 4.115186615186615e-05,
      "loss": 0.1753,
      "step": 1200
    },
    {
      "epoch": 0.1915769474350855,
      "grad_norm": 8.570044542016596,
      "learning_rate": 4.107142857142857e-05,
      "loss": 0.1814,
      "step": 1210
    },
    {
      "epoch": 0.19316022799240026,
      "grad_norm": 1.4111714182921966,
      "learning_rate": 4.099099099099099e-05,
      "loss": 0.2043,
      "step": 1220
    },
    {
      "epoch": 0.194743508549715,
      "grad_norm": 5.538068286677259,
      "learning_rate": 4.091055341055341e-05,
      "loss": 0.1556,
      "step": 1230
    },
    {
      "epoch": 0.19632678910702978,
      "grad_norm": 7.552960897737648,
      "learning_rate": 4.083011583011583e-05,
      "loss": 0.2068,
      "step": 1240
    },
    {
      "epoch": 0.19791006966434452,
      "grad_norm": 7.321675339637284,
      "learning_rate": 4.0749678249678256e-05,
      "loss": 0.2632,
      "step": 1250
    },
    {
      "epoch": 0.1994933502216593,
      "grad_norm": 3.874266401191315,
      "learning_rate": 4.0669240669240674e-05,
      "loss": 0.1862,
      "step": 1260
    },
    {
      "epoch": 0.20107663077897403,
      "grad_norm": 10.414115980029598,
      "learning_rate": 4.058880308880309e-05,
      "loss": 0.1991,
      "step": 1270
    },
    {
      "epoch": 0.2026599113362888,
      "grad_norm": 6.381218364461556,
      "learning_rate": 4.050836550836551e-05,
      "loss": 0.1788,
      "step": 1280
    },
    {
      "epoch": 0.20424319189360354,
      "grad_norm": 2.773098433278973,
      "learning_rate": 4.042792792792793e-05,
      "loss": 0.1892,
      "step": 1290
    },
    {
      "epoch": 0.2058264724509183,
      "grad_norm": 4.215632890675528,
      "learning_rate": 4.034749034749035e-05,
      "loss": 0.2215,
      "step": 1300
    },
    {
      "epoch": 0.20740975300823306,
      "grad_norm": 3.8621220869841113,
      "learning_rate": 4.026705276705277e-05,
      "loss": 0.1757,
      "step": 1310
    },
    {
      "epoch": 0.20899303356554783,
      "grad_norm": 0.8616808041667754,
      "learning_rate": 4.018661518661519e-05,
      "loss": 0.22,
      "step": 1320
    },
    {
      "epoch": 0.21057631412286257,
      "grad_norm": 4.409266095671864,
      "learning_rate": 4.010617760617761e-05,
      "loss": 0.2288,
      "step": 1330
    },
    {
      "epoch": 0.21215959468017734,
      "grad_norm": 7.696244143715669,
      "learning_rate": 4.0025740025740025e-05,
      "loss": 0.1905,
      "step": 1340
    },
    {
      "epoch": 0.21374287523749208,
      "grad_norm": 4.725293605502532,
      "learning_rate": 3.994530244530244e-05,
      "loss": 0.1782,
      "step": 1350
    },
    {
      "epoch": 0.21532615579480685,
      "grad_norm": 8.152894012933862,
      "learning_rate": 3.986486486486487e-05,
      "loss": 0.174,
      "step": 1360
    },
    {
      "epoch": 0.2169094363521216,
      "grad_norm": 6.104721130950202,
      "learning_rate": 3.9784427284427286e-05,
      "loss": 0.1618,
      "step": 1370
    },
    {
      "epoch": 0.21849271690943636,
      "grad_norm": 4.980782006079953,
      "learning_rate": 3.970398970398971e-05,
      "loss": 0.1668,
      "step": 1380
    },
    {
      "epoch": 0.2200759974667511,
      "grad_norm": 0.9099917283573027,
      "learning_rate": 3.962355212355213e-05,
      "loss": 0.1514,
      "step": 1390
    },
    {
      "epoch": 0.22165927802406588,
      "grad_norm": 6.357555382142708,
      "learning_rate": 3.954311454311455e-05,
      "loss": 0.2241,
      "step": 1400
    },
    {
      "epoch": 0.22324255858138062,
      "grad_norm": 5.949548322699852,
      "learning_rate": 3.9462676962676965e-05,
      "loss": 0.1371,
      "step": 1410
    },
    {
      "epoch": 0.2248258391386954,
      "grad_norm": 7.752347529098142,
      "learning_rate": 3.938223938223938e-05,
      "loss": 0.1437,
      "step": 1420
    },
    {
      "epoch": 0.22640911969601013,
      "grad_norm": 9.89122087030594,
      "learning_rate": 3.93018018018018e-05,
      "loss": 0.1491,
      "step": 1430
    },
    {
      "epoch": 0.2279924002533249,
      "grad_norm": 10.898366095196192,
      "learning_rate": 3.922136422136422e-05,
      "loss": 0.2222,
      "step": 1440
    },
    {
      "epoch": 0.22957568081063964,
      "grad_norm": 11.362832069370679,
      "learning_rate": 3.9140926640926644e-05,
      "loss": 0.2079,
      "step": 1450
    },
    {
      "epoch": 0.2311589613679544,
      "grad_norm": 2.1706280318968623,
      "learning_rate": 3.906048906048906e-05,
      "loss": 0.2157,
      "step": 1460
    },
    {
      "epoch": 0.23274224192526916,
      "grad_norm": 0.27059155761909065,
      "learning_rate": 3.898005148005148e-05,
      "loss": 0.1606,
      "step": 1470
    },
    {
      "epoch": 0.23432552248258393,
      "grad_norm": 3.0743133646693486,
      "learning_rate": 3.8899613899613905e-05,
      "loss": 0.1413,
      "step": 1480
    },
    {
      "epoch": 0.23590880303989867,
      "grad_norm": 2.8091335069782777,
      "learning_rate": 3.881917631917632e-05,
      "loss": 0.1291,
      "step": 1490
    },
    {
      "epoch": 0.23749208359721344,
      "grad_norm": 11.958095499436054,
      "learning_rate": 3.873873873873874e-05,
      "loss": 0.1628,
      "step": 1500
    },
    {
      "epoch": 0.23749208359721344,
      "eval_loss": 0.25035035610198975,
      "eval_runtime": 303.8622,
      "eval_samples_per_second": 9.824,
      "eval_steps_per_second": 1.639,
      "step": 1500
    },
    {
      "epoch": 0.23907536415452818,
      "grad_norm": 9.030967839991078,
      "learning_rate": 3.865830115830116e-05,
      "loss": 0.2532,
      "step": 1510
    },
    {
      "epoch": 0.24065864471184295,
      "grad_norm": 14.196778074282548,
      "learning_rate": 3.8577863577863584e-05,
      "loss": 0.1746,
      "step": 1520
    },
    {
      "epoch": 0.2422419252691577,
      "grad_norm": 1.6069430151320974,
      "learning_rate": 3.8497425997426e-05,
      "loss": 0.1238,
      "step": 1530
    },
    {
      "epoch": 0.24382520582647246,
      "grad_norm": 8.289043631428807,
      "learning_rate": 3.841698841698842e-05,
      "loss": 0.2283,
      "step": 1540
    },
    {
      "epoch": 0.2454084863837872,
      "grad_norm": 0.21411396403413732,
      "learning_rate": 3.833655083655084e-05,
      "loss": 0.2084,
      "step": 1550
    },
    {
      "epoch": 0.24699176694110198,
      "grad_norm": 4.163900805227171,
      "learning_rate": 3.8256113256113256e-05,
      "loss": 0.1496,
      "step": 1560
    },
    {
      "epoch": 0.24857504749841672,
      "grad_norm": 7.946888335078396,
      "learning_rate": 3.8175675675675674e-05,
      "loss": 0.1649,
      "step": 1570
    },
    {
      "epoch": 0.25015832805573146,
      "grad_norm": 11.708923614573376,
      "learning_rate": 3.809523809523809e-05,
      "loss": 0.2122,
      "step": 1580
    },
    {
      "epoch": 0.25174160861304623,
      "grad_norm": 7.625153586920141,
      "learning_rate": 3.801480051480052e-05,
      "loss": 0.1774,
      "step": 1590
    },
    {
      "epoch": 0.253324889170361,
      "grad_norm": 11.89324962307105,
      "learning_rate": 3.7934362934362935e-05,
      "loss": 0.2361,
      "step": 1600
    },
    {
      "epoch": 0.25490816972767577,
      "grad_norm": 6.899496651686329,
      "learning_rate": 3.785392535392536e-05,
      "loss": 0.2088,
      "step": 1610
    },
    {
      "epoch": 0.2564914502849905,
      "grad_norm": 8.814236517183968,
      "learning_rate": 3.777348777348778e-05,
      "loss": 0.1489,
      "step": 1620
    },
    {
      "epoch": 0.25807473084230526,
      "grad_norm": 1.337565317074228,
      "learning_rate": 3.7693050193050196e-05,
      "loss": 0.1514,
      "step": 1630
    },
    {
      "epoch": 0.25965801139962,
      "grad_norm": 17.69429236159882,
      "learning_rate": 3.7612612612612614e-05,
      "loss": 0.2443,
      "step": 1640
    },
    {
      "epoch": 0.2612412919569348,
      "grad_norm": 6.430657463099309,
      "learning_rate": 3.753217503217503e-05,
      "loss": 0.1197,
      "step": 1650
    },
    {
      "epoch": 0.2628245725142495,
      "grad_norm": 4.613632666812275,
      "learning_rate": 3.745173745173745e-05,
      "loss": 0.1606,
      "step": 1660
    },
    {
      "epoch": 0.2644078530715643,
      "grad_norm": 4.631981812186103,
      "learning_rate": 3.7371299871299875e-05,
      "loss": 0.3267,
      "step": 1670
    },
    {
      "epoch": 0.26599113362887905,
      "grad_norm": 2.4431891927144087,
      "learning_rate": 3.729086229086229e-05,
      "loss": 0.2243,
      "step": 1680
    },
    {
      "epoch": 0.2675744141861938,
      "grad_norm": 2.3840834933131805,
      "learning_rate": 3.721042471042471e-05,
      "loss": 0.1773,
      "step": 1690
    },
    {
      "epoch": 0.26915769474350854,
      "grad_norm": 5.82968650537716,
      "learning_rate": 3.712998712998713e-05,
      "loss": 0.2044,
      "step": 1700
    },
    {
      "epoch": 0.2707409753008233,
      "grad_norm": 2.4929962281016107,
      "learning_rate": 3.704954954954955e-05,
      "loss": 0.1361,
      "step": 1710
    },
    {
      "epoch": 0.2723242558581381,
      "grad_norm": 13.95553120437517,
      "learning_rate": 3.696911196911197e-05,
      "loss": 0.1935,
      "step": 1720
    },
    {
      "epoch": 0.27390753641545285,
      "grad_norm": 5.190705377644245,
      "learning_rate": 3.688867438867439e-05,
      "loss": 0.2383,
      "step": 1730
    },
    {
      "epoch": 0.27549081697276756,
      "grad_norm": 8.665581806459022,
      "learning_rate": 3.6808236808236815e-05,
      "loss": 0.183,
      "step": 1740
    },
    {
      "epoch": 0.27707409753008233,
      "grad_norm": 0.9806665167885136,
      "learning_rate": 3.672779922779923e-05,
      "loss": 0.1951,
      "step": 1750
    },
    {
      "epoch": 0.2786573780873971,
      "grad_norm": 1.4197329640818153,
      "learning_rate": 3.664736164736165e-05,
      "loss": 0.1625,
      "step": 1760
    },
    {
      "epoch": 0.2802406586447118,
      "grad_norm": 6.600480680590145,
      "learning_rate": 3.656692406692407e-05,
      "loss": 0.177,
      "step": 1770
    },
    {
      "epoch": 0.2818239392020266,
      "grad_norm": 6.091672885681123,
      "learning_rate": 3.648648648648649e-05,
      "loss": 0.2248,
      "step": 1780
    },
    {
      "epoch": 0.28340721975934136,
      "grad_norm": 6.060840497540015,
      "learning_rate": 3.6406048906048905e-05,
      "loss": 0.1957,
      "step": 1790
    },
    {
      "epoch": 0.2849905003166561,
      "grad_norm": 7.544467075908852,
      "learning_rate": 3.6325611325611323e-05,
      "loss": 0.2087,
      "step": 1800
    },
    {
      "epoch": 0.28657378087397084,
      "grad_norm": 6.512829663504956,
      "learning_rate": 3.624517374517375e-05,
      "loss": 0.1235,
      "step": 1810
    },
    {
      "epoch": 0.2881570614312856,
      "grad_norm": 7.658804331157637,
      "learning_rate": 3.6164736164736166e-05,
      "loss": 0.1736,
      "step": 1820
    },
    {
      "epoch": 0.2897403419886004,
      "grad_norm": 10.233974303343931,
      "learning_rate": 3.6084298584298584e-05,
      "loss": 0.2092,
      "step": 1830
    },
    {
      "epoch": 0.29132362254591515,
      "grad_norm": 10.054448098961327,
      "learning_rate": 3.6003861003861e-05,
      "loss": 0.2382,
      "step": 1840
    },
    {
      "epoch": 0.29290690310322987,
      "grad_norm": 3.8818547316762015,
      "learning_rate": 3.592342342342343e-05,
      "loss": 0.1991,
      "step": 1850
    },
    {
      "epoch": 0.29449018366054464,
      "grad_norm": 5.2587385566574225,
      "learning_rate": 3.5842985842985845e-05,
      "loss": 0.1918,
      "step": 1860
    },
    {
      "epoch": 0.2960734642178594,
      "grad_norm": 3.575312412723086,
      "learning_rate": 3.5762548262548263e-05,
      "loss": 0.1579,
      "step": 1870
    },
    {
      "epoch": 0.2976567447751742,
      "grad_norm": 2.659001798700167,
      "learning_rate": 3.568211068211069e-05,
      "loss": 0.2422,
      "step": 1880
    },
    {
      "epoch": 0.2992400253324889,
      "grad_norm": 5.496251649628583,
      "learning_rate": 3.5601673101673106e-05,
      "loss": 0.2085,
      "step": 1890
    },
    {
      "epoch": 0.30082330588980366,
      "grad_norm": 1.980950471878005,
      "learning_rate": 3.5521235521235524e-05,
      "loss": 0.1977,
      "step": 1900
    },
    {
      "epoch": 0.30240658644711843,
      "grad_norm": 6.756621892047079,
      "learning_rate": 3.544079794079794e-05,
      "loss": 0.1744,
      "step": 1910
    },
    {
      "epoch": 0.3039898670044332,
      "grad_norm": 11.428712898468707,
      "learning_rate": 3.536036036036036e-05,
      "loss": 0.2254,
      "step": 1920
    },
    {
      "epoch": 0.3055731475617479,
      "grad_norm": 1.8634093938304332,
      "learning_rate": 3.527992277992278e-05,
      "loss": 0.2453,
      "step": 1930
    },
    {
      "epoch": 0.3071564281190627,
      "grad_norm": 1.3761509499866096,
      "learning_rate": 3.51994851994852e-05,
      "loss": 0.0908,
      "step": 1940
    },
    {
      "epoch": 0.30873970867637746,
      "grad_norm": 3.5945129911427016,
      "learning_rate": 3.511904761904762e-05,
      "loss": 0.2076,
      "step": 1950
    },
    {
      "epoch": 0.3103229892336922,
      "grad_norm": 10.112217121859523,
      "learning_rate": 3.503861003861004e-05,
      "loss": 0.1864,
      "step": 1960
    },
    {
      "epoch": 0.31190626979100694,
      "grad_norm": 9.3565492264902,
      "learning_rate": 3.4958172458172464e-05,
      "loss": 0.2463,
      "step": 1970
    },
    {
      "epoch": 0.3134895503483217,
      "grad_norm": 2.0141296754322418,
      "learning_rate": 3.487773487773488e-05,
      "loss": 0.0955,
      "step": 1980
    },
    {
      "epoch": 0.3150728309056365,
      "grad_norm": 2.265680351896581,
      "learning_rate": 3.47972972972973e-05,
      "loss": 0.2234,
      "step": 1990
    },
    {
      "epoch": 0.31665611146295125,
      "grad_norm": 3.02295280731141,
      "learning_rate": 3.471685971685972e-05,
      "loss": 0.1888,
      "step": 2000
    },
    {
      "epoch": 0.31665611146295125,
      "eval_loss": 0.2373693585395813,
      "eval_runtime": 303.5296,
      "eval_samples_per_second": 9.834,
      "eval_steps_per_second": 1.641,
      "step": 2000
    },
    {
      "epoch": 0.31823939202026597,
      "grad_norm": 15.896466977083795,
      "learning_rate": 3.4636422136422137e-05,
      "loss": 0.1794,
      "step": 2010
    },
    {
      "epoch": 0.31982267257758074,
      "grad_norm": 14.011110529209265,
      "learning_rate": 3.4555984555984555e-05,
      "loss": 0.1362,
      "step": 2020
    },
    {
      "epoch": 0.3214059531348955,
      "grad_norm": 13.632888050471173,
      "learning_rate": 3.447554697554698e-05,
      "loss": 0.2444,
      "step": 2030
    },
    {
      "epoch": 0.3229892336922103,
      "grad_norm": 3.5096111486507855,
      "learning_rate": 3.43951093951094e-05,
      "loss": 0.1608,
      "step": 2040
    },
    {
      "epoch": 0.324572514249525,
      "grad_norm": 4.369999889312673,
      "learning_rate": 3.4314671814671816e-05,
      "loss": 0.215,
      "step": 2050
    },
    {
      "epoch": 0.32615579480683976,
      "grad_norm": 15.806073356658025,
      "learning_rate": 3.4234234234234234e-05,
      "loss": 0.1485,
      "step": 2060
    },
    {
      "epoch": 0.32773907536415453,
      "grad_norm": 1.501061937811645,
      "learning_rate": 3.415379665379665e-05,
      "loss": 0.2054,
      "step": 2070
    },
    {
      "epoch": 0.3293223559214693,
      "grad_norm": 3.7351328826920183,
      "learning_rate": 3.4073359073359077e-05,
      "loss": 0.2351,
      "step": 2080
    },
    {
      "epoch": 0.330905636478784,
      "grad_norm": 4.339292146116196,
      "learning_rate": 3.3992921492921495e-05,
      "loss": 0.1718,
      "step": 2090
    },
    {
      "epoch": 0.3324889170360988,
      "grad_norm": 8.294146705229604,
      "learning_rate": 3.391248391248392e-05,
      "loss": 0.1999,
      "step": 2100
    },
    {
      "epoch": 0.33407219759341356,
      "grad_norm": 10.50570959440776,
      "learning_rate": 3.383204633204634e-05,
      "loss": 0.1968,
      "step": 2110
    },
    {
      "epoch": 0.3356554781507283,
      "grad_norm": 3.069649738870568,
      "learning_rate": 3.3751608751608756e-05,
      "loss": 0.1249,
      "step": 2120
    },
    {
      "epoch": 0.33723875870804304,
      "grad_norm": 4.823217966158306,
      "learning_rate": 3.3671171171171174e-05,
      "loss": 0.1206,
      "step": 2130
    },
    {
      "epoch": 0.3388220392653578,
      "grad_norm": 6.2827805509516255,
      "learning_rate": 3.359073359073359e-05,
      "loss": 0.1616,
      "step": 2140
    },
    {
      "epoch": 0.3404053198226726,
      "grad_norm": 7.685746652025494,
      "learning_rate": 3.351029601029601e-05,
      "loss": 0.2188,
      "step": 2150
    },
    {
      "epoch": 0.34198860037998735,
      "grad_norm": 3.162593547658768,
      "learning_rate": 3.342985842985843e-05,
      "loss": 0.2097,
      "step": 2160
    },
    {
      "epoch": 0.34357188093730207,
      "grad_norm": 1.829006406444344,
      "learning_rate": 3.334942084942085e-05,
      "loss": 0.162,
      "step": 2170
    },
    {
      "epoch": 0.34515516149461684,
      "grad_norm": 4.979735316707394,
      "learning_rate": 3.326898326898327e-05,
      "loss": 0.1323,
      "step": 2180
    },
    {
      "epoch": 0.3467384420519316,
      "grad_norm": 6.469076692007161,
      "learning_rate": 3.318854568854569e-05,
      "loss": 0.1842,
      "step": 2190
    },
    {
      "epoch": 0.3483217226092464,
      "grad_norm": 6.935756704883465,
      "learning_rate": 3.310810810810811e-05,
      "loss": 0.2133,
      "step": 2200
    },
    {
      "epoch": 0.3499050031665611,
      "grad_norm": 7.8496028143633945,
      "learning_rate": 3.302767052767053e-05,
      "loss": 0.2028,
      "step": 2210
    },
    {
      "epoch": 0.35148828372387586,
      "grad_norm": 0.9937235738731419,
      "learning_rate": 3.294723294723295e-05,
      "loss": 0.1554,
      "step": 2220
    },
    {
      "epoch": 0.35307156428119063,
      "grad_norm": 12.678870963965933,
      "learning_rate": 3.286679536679537e-05,
      "loss": 0.1583,
      "step": 2230
    },
    {
      "epoch": 0.3546548448385054,
      "grad_norm": 3.947212955023416,
      "learning_rate": 3.2786357786357786e-05,
      "loss": 0.133,
      "step": 2240
    },
    {
      "epoch": 0.3562381253958201,
      "grad_norm": 7.911179042672138,
      "learning_rate": 3.270592020592021e-05,
      "loss": 0.2303,
      "step": 2250
    },
    {
      "epoch": 0.3578214059531349,
      "grad_norm": 20.21515285089767,
      "learning_rate": 3.262548262548263e-05,
      "loss": 0.2,
      "step": 2260
    },
    {
      "epoch": 0.35940468651044966,
      "grad_norm": 4.507443946832605,
      "learning_rate": 3.254504504504505e-05,
      "loss": 0.1878,
      "step": 2270
    },
    {
      "epoch": 0.3609879670677644,
      "grad_norm": 5.324464855257573,
      "learning_rate": 3.2464607464607465e-05,
      "loss": 0.1777,
      "step": 2280
    },
    {
      "epoch": 0.36257124762507914,
      "grad_norm": 1.398960931945493,
      "learning_rate": 3.238416988416988e-05,
      "loss": 0.1658,
      "step": 2290
    },
    {
      "epoch": 0.3641545281823939,
      "grad_norm": 12.541097600621738,
      "learning_rate": 3.23037323037323e-05,
      "loss": 0.257,
      "step": 2300
    },
    {
      "epoch": 0.3657378087397087,
      "grad_norm": 4.971374010779486,
      "learning_rate": 3.222329472329472e-05,
      "loss": 0.1043,
      "step": 2310
    },
    {
      "epoch": 0.36732108929702345,
      "grad_norm": 15.241552295676314,
      "learning_rate": 3.2142857142857144e-05,
      "loss": 0.1943,
      "step": 2320
    },
    {
      "epoch": 0.36890436985433817,
      "grad_norm": 8.254160901035052,
      "learning_rate": 3.206241956241957e-05,
      "loss": 0.184,
      "step": 2330
    },
    {
      "epoch": 0.37048765041165294,
      "grad_norm": 3.363385454750038,
      "learning_rate": 3.198198198198199e-05,
      "loss": 0.1733,
      "step": 2340
    },
    {
      "epoch": 0.3720709309689677,
      "grad_norm": 9.19008179803585,
      "learning_rate": 3.1901544401544405e-05,
      "loss": 0.1481,
      "step": 2350
    },
    {
      "epoch": 0.3736542115262825,
      "grad_norm": 6.09940580381958,
      "learning_rate": 3.182110682110682e-05,
      "loss": 0.2033,
      "step": 2360
    },
    {
      "epoch": 0.3752374920835972,
      "grad_norm": 3.150419534265607,
      "learning_rate": 3.174066924066924e-05,
      "loss": 0.1146,
      "step": 2370
    },
    {
      "epoch": 0.37682077264091196,
      "grad_norm": 10.855592796273084,
      "learning_rate": 3.166023166023166e-05,
      "loss": 0.1476,
      "step": 2380
    },
    {
      "epoch": 0.37840405319822673,
      "grad_norm": 2.5683911223679496,
      "learning_rate": 3.1579794079794084e-05,
      "loss": 0.1996,
      "step": 2390
    },
    {
      "epoch": 0.3799873337555415,
      "grad_norm": 6.156748795029537,
      "learning_rate": 3.14993564993565e-05,
      "loss": 0.2168,
      "step": 2400
    },
    {
      "epoch": 0.3815706143128562,
      "grad_norm": 2.2300129172459933,
      "learning_rate": 3.141891891891892e-05,
      "loss": 0.1663,
      "step": 2410
    },
    {
      "epoch": 0.383153894870171,
      "grad_norm": 20.76421558657541,
      "learning_rate": 3.133848133848134e-05,
      "loss": 0.2915,
      "step": 2420
    },
    {
      "epoch": 0.38473717542748576,
      "grad_norm": 7.379561484523143,
      "learning_rate": 3.1258043758043756e-05,
      "loss": 0.0943,
      "step": 2430
    },
    {
      "epoch": 0.3863204559848005,
      "grad_norm": 7.416939662523859,
      "learning_rate": 3.117760617760618e-05,
      "loss": 0.2621,
      "step": 2440
    },
    {
      "epoch": 0.38790373654211524,
      "grad_norm": 3.823817979271324,
      "learning_rate": 3.10971685971686e-05,
      "loss": 0.1062,
      "step": 2450
    },
    {
      "epoch": 0.38948701709943,
      "grad_norm": 9.202502399621478,
      "learning_rate": 3.101673101673102e-05,
      "loss": 0.1835,
      "step": 2460
    },
    {
      "epoch": 0.3910702976567448,
      "grad_norm": 7.9742116125849805,
      "learning_rate": 3.093629343629344e-05,
      "loss": 0.2161,
      "step": 2470
    },
    {
      "epoch": 0.39265357821405955,
      "grad_norm": 12.873070433381947,
      "learning_rate": 3.085585585585586e-05,
      "loss": 0.1747,
      "step": 2480
    },
    {
      "epoch": 0.39423685877137427,
      "grad_norm": 5.1251516552328225,
      "learning_rate": 3.077541827541828e-05,
      "loss": 0.195,
      "step": 2490
    },
    {
      "epoch": 0.39582013932868904,
      "grad_norm": 0.8492450853912478,
      "learning_rate": 3.0694980694980696e-05,
      "loss": 0.1481,
      "step": 2500
    },
    {
      "epoch": 0.39582013932868904,
      "eval_loss": 0.22845105826854706,
      "eval_runtime": 303.7182,
      "eval_samples_per_second": 9.828,
      "eval_steps_per_second": 1.64,
      "step": 2500
    },
    {
      "epoch": 0.3974034198860038,
      "grad_norm": 0.7171139548496545,
      "learning_rate": 3.0614543114543114e-05,
      "loss": 0.1994,
      "step": 2510
    },
    {
      "epoch": 0.3989867004433186,
      "grad_norm": 9.220457171113368,
      "learning_rate": 3.053410553410553e-05,
      "loss": 0.1492,
      "step": 2520
    },
    {
      "epoch": 0.4005699810006333,
      "grad_norm": 3.2968602473936817,
      "learning_rate": 3.0453667953667954e-05,
      "loss": 0.1729,
      "step": 2530
    },
    {
      "epoch": 0.40215326155794806,
      "grad_norm": 2.3539002416858787,
      "learning_rate": 3.037323037323038e-05,
      "loss": 0.1533,
      "step": 2540
    },
    {
      "epoch": 0.40373654211526283,
      "grad_norm": 0.2028468226263407,
      "learning_rate": 3.0292792792792797e-05,
      "loss": 0.2177,
      "step": 2550
    },
    {
      "epoch": 0.4053198226725776,
      "grad_norm": 5.507545497185153,
      "learning_rate": 3.0212355212355215e-05,
      "loss": 0.1553,
      "step": 2560
    },
    {
      "epoch": 0.4069031032298923,
      "grad_norm": 16.54039190010274,
      "learning_rate": 3.0131917631917633e-05,
      "loss": 0.1896,
      "step": 2570
    },
    {
      "epoch": 0.4084863837872071,
      "grad_norm": 4.995636943725068,
      "learning_rate": 3.005148005148005e-05,
      "loss": 0.1932,
      "step": 2580
    },
    {
      "epoch": 0.41006966434452186,
      "grad_norm": 9.78522018442187,
      "learning_rate": 2.9971042471042472e-05,
      "loss": 0.1773,
      "step": 2590
    },
    {
      "epoch": 0.4116529449018366,
      "grad_norm": 29.856534606203148,
      "learning_rate": 2.989060489060489e-05,
      "loss": 0.2048,
      "step": 2600
    },
    {
      "epoch": 0.41323622545915134,
      "grad_norm": 6.966805088304662,
      "learning_rate": 2.9810167310167315e-05,
      "loss": 0.1157,
      "step": 2610
    },
    {
      "epoch": 0.4148195060164661,
      "grad_norm": 12.469565611051586,
      "learning_rate": 2.9729729729729733e-05,
      "loss": 0.1992,
      "step": 2620
    },
    {
      "epoch": 0.4164027865737809,
      "grad_norm": 5.300906647201838,
      "learning_rate": 2.964929214929215e-05,
      "loss": 0.1591,
      "step": 2630
    },
    {
      "epoch": 0.41798606713109565,
      "grad_norm": 11.514164038728222,
      "learning_rate": 2.956885456885457e-05,
      "loss": 0.1964,
      "step": 2640
    },
    {
      "epoch": 0.41956934768841037,
      "grad_norm": 0.6456997999969925,
      "learning_rate": 2.948841698841699e-05,
      "loss": 0.1739,
      "step": 2650
    },
    {
      "epoch": 0.42115262824572514,
      "grad_norm": 6.701774692355721,
      "learning_rate": 2.940797940797941e-05,
      "loss": 0.1993,
      "step": 2660
    },
    {
      "epoch": 0.4227359088030399,
      "grad_norm": 4.517443228165922,
      "learning_rate": 2.9327541827541827e-05,
      "loss": 0.1161,
      "step": 2670
    },
    {
      "epoch": 0.4243191893603547,
      "grad_norm": 9.210344420049529,
      "learning_rate": 2.9247104247104252e-05,
      "loss": 0.3361,
      "step": 2680
    },
    {
      "epoch": 0.4259024699176694,
      "grad_norm": 9.965729545841558,
      "learning_rate": 2.916666666666667e-05,
      "loss": 0.322,
      "step": 2690
    },
    {
      "epoch": 0.42748575047498416,
      "grad_norm": 4.769575638997986,
      "learning_rate": 2.9086229086229088e-05,
      "loss": 0.1566,
      "step": 2700
    },
    {
      "epoch": 0.42906903103229893,
      "grad_norm": 2.2576331889086014,
      "learning_rate": 2.9005791505791506e-05,
      "loss": 0.1479,
      "step": 2710
    },
    {
      "epoch": 0.4306523115896137,
      "grad_norm": 9.766825707435045,
      "learning_rate": 2.8925353925353927e-05,
      "loss": 0.1786,
      "step": 2720
    },
    {
      "epoch": 0.4322355921469284,
      "grad_norm": 3.3871972825040806,
      "learning_rate": 2.8844916344916345e-05,
      "loss": 0.1657,
      "step": 2730
    },
    {
      "epoch": 0.4338188727042432,
      "grad_norm": 6.851521577788995,
      "learning_rate": 2.8764478764478763e-05,
      "loss": 0.1163,
      "step": 2740
    },
    {
      "epoch": 0.43540215326155796,
      "grad_norm": 5.786150530695446,
      "learning_rate": 2.868404118404118e-05,
      "loss": 0.1808,
      "step": 2750
    },
    {
      "epoch": 0.4369854338188727,
      "grad_norm": 4.704397644012798,
      "learning_rate": 2.8603603603603606e-05,
      "loss": 0.2055,
      "step": 2760
    },
    {
      "epoch": 0.43856871437618744,
      "grad_norm": 7.919270405157283,
      "learning_rate": 2.8523166023166024e-05,
      "loss": 0.2359,
      "step": 2770
    },
    {
      "epoch": 0.4401519949335022,
      "grad_norm": 1.7253251971672543,
      "learning_rate": 2.8442728442728446e-05,
      "loss": 0.153,
      "step": 2780
    },
    {
      "epoch": 0.441735275490817,
      "grad_norm": 6.347627704262737,
      "learning_rate": 2.8362290862290864e-05,
      "loss": 0.0896,
      "step": 2790
    },
    {
      "epoch": 0.44331855604813175,
      "grad_norm": 3.537168690833406,
      "learning_rate": 2.8281853281853282e-05,
      "loss": 0.1857,
      "step": 2800
    },
    {
      "epoch": 0.44490183660544647,
      "grad_norm": 7.888442902950206,
      "learning_rate": 2.82014157014157e-05,
      "loss": 0.1676,
      "step": 2810
    },
    {
      "epoch": 0.44648511716276124,
      "grad_norm": 6.694462369452503,
      "learning_rate": 2.8120978120978118e-05,
      "loss": 0.2026,
      "step": 2820
    },
    {
      "epoch": 0.448068397720076,
      "grad_norm": 0.33630203828205296,
      "learning_rate": 2.8040540540540543e-05,
      "loss": 0.2415,
      "step": 2830
    },
    {
      "epoch": 0.4496516782773908,
      "grad_norm": 6.120327471280674,
      "learning_rate": 2.7960102960102964e-05,
      "loss": 0.1547,
      "step": 2840
    },
    {
      "epoch": 0.4512349588347055,
      "grad_norm": 5.192811016673225,
      "learning_rate": 2.7879665379665382e-05,
      "loss": 0.0861,
      "step": 2850
    },
    {
      "epoch": 0.45281823939202026,
      "grad_norm": 12.968830007283328,
      "learning_rate": 2.77992277992278e-05,
      "loss": 0.217,
      "step": 2860
    },
    {
      "epoch": 0.45440151994933503,
      "grad_norm": 3.785864166418582,
      "learning_rate": 2.771879021879022e-05,
      "loss": 0.1188,
      "step": 2870
    },
    {
      "epoch": 0.4559848005066498,
      "grad_norm": 3.2693539005066143,
      "learning_rate": 2.7638352638352637e-05,
      "loss": 0.1332,
      "step": 2880
    },
    {
      "epoch": 0.4575680810639645,
      "grad_norm": 5.063531464414266,
      "learning_rate": 2.7557915057915058e-05,
      "loss": 0.1979,
      "step": 2890
    },
    {
      "epoch": 0.4591513616212793,
      "grad_norm": 1.6468863760104677,
      "learning_rate": 2.7477477477477483e-05,
      "loss": 0.169,
      "step": 2900
    },
    {
      "epoch": 0.46073464217859406,
      "grad_norm": 4.897493359657136,
      "learning_rate": 2.73970398970399e-05,
      "loss": 0.1594,
      "step": 2910
    },
    {
      "epoch": 0.4623179227359088,
      "grad_norm": 14.215918760017104,
      "learning_rate": 2.731660231660232e-05,
      "loss": 0.1715,
      "step": 2920
    },
    {
      "epoch": 0.46390120329322354,
      "grad_norm": 5.600503946517318,
      "learning_rate": 2.7236164736164737e-05,
      "loss": 0.1575,
      "step": 2930
    },
    {
      "epoch": 0.4654844838505383,
      "grad_norm": 0.21753994009094715,
      "learning_rate": 2.7155727155727155e-05,
      "loss": 0.1599,
      "step": 2940
    },
    {
      "epoch": 0.4670677644078531,
      "grad_norm": 0.16349422719443873,
      "learning_rate": 2.7075289575289577e-05,
      "loss": 0.1656,
      "step": 2950
    },
    {
      "epoch": 0.46865104496516785,
      "grad_norm": 6.576025403495783,
      "learning_rate": 2.6994851994851995e-05,
      "loss": 0.1079,
      "step": 2960
    },
    {
      "epoch": 0.47023432552248257,
      "grad_norm": 5.492820735798695,
      "learning_rate": 2.691441441441442e-05,
      "loss": 0.2653,
      "step": 2970
    },
    {
      "epoch": 0.47181760607979734,
      "grad_norm": 4.09489343413702,
      "learning_rate": 2.6833976833976838e-05,
      "loss": 0.2407,
      "step": 2980
    },
    {
      "epoch": 0.4734008866371121,
      "grad_norm": 2.57802059077762,
      "learning_rate": 2.6753539253539256e-05,
      "loss": 0.163,
      "step": 2990
    },
    {
      "epoch": 0.4749841671944269,
      "grad_norm": 13.30880815060644,
      "learning_rate": 2.6673101673101674e-05,
      "loss": 0.1909,
      "step": 3000
    },
    {
      "epoch": 0.4749841671944269,
      "eval_loss": 0.20150120556354523,
      "eval_runtime": 303.6741,
      "eval_samples_per_second": 9.83,
      "eval_steps_per_second": 1.64,
      "step": 3000
    },
    {
      "epoch": 0.4765674477517416,
      "grad_norm": 2.4413356435102656,
      "learning_rate": 2.6592664092664095e-05,
      "loss": 0.149,
      "step": 3010
    },
    {
      "epoch": 0.47815072830905636,
      "grad_norm": 3.381430680670706,
      "learning_rate": 2.6512226512226513e-05,
      "loss": 0.1903,
      "step": 3020
    },
    {
      "epoch": 0.47973400886637113,
      "grad_norm": 4.918024985406243,
      "learning_rate": 2.643178893178893e-05,
      "loss": 0.1695,
      "step": 3030
    },
    {
      "epoch": 0.4813172894236859,
      "grad_norm": 4.246030412217347,
      "learning_rate": 2.635135135135135e-05,
      "loss": 0.211,
      "step": 3040
    },
    {
      "epoch": 0.4829005699810006,
      "grad_norm": 9.361725628231222,
      "learning_rate": 2.6270913770913774e-05,
      "loss": 0.2014,
      "step": 3050
    },
    {
      "epoch": 0.4844838505383154,
      "grad_norm": 6.745408934009244,
      "learning_rate": 2.6190476190476192e-05,
      "loss": 0.1725,
      "step": 3060
    },
    {
      "epoch": 0.48606713109563016,
      "grad_norm": 5.974470183692448,
      "learning_rate": 2.611003861003861e-05,
      "loss": 0.1225,
      "step": 3070
    },
    {
      "epoch": 0.4876504116529449,
      "grad_norm": 4.880828893962446,
      "learning_rate": 2.6029601029601032e-05,
      "loss": 0.1951,
      "step": 3080
    },
    {
      "epoch": 0.48923369221025964,
      "grad_norm": 8.145549902574535,
      "learning_rate": 2.594916344916345e-05,
      "loss": 0.2195,
      "step": 3090
    },
    {
      "epoch": 0.4908169727675744,
      "grad_norm": 12.869052142708794,
      "learning_rate": 2.5868725868725868e-05,
      "loss": 0.1545,
      "step": 3100
    },
    {
      "epoch": 0.4924002533248892,
      "grad_norm": 13.100992389392266,
      "learning_rate": 2.5788288288288286e-05,
      "loss": 0.2053,
      "step": 3110
    },
    {
      "epoch": 0.49398353388220395,
      "grad_norm": 2.5835886080552,
      "learning_rate": 2.570785070785071e-05,
      "loss": 0.1668,
      "step": 3120
    },
    {
      "epoch": 0.49556681443951867,
      "grad_norm": 5.370327004931132,
      "learning_rate": 2.562741312741313e-05,
      "loss": 0.1864,
      "step": 3130
    },
    {
      "epoch": 0.49715009499683344,
      "grad_norm": 1.7209982992293507,
      "learning_rate": 2.554697554697555e-05,
      "loss": 0.2488,
      "step": 3140
    },
    {
      "epoch": 0.4987333755541482,
      "grad_norm": 10.290997646893103,
      "learning_rate": 2.546653796653797e-05,
      "loss": 0.1807,
      "step": 3150
    },
    {
      "epoch": 0.5003166561114629,
      "grad_norm": 8.388381061242585,
      "learning_rate": 2.5386100386100386e-05,
      "loss": 0.1637,
      "step": 3160
    },
    {
      "epoch": 0.5018999366687777,
      "grad_norm": 9.954272433123958,
      "learning_rate": 2.5305662805662804e-05,
      "loss": 0.2509,
      "step": 3170
    },
    {
      "epoch": 0.5034832172260925,
      "grad_norm": 2.7180325668663166,
      "learning_rate": 2.5225225225225222e-05,
      "loss": 0.2427,
      "step": 3180
    },
    {
      "epoch": 0.5050664977834072,
      "grad_norm": 3.157759352760094,
      "learning_rate": 2.5144787644787647e-05,
      "loss": 0.1247,
      "step": 3190
    },
    {
      "epoch": 0.506649778340722,
      "grad_norm": 13.100919012782736,
      "learning_rate": 2.506435006435007e-05,
      "loss": 0.1715,
      "step": 3200
    },
    {
      "epoch": 0.5082330588980367,
      "grad_norm": 9.349831531659282,
      "learning_rate": 2.4983912483912487e-05,
      "loss": 0.1756,
      "step": 3210
    },
    {
      "epoch": 0.5098163394553515,
      "grad_norm": 3.658360190209684,
      "learning_rate": 2.4903474903474905e-05,
      "loss": 0.1784,
      "step": 3220
    },
    {
      "epoch": 0.5113996200126663,
      "grad_norm": 0.4937356940744124,
      "learning_rate": 2.4823037323037323e-05,
      "loss": 0.155,
      "step": 3230
    },
    {
      "epoch": 0.512982900569981,
      "grad_norm": 9.647514268202757,
      "learning_rate": 2.474259974259974e-05,
      "loss": 0.1666,
      "step": 3240
    },
    {
      "epoch": 0.5145661811272958,
      "grad_norm": 2.2686176398053477,
      "learning_rate": 2.4662162162162162e-05,
      "loss": 0.1717,
      "step": 3250
    },
    {
      "epoch": 0.5161494616846105,
      "grad_norm": 10.342702945140877,
      "learning_rate": 2.4581724581724584e-05,
      "loss": 0.1086,
      "step": 3260
    },
    {
      "epoch": 0.5177327422419252,
      "grad_norm": 2.6200113577268933,
      "learning_rate": 2.4501287001287002e-05,
      "loss": 0.1622,
      "step": 3270
    },
    {
      "epoch": 0.51931602279924,
      "grad_norm": 1.0745438517288766,
      "learning_rate": 2.4420849420849423e-05,
      "loss": 0.1683,
      "step": 3280
    },
    {
      "epoch": 0.5208993033565548,
      "grad_norm": 7.728823617346733,
      "learning_rate": 2.434041184041184e-05,
      "loss": 0.1703,
      "step": 3290
    },
    {
      "epoch": 0.5224825839138696,
      "grad_norm": 12.127195179225865,
      "learning_rate": 2.425997425997426e-05,
      "loss": 0.1621,
      "step": 3300
    },
    {
      "epoch": 0.5240658644711843,
      "grad_norm": 1.05394051554792,
      "learning_rate": 2.417953667953668e-05,
      "loss": 0.1446,
      "step": 3310
    },
    {
      "epoch": 0.525649145028499,
      "grad_norm": 7.050564833936289,
      "learning_rate": 2.4099099099099102e-05,
      "loss": 0.1359,
      "step": 3320
    },
    {
      "epoch": 0.5272324255858138,
      "grad_norm": 0.39006679705646047,
      "learning_rate": 2.401866151866152e-05,
      "loss": 0.111,
      "step": 3330
    },
    {
      "epoch": 0.5288157061431286,
      "grad_norm": 10.081328221565723,
      "learning_rate": 2.393822393822394e-05,
      "loss": 0.2369,
      "step": 3340
    },
    {
      "epoch": 0.5303989867004433,
      "grad_norm": 2.0767507957125417,
      "learning_rate": 2.385778635778636e-05,
      "loss": 0.1633,
      "step": 3350
    },
    {
      "epoch": 0.5319822672577581,
      "grad_norm": 3.090432903001471,
      "learning_rate": 2.3777348777348778e-05,
      "loss": 0.112,
      "step": 3360
    },
    {
      "epoch": 0.5335655478150728,
      "grad_norm": 10.663906177311206,
      "learning_rate": 2.36969111969112e-05,
      "loss": 0.1808,
      "step": 3370
    },
    {
      "epoch": 0.5351488283723876,
      "grad_norm": 5.754439257390088,
      "learning_rate": 2.3616473616473618e-05,
      "loss": 0.2535,
      "step": 3380
    },
    {
      "epoch": 0.5367321089297024,
      "grad_norm": 9.625008719304086,
      "learning_rate": 2.353603603603604e-05,
      "loss": 0.2095,
      "step": 3390
    },
    {
      "epoch": 0.5383153894870171,
      "grad_norm": 0.26119685446972324,
      "learning_rate": 2.3455598455598457e-05,
      "loss": 0.1045,
      "step": 3400
    },
    {
      "epoch": 0.5398986700443319,
      "grad_norm": 13.62260709975649,
      "learning_rate": 2.3375160875160875e-05,
      "loss": 0.1522,
      "step": 3410
    },
    {
      "epoch": 0.5414819506016466,
      "grad_norm": 0.09153997713852768,
      "learning_rate": 2.3294723294723293e-05,
      "loss": 0.1111,
      "step": 3420
    },
    {
      "epoch": 0.5430652311589613,
      "grad_norm": 2.866662083851308,
      "learning_rate": 2.3214285714285715e-05,
      "loss": 0.184,
      "step": 3430
    },
    {
      "epoch": 0.5446485117162762,
      "grad_norm": 11.906308311660029,
      "learning_rate": 2.3133848133848136e-05,
      "loss": 0.0995,
      "step": 3440
    },
    {
      "epoch": 0.5462317922735909,
      "grad_norm": 2.1994040158767856,
      "learning_rate": 2.3053410553410554e-05,
      "loss": 0.2133,
      "step": 3450
    },
    {
      "epoch": 0.5478150728309057,
      "grad_norm": 17.290914912907027,
      "learning_rate": 2.2972972972972976e-05,
      "loss": 0.1369,
      "step": 3460
    },
    {
      "epoch": 0.5493983533882204,
      "grad_norm": 8.905273383954517,
      "learning_rate": 2.2892535392535394e-05,
      "loss": 0.2746,
      "step": 3470
    },
    {
      "epoch": 0.5509816339455351,
      "grad_norm": 11.744757598804988,
      "learning_rate": 2.2812097812097812e-05,
      "loss": 0.1461,
      "step": 3480
    },
    {
      "epoch": 0.55256491450285,
      "grad_norm": 18.1044670873137,
      "learning_rate": 2.2731660231660233e-05,
      "loss": 0.2126,
      "step": 3490
    },
    {
      "epoch": 0.5541481950601647,
      "grad_norm": 11.15610707081937,
      "learning_rate": 2.2651222651222655e-05,
      "loss": 0.1269,
      "step": 3500
    },
    {
      "epoch": 0.5541481950601647,
      "eval_loss": 0.2221607267856598,
      "eval_runtime": 304.0932,
      "eval_samples_per_second": 9.816,
      "eval_steps_per_second": 1.638,
      "step": 3500
    },
    {
      "epoch": 0.5557314756174794,
      "grad_norm": 10.810950372155943,
      "learning_rate": 2.2570785070785073e-05,
      "loss": 0.1639,
      "step": 3510
    },
    {
      "epoch": 0.5573147561747942,
      "grad_norm": 9.0291851283508,
      "learning_rate": 2.249034749034749e-05,
      "loss": 0.1715,
      "step": 3520
    },
    {
      "epoch": 0.5588980367321089,
      "grad_norm": 4.834980563388011,
      "learning_rate": 2.240990990990991e-05,
      "loss": 0.2666,
      "step": 3530
    },
    {
      "epoch": 0.5604813172894236,
      "grad_norm": 4.252965453530722,
      "learning_rate": 2.232947232947233e-05,
      "loss": 0.1716,
      "step": 3540
    },
    {
      "epoch": 0.5620645978467385,
      "grad_norm": 5.476220657628766,
      "learning_rate": 2.2249034749034752e-05,
      "loss": 0.2041,
      "step": 3550
    },
    {
      "epoch": 0.5636478784040532,
      "grad_norm": 14.463493430423856,
      "learning_rate": 2.216859716859717e-05,
      "loss": 0.143,
      "step": 3560
    },
    {
      "epoch": 0.565231158961368,
      "grad_norm": 15.110576719920182,
      "learning_rate": 2.208815958815959e-05,
      "loss": 0.1812,
      "step": 3570
    },
    {
      "epoch": 0.5668144395186827,
      "grad_norm": 8.763374352468569,
      "learning_rate": 2.200772200772201e-05,
      "loss": 0.1809,
      "step": 3580
    },
    {
      "epoch": 0.5683977200759974,
      "grad_norm": 7.004512422353346,
      "learning_rate": 2.1927284427284427e-05,
      "loss": 0.1766,
      "step": 3590
    },
    {
      "epoch": 0.5699810006333123,
      "grad_norm": 5.320619549062332,
      "learning_rate": 2.1846846846846845e-05,
      "loss": 0.1685,
      "step": 3600
    },
    {
      "epoch": 0.571564281190627,
      "grad_norm": 9.058759667249396,
      "learning_rate": 2.1766409266409267e-05,
      "loss": 0.1663,
      "step": 3610
    },
    {
      "epoch": 0.5731475617479417,
      "grad_norm": 4.874599929434814,
      "learning_rate": 2.168597168597169e-05,
      "loss": 0.1419,
      "step": 3620
    },
    {
      "epoch": 0.5747308423052565,
      "grad_norm": 1.1847463604335258,
      "learning_rate": 2.1605534105534106e-05,
      "loss": 0.1916,
      "step": 3630
    },
    {
      "epoch": 0.5763141228625712,
      "grad_norm": 4.527861071069457,
      "learning_rate": 2.1525096525096524e-05,
      "loss": 0.1442,
      "step": 3640
    },
    {
      "epoch": 0.577897403419886,
      "grad_norm": 3.794134838815018,
      "learning_rate": 2.1444658944658946e-05,
      "loss": 0.1411,
      "step": 3650
    },
    {
      "epoch": 0.5794806839772008,
      "grad_norm": 0.9623135893998208,
      "learning_rate": 2.1364221364221364e-05,
      "loss": 0.2033,
      "step": 3660
    },
    {
      "epoch": 0.5810639645345155,
      "grad_norm": 8.927033384547642,
      "learning_rate": 2.1283783783783785e-05,
      "loss": 0.1962,
      "step": 3670
    },
    {
      "epoch": 0.5826472450918303,
      "grad_norm": 9.758953971465768,
      "learning_rate": 2.1203346203346207e-05,
      "loss": 0.151,
      "step": 3680
    },
    {
      "epoch": 0.584230525649145,
      "grad_norm": 2.2405939586835473,
      "learning_rate": 2.1122908622908625e-05,
      "loss": 0.2127,
      "step": 3690
    },
    {
      "epoch": 0.5858138062064597,
      "grad_norm": 8.525558641314033,
      "learning_rate": 2.1042471042471043e-05,
      "loss": 0.1636,
      "step": 3700
    },
    {
      "epoch": 0.5873970867637746,
      "grad_norm": 1.5710682734582044,
      "learning_rate": 2.096203346203346e-05,
      "loss": 0.2153,
      "step": 3710
    },
    {
      "epoch": 0.5889803673210893,
      "grad_norm": 13.018836826102687,
      "learning_rate": 2.0881595881595882e-05,
      "loss": 0.1681,
      "step": 3720
    },
    {
      "epoch": 0.5905636478784041,
      "grad_norm": 10.641442355722097,
      "learning_rate": 2.08011583011583e-05,
      "loss": 0.1295,
      "step": 3730
    },
    {
      "epoch": 0.5921469284357188,
      "grad_norm": 1.1231547693585788,
      "learning_rate": 2.0720720720720722e-05,
      "loss": 0.1701,
      "step": 3740
    },
    {
      "epoch": 0.5937302089930335,
      "grad_norm": 8.515582891237631,
      "learning_rate": 2.0640283140283143e-05,
      "loss": 0.1527,
      "step": 3750
    },
    {
      "epoch": 0.5953134895503484,
      "grad_norm": 3.9751639614238097,
      "learning_rate": 2.055984555984556e-05,
      "loss": 0.1131,
      "step": 3760
    },
    {
      "epoch": 0.5968967701076631,
      "grad_norm": 4.5972666871122065,
      "learning_rate": 2.047940797940798e-05,
      "loss": 0.1396,
      "step": 3770
    },
    {
      "epoch": 0.5984800506649778,
      "grad_norm": 8.421370397394785,
      "learning_rate": 2.0398970398970398e-05,
      "loss": 0.1739,
      "step": 3780
    },
    {
      "epoch": 0.6000633312222926,
      "grad_norm": 14.792863021968355,
      "learning_rate": 2.031853281853282e-05,
      "loss": 0.1414,
      "step": 3790
    },
    {
      "epoch": 0.6016466117796073,
      "grad_norm": 0.12740950349523048,
      "learning_rate": 2.023809523809524e-05,
      "loss": 0.1592,
      "step": 3800
    },
    {
      "epoch": 0.6032298923369221,
      "grad_norm": 3.6894128008648677,
      "learning_rate": 2.015765765765766e-05,
      "loss": 0.1632,
      "step": 3810
    },
    {
      "epoch": 0.6048131728942369,
      "grad_norm": 6.526990751975001,
      "learning_rate": 2.0077220077220077e-05,
      "loss": 0.266,
      "step": 3820
    },
    {
      "epoch": 0.6063964534515516,
      "grad_norm": 8.30443485769285,
      "learning_rate": 1.9996782496782498e-05,
      "loss": 0.1662,
      "step": 3830
    },
    {
      "epoch": 0.6079797340088664,
      "grad_norm": 11.845760285569012,
      "learning_rate": 1.9916344916344916e-05,
      "loss": 0.2084,
      "step": 3840
    },
    {
      "epoch": 0.6095630145661811,
      "grad_norm": 5.575526724938017,
      "learning_rate": 1.9835907335907338e-05,
      "loss": 0.2056,
      "step": 3850
    },
    {
      "epoch": 0.6111462951234958,
      "grad_norm": 2.6527132611199113,
      "learning_rate": 1.975546975546976e-05,
      "loss": 0.1004,
      "step": 3860
    },
    {
      "epoch": 0.6127295756808107,
      "grad_norm": 1.2322590232173585,
      "learning_rate": 1.9675032175032177e-05,
      "loss": 0.1208,
      "step": 3870
    },
    {
      "epoch": 0.6143128562381254,
      "grad_norm": 2.6467674188470385,
      "learning_rate": 1.9594594594594595e-05,
      "loss": 0.1888,
      "step": 3880
    },
    {
      "epoch": 0.6158961367954402,
      "grad_norm": 18.289049150998974,
      "learning_rate": 1.9514157014157013e-05,
      "loss": 0.1908,
      "step": 3890
    },
    {
      "epoch": 0.6174794173527549,
      "grad_norm": 0.11338529659139887,
      "learning_rate": 1.9433719433719435e-05,
      "loss": 0.0765,
      "step": 3900
    },
    {
      "epoch": 0.6190626979100696,
      "grad_norm": 0.918292179350943,
      "learning_rate": 1.9353281853281853e-05,
      "loss": 0.1856,
      "step": 3910
    },
    {
      "epoch": 0.6206459784673845,
      "grad_norm": 6.799238543792285,
      "learning_rate": 1.9272844272844274e-05,
      "loss": 0.1691,
      "step": 3920
    },
    {
      "epoch": 0.6222292590246992,
      "grad_norm": 27.568756154711963,
      "learning_rate": 1.9192406692406692e-05,
      "loss": 0.1131,
      "step": 3930
    },
    {
      "epoch": 0.6238125395820139,
      "grad_norm": 4.114292697862723,
      "learning_rate": 1.9111969111969114e-05,
      "loss": 0.2054,
      "step": 3940
    },
    {
      "epoch": 0.6253958201393287,
      "grad_norm": 15.020389686131388,
      "learning_rate": 1.9031531531531532e-05,
      "loss": 0.1224,
      "step": 3950
    },
    {
      "epoch": 0.6269791006966434,
      "grad_norm": 11.260195710834207,
      "learning_rate": 1.895109395109395e-05,
      "loss": 0.1373,
      "step": 3960
    },
    {
      "epoch": 0.6285623812539582,
      "grad_norm": 0.500367238364057,
      "learning_rate": 1.887065637065637e-05,
      "loss": 0.1701,
      "step": 3970
    },
    {
      "epoch": 0.630145661811273,
      "grad_norm": 5.624800614955859,
      "learning_rate": 1.8790218790218793e-05,
      "loss": 0.17,
      "step": 3980
    },
    {
      "epoch": 0.6317289423685877,
      "grad_norm": 21.00365234584772,
      "learning_rate": 1.870978120978121e-05,
      "loss": 0.1686,
      "step": 3990
    },
    {
      "epoch": 0.6333122229259025,
      "grad_norm": 18.25263435476293,
      "learning_rate": 1.862934362934363e-05,
      "loss": 0.2566,
      "step": 4000
    },
    {
      "epoch": 0.6333122229259025,
      "eval_loss": 0.22205820679664612,
      "eval_runtime": 303.4942,
      "eval_samples_per_second": 9.835,
      "eval_steps_per_second": 1.641,
      "step": 4000
    },
    {
      "epoch": 0.6348955034832172,
      "grad_norm": 23.05358482834069,
      "learning_rate": 1.854890604890605e-05,
      "loss": 0.0738,
      "step": 4010
    },
    {
      "epoch": 0.6364787840405319,
      "grad_norm": 7.250367517035262,
      "learning_rate": 1.846846846846847e-05,
      "loss": 0.2058,
      "step": 4020
    },
    {
      "epoch": 0.6380620645978468,
      "grad_norm": 7.0284800859158185,
      "learning_rate": 1.838803088803089e-05,
      "loss": 0.1899,
      "step": 4030
    },
    {
      "epoch": 0.6396453451551615,
      "grad_norm": 1.2350168128934835,
      "learning_rate": 1.830759330759331e-05,
      "loss": 0.0904,
      "step": 4040
    },
    {
      "epoch": 0.6412286257124763,
      "grad_norm": 2.4089644343251533,
      "learning_rate": 1.822715572715573e-05,
      "loss": 0.1572,
      "step": 4050
    },
    {
      "epoch": 0.642811906269791,
      "grad_norm": 0.1771329303082034,
      "learning_rate": 1.8146718146718147e-05,
      "loss": 0.0723,
      "step": 4060
    },
    {
      "epoch": 0.6443951868271057,
      "grad_norm": 2.2688143676370136,
      "learning_rate": 1.8066280566280565e-05,
      "loss": 0.2956,
      "step": 4070
    },
    {
      "epoch": 0.6459784673844206,
      "grad_norm": 3.40648895265464,
      "learning_rate": 1.7985842985842987e-05,
      "loss": 0.2089,
      "step": 4080
    },
    {
      "epoch": 0.6475617479417353,
      "grad_norm": 10.923405748751415,
      "learning_rate": 1.7905405405405405e-05,
      "loss": 0.2311,
      "step": 4090
    },
    {
      "epoch": 0.64914502849905,
      "grad_norm": 5.52670808513538,
      "learning_rate": 1.7824967824967826e-05,
      "loss": 0.3019,
      "step": 4100
    },
    {
      "epoch": 0.6507283090563648,
      "grad_norm": 0.9869747044337447,
      "learning_rate": 1.7744530244530244e-05,
      "loss": 0.0858,
      "step": 4110
    },
    {
      "epoch": 0.6523115896136795,
      "grad_norm": 7.028899618011904,
      "learning_rate": 1.7664092664092666e-05,
      "loss": 0.1181,
      "step": 4120
    },
    {
      "epoch": 0.6538948701709943,
      "grad_norm": 12.947883603868855,
      "learning_rate": 1.7583655083655084e-05,
      "loss": 0.1693,
      "step": 4130
    },
    {
      "epoch": 0.6554781507283091,
      "grad_norm": 9.606755391156153,
      "learning_rate": 1.7503217503217502e-05,
      "loss": 0.0799,
      "step": 4140
    },
    {
      "epoch": 0.6570614312856238,
      "grad_norm": 4.975408543053333,
      "learning_rate": 1.7422779922779923e-05,
      "loss": 0.1837,
      "step": 4150
    },
    {
      "epoch": 0.6586447118429386,
      "grad_norm": 1.0551470285264355,
      "learning_rate": 1.7342342342342345e-05,
      "loss": 0.1671,
      "step": 4160
    },
    {
      "epoch": 0.6602279924002533,
      "grad_norm": 5.839148030255637,
      "learning_rate": 1.7261904761904763e-05,
      "loss": 0.1967,
      "step": 4170
    },
    {
      "epoch": 0.661811272957568,
      "grad_norm": 0.45109296496712453,
      "learning_rate": 1.718146718146718e-05,
      "loss": 0.1045,
      "step": 4180
    },
    {
      "epoch": 0.6633945535148829,
      "grad_norm": 4.533894576130528,
      "learning_rate": 1.7101029601029602e-05,
      "loss": 0.1411,
      "step": 4190
    },
    {
      "epoch": 0.6649778340721976,
      "grad_norm": 0.2232117833269723,
      "learning_rate": 1.702059202059202e-05,
      "loss": 0.1712,
      "step": 4200
    },
    {
      "epoch": 0.6665611146295124,
      "grad_norm": 9.220664856743825,
      "learning_rate": 1.6940154440154442e-05,
      "loss": 0.1778,
      "step": 4210
    },
    {
      "epoch": 0.6681443951868271,
      "grad_norm": 0.4877451433138423,
      "learning_rate": 1.685971685971686e-05,
      "loss": 0.0906,
      "step": 4220
    },
    {
      "epoch": 0.6697276757441418,
      "grad_norm": 11.432976500463747,
      "learning_rate": 1.677927927927928e-05,
      "loss": 0.2294,
      "step": 4230
    },
    {
      "epoch": 0.6713109563014567,
      "grad_norm": 1.0240525006716086,
      "learning_rate": 1.66988416988417e-05,
      "loss": 0.0471,
      "step": 4240
    },
    {
      "epoch": 0.6728942368587714,
      "grad_norm": 10.729054472006434,
      "learning_rate": 1.6618404118404118e-05,
      "loss": 0.25,
      "step": 4250
    },
    {
      "epoch": 0.6744775174160861,
      "grad_norm": 14.971315550299533,
      "learning_rate": 1.653796653796654e-05,
      "loss": 0.1914,
      "step": 4260
    },
    {
      "epoch": 0.6760607979734009,
      "grad_norm": 8.208222467541932,
      "learning_rate": 1.6457528957528957e-05,
      "loss": 0.1303,
      "step": 4270
    },
    {
      "epoch": 0.6776440785307156,
      "grad_norm": 1.7448210376905435,
      "learning_rate": 1.637709137709138e-05,
      "loss": 0.1345,
      "step": 4280
    },
    {
      "epoch": 0.6792273590880304,
      "grad_norm": 8.627935379967703,
      "learning_rate": 1.6296653796653797e-05,
      "loss": 0.1469,
      "step": 4290
    },
    {
      "epoch": 0.6808106396453452,
      "grad_norm": 5.967014879405356,
      "learning_rate": 1.6216216216216218e-05,
      "loss": 0.141,
      "step": 4300
    },
    {
      "epoch": 0.6823939202026599,
      "grad_norm": 12.317081431699524,
      "learning_rate": 1.6135778635778636e-05,
      "loss": 0.1508,
      "step": 4310
    },
    {
      "epoch": 0.6839772007599747,
      "grad_norm": 9.701581012046478,
      "learning_rate": 1.6055341055341054e-05,
      "loss": 0.1982,
      "step": 4320
    },
    {
      "epoch": 0.6855604813172894,
      "grad_norm": 0.8224177276486463,
      "learning_rate": 1.5974903474903476e-05,
      "loss": 0.0755,
      "step": 4330
    },
    {
      "epoch": 0.6871437618746041,
      "grad_norm": 3.2205867526542535,
      "learning_rate": 1.5894465894465897e-05,
      "loss": 0.2715,
      "step": 4340
    },
    {
      "epoch": 0.688727042431919,
      "grad_norm": 0.2220854301976904,
      "learning_rate": 1.5814028314028315e-05,
      "loss": 0.169,
      "step": 4350
    },
    {
      "epoch": 0.6903103229892337,
      "grad_norm": 16.898916067541506,
      "learning_rate": 1.5733590733590733e-05,
      "loss": 0.1409,
      "step": 4360
    },
    {
      "epoch": 0.6918936035465485,
      "grad_norm": 18.811321437075716,
      "learning_rate": 1.5653153153153155e-05,
      "loss": 0.1455,
      "step": 4370
    },
    {
      "epoch": 0.6934768841038632,
      "grad_norm": 11.339711208534755,
      "learning_rate": 1.5572715572715573e-05,
      "loss": 0.1297,
      "step": 4380
    },
    {
      "epoch": 0.6950601646611779,
      "grad_norm": 7.439759239895295,
      "learning_rate": 1.5492277992277994e-05,
      "loss": 0.1215,
      "step": 4390
    },
    {
      "epoch": 0.6966434452184928,
      "grad_norm": 0.5738354915512203,
      "learning_rate": 1.5411840411840412e-05,
      "loss": 0.1389,
      "step": 4400
    },
    {
      "epoch": 0.6982267257758075,
      "grad_norm": 5.01488777042673,
      "learning_rate": 1.5331402831402834e-05,
      "loss": 0.2149,
      "step": 4410
    },
    {
      "epoch": 0.6998100063331222,
      "grad_norm": 6.032173046574374,
      "learning_rate": 1.5250965250965252e-05,
      "loss": 0.2255,
      "step": 4420
    },
    {
      "epoch": 0.701393286890437,
      "grad_norm": 13.631073044472691,
      "learning_rate": 1.517052767052767e-05,
      "loss": 0.2602,
      "step": 4430
    },
    {
      "epoch": 0.7029765674477517,
      "grad_norm": 3.087089844923909,
      "learning_rate": 1.5090090090090091e-05,
      "loss": 0.177,
      "step": 4440
    },
    {
      "epoch": 0.7045598480050665,
      "grad_norm": 9.398366875513949,
      "learning_rate": 1.5009652509652511e-05,
      "loss": 0.1185,
      "step": 4450
    },
    {
      "epoch": 0.7061431285623813,
      "grad_norm": 0.3156052564356682,
      "learning_rate": 1.4929214929214929e-05,
      "loss": 0.2091,
      "step": 4460
    },
    {
      "epoch": 0.707726409119696,
      "grad_norm": 4.472459867072397,
      "learning_rate": 1.4848777348777349e-05,
      "loss": 0.1583,
      "step": 4470
    },
    {
      "epoch": 0.7093096896770108,
      "grad_norm": 1.2201327280636733,
      "learning_rate": 1.476833976833977e-05,
      "loss": 0.2145,
      "step": 4480
    },
    {
      "epoch": 0.7108929702343255,
      "grad_norm": 10.150210418775078,
      "learning_rate": 1.4687902187902188e-05,
      "loss": 0.1242,
      "step": 4490
    },
    {
      "epoch": 0.7124762507916402,
      "grad_norm": 4.332225413395603,
      "learning_rate": 1.4607464607464608e-05,
      "loss": 0.1286,
      "step": 4500
    },
    {
      "epoch": 0.7124762507916402,
      "eval_loss": 0.19627875089645386,
      "eval_runtime": 303.7354,
      "eval_samples_per_second": 9.828,
      "eval_steps_per_second": 1.64,
      "step": 4500
    },
    {
      "epoch": 0.7140595313489551,
      "grad_norm": 5.428266556145289,
      "learning_rate": 1.4527027027027026e-05,
      "loss": 0.1617,
      "step": 4510
    },
    {
      "epoch": 0.7156428119062698,
      "grad_norm": 0.40321060425034533,
      "learning_rate": 1.4446589446589448e-05,
      "loss": 0.1378,
      "step": 4520
    },
    {
      "epoch": 0.7172260924635846,
      "grad_norm": 0.7174082547190661,
      "learning_rate": 1.4366151866151867e-05,
      "loss": 0.0924,
      "step": 4530
    },
    {
      "epoch": 0.7188093730208993,
      "grad_norm": 3.8689908841622977,
      "learning_rate": 1.4285714285714285e-05,
      "loss": 0.134,
      "step": 4540
    },
    {
      "epoch": 0.720392653578214,
      "grad_norm": 1.3945007320879481,
      "learning_rate": 1.4205276705276707e-05,
      "loss": 0.1358,
      "step": 4550
    },
    {
      "epoch": 0.7219759341355289,
      "grad_norm": 12.388753627006393,
      "learning_rate": 1.4124839124839127e-05,
      "loss": 0.2197,
      "step": 4560
    },
    {
      "epoch": 0.7235592146928436,
      "grad_norm": 17.566413633392933,
      "learning_rate": 1.4044401544401545e-05,
      "loss": 0.1998,
      "step": 4570
    },
    {
      "epoch": 0.7251424952501583,
      "grad_norm": 0.34514748915765203,
      "learning_rate": 1.3963963963963963e-05,
      "loss": 0.1811,
      "step": 4580
    },
    {
      "epoch": 0.7267257758074731,
      "grad_norm": 13.494197587491945,
      "learning_rate": 1.3883526383526386e-05,
      "loss": 0.1857,
      "step": 4590
    },
    {
      "epoch": 0.7283090563647878,
      "grad_norm": 11.324207296691345,
      "learning_rate": 1.3803088803088804e-05,
      "loss": 0.175,
      "step": 4600
    },
    {
      "epoch": 0.7298923369221026,
      "grad_norm": 34.866050529020164,
      "learning_rate": 1.3722651222651222e-05,
      "loss": 0.2162,
      "step": 4610
    },
    {
      "epoch": 0.7314756174794174,
      "grad_norm": 11.088288158112764,
      "learning_rate": 1.3642213642213642e-05,
      "loss": 0.1747,
      "step": 4620
    },
    {
      "epoch": 0.7330588980367321,
      "grad_norm": 0.6458100781304413,
      "learning_rate": 1.3561776061776063e-05,
      "loss": 0.1063,
      "step": 4630
    },
    {
      "epoch": 0.7346421785940469,
      "grad_norm": 3.6550035226703166,
      "learning_rate": 1.3481338481338481e-05,
      "loss": 0.1559,
      "step": 4640
    },
    {
      "epoch": 0.7362254591513616,
      "grad_norm": 8.587555029191634,
      "learning_rate": 1.3400900900900901e-05,
      "loss": 0.1282,
      "step": 4650
    },
    {
      "epoch": 0.7378087397086763,
      "grad_norm": 2.4830539477936857,
      "learning_rate": 1.3320463320463322e-05,
      "loss": 0.1371,
      "step": 4660
    },
    {
      "epoch": 0.7393920202659912,
      "grad_norm": 3.051344190719765,
      "learning_rate": 1.324002574002574e-05,
      "loss": 0.1163,
      "step": 4670
    },
    {
      "epoch": 0.7409753008233059,
      "grad_norm": 12.528074551883025,
      "learning_rate": 1.315958815958816e-05,
      "loss": 0.2848,
      "step": 4680
    },
    {
      "epoch": 0.7425585813806207,
      "grad_norm": 7.862689614245923,
      "learning_rate": 1.3079150579150578e-05,
      "loss": 0.1817,
      "step": 4690
    },
    {
      "epoch": 0.7441418619379354,
      "grad_norm": 20.69223622851621,
      "learning_rate": 1.2998712998713e-05,
      "loss": 0.1424,
      "step": 4700
    },
    {
      "epoch": 0.7457251424952501,
      "grad_norm": 9.794289571752104,
      "learning_rate": 1.291827541827542e-05,
      "loss": 0.1614,
      "step": 4710
    },
    {
      "epoch": 0.747308423052565,
      "grad_norm": 4.45932442650457,
      "learning_rate": 1.2837837837837838e-05,
      "loss": 0.141,
      "step": 4720
    },
    {
      "epoch": 0.7488917036098797,
      "grad_norm": 0.3304021926121315,
      "learning_rate": 1.2757400257400259e-05,
      "loss": 0.1957,
      "step": 4730
    },
    {
      "epoch": 0.7504749841671944,
      "grad_norm": 0.20341647766123513,
      "learning_rate": 1.2676962676962679e-05,
      "loss": 0.1919,
      "step": 4740
    },
    {
      "epoch": 0.7520582647245092,
      "grad_norm": 0.7868483799316731,
      "learning_rate": 1.2596525096525097e-05,
      "loss": 0.1134,
      "step": 4750
    },
    {
      "epoch": 0.7536415452818239,
      "grad_norm": 0.4860954647346645,
      "learning_rate": 1.2516087516087515e-05,
      "loss": 0.2241,
      "step": 4760
    },
    {
      "epoch": 0.7552248258391387,
      "grad_norm": 19.097471283492695,
      "learning_rate": 1.2435649935649936e-05,
      "loss": 0.1055,
      "step": 4770
    },
    {
      "epoch": 0.7568081063964535,
      "grad_norm": 12.015205286679652,
      "learning_rate": 1.2355212355212356e-05,
      "loss": 0.0866,
      "step": 4780
    },
    {
      "epoch": 0.7583913869537682,
      "grad_norm": 3.0186535742861076,
      "learning_rate": 1.2274774774774774e-05,
      "loss": 0.129,
      "step": 4790
    },
    {
      "epoch": 0.759974667511083,
      "grad_norm": 5.910488968968212,
      "learning_rate": 1.2194337194337196e-05,
      "loss": 0.1261,
      "step": 4800
    },
    {
      "epoch": 0.7615579480683977,
      "grad_norm": 9.476157133359138,
      "learning_rate": 1.2113899613899614e-05,
      "loss": 0.1709,
      "step": 4810
    },
    {
      "epoch": 0.7631412286257124,
      "grad_norm": 10.566359678155223,
      "learning_rate": 1.2033462033462033e-05,
      "loss": 0.1918,
      "step": 4820
    },
    {
      "epoch": 0.7647245091830273,
      "grad_norm": 3.3418292652123314,
      "learning_rate": 1.1953024453024455e-05,
      "loss": 0.1707,
      "step": 4830
    },
    {
      "epoch": 0.766307789740342,
      "grad_norm": 9.784205371089282,
      "learning_rate": 1.1872586872586873e-05,
      "loss": 0.1118,
      "step": 4840
    },
    {
      "epoch": 0.7678910702976568,
      "grad_norm": 0.8477057165663456,
      "learning_rate": 1.1792149292149293e-05,
      "loss": 0.201,
      "step": 4850
    },
    {
      "epoch": 0.7694743508549715,
      "grad_norm": 2.39327716191219,
      "learning_rate": 1.1711711711711713e-05,
      "loss": 0.0901,
      "step": 4860
    },
    {
      "epoch": 0.7710576314122862,
      "grad_norm": 0.21101007272759126,
      "learning_rate": 1.1631274131274132e-05,
      "loss": 0.1698,
      "step": 4870
    },
    {
      "epoch": 0.772640911969601,
      "grad_norm": 8.22343839065167,
      "learning_rate": 1.155083655083655e-05,
      "loss": 0.1105,
      "step": 4880
    },
    {
      "epoch": 0.7742241925269158,
      "grad_norm": 12.760539766094157,
      "learning_rate": 1.1470398970398972e-05,
      "loss": 0.2035,
      "step": 4890
    },
    {
      "epoch": 0.7758074730842305,
      "grad_norm": 3.7525200323679493,
      "learning_rate": 1.138996138996139e-05,
      "loss": 0.1248,
      "step": 4900
    },
    {
      "epoch": 0.7773907536415453,
      "grad_norm": 31.42959234387783,
      "learning_rate": 1.130952380952381e-05,
      "loss": 0.2435,
      "step": 4910
    },
    {
      "epoch": 0.77897403419886,
      "grad_norm": 4.467827761794049,
      "learning_rate": 1.1229086229086231e-05,
      "loss": 0.1794,
      "step": 4920
    },
    {
      "epoch": 0.7805573147561748,
      "grad_norm": 6.651851723216344,
      "learning_rate": 1.1148648648648649e-05,
      "loss": 0.2279,
      "step": 4930
    },
    {
      "epoch": 0.7821405953134896,
      "grad_norm": 7.5214983222572585,
      "learning_rate": 1.1068211068211069e-05,
      "loss": 0.2744,
      "step": 4940
    },
    {
      "epoch": 0.7837238758708043,
      "grad_norm": 5.667769530440993,
      "learning_rate": 1.0987773487773489e-05,
      "loss": 0.2778,
      "step": 4950
    },
    {
      "epoch": 0.7853071564281191,
      "grad_norm": 21.41695957008283,
      "learning_rate": 1.0907335907335908e-05,
      "loss": 0.1358,
      "step": 4960
    },
    {
      "epoch": 0.7868904369854338,
      "grad_norm": 4.553906015450758,
      "learning_rate": 1.0826898326898326e-05,
      "loss": 0.1969,
      "step": 4970
    },
    {
      "epoch": 0.7884737175427485,
      "grad_norm": 6.22504386426799,
      "learning_rate": 1.0746460746460748e-05,
      "loss": 0.1718,
      "step": 4980
    },
    {
      "epoch": 0.7900569981000634,
      "grad_norm": 14.693271493198905,
      "learning_rate": 1.0666023166023166e-05,
      "loss": 0.1566,
      "step": 4990
    },
    {
      "epoch": 0.7916402786573781,
      "grad_norm": 21.237977699803334,
      "learning_rate": 1.0585585585585586e-05,
      "loss": 0.1974,
      "step": 5000
    },
    {
      "epoch": 0.7916402786573781,
      "eval_loss": 0.18823345005512238,
      "eval_runtime": 303.4124,
      "eval_samples_per_second": 9.838,
      "eval_steps_per_second": 1.641,
      "step": 5000
    },
    {
      "epoch": 0.7932235592146929,
      "grad_norm": 4.16953855088245,
      "learning_rate": 1.0505148005148005e-05,
      "loss": 0.1143,
      "step": 5010
    },
    {
      "epoch": 0.7948068397720076,
      "grad_norm": 0.2625134629248578,
      "learning_rate": 1.0424710424710425e-05,
      "loss": 0.0979,
      "step": 5020
    },
    {
      "epoch": 0.7963901203293223,
      "grad_norm": 3.34396176246976,
      "learning_rate": 1.0344272844272845e-05,
      "loss": 0.1358,
      "step": 5030
    },
    {
      "epoch": 0.7979734008866372,
      "grad_norm": 8.442484873678197,
      "learning_rate": 1.0263835263835265e-05,
      "loss": 0.1203,
      "step": 5040
    },
    {
      "epoch": 0.7995566814439519,
      "grad_norm": 8.99664032004947,
      "learning_rate": 1.0183397683397684e-05,
      "loss": 0.1634,
      "step": 5050
    },
    {
      "epoch": 0.8011399620012666,
      "grad_norm": 19.274751677935924,
      "learning_rate": 1.0102960102960103e-05,
      "loss": 0.165,
      "step": 5060
    },
    {
      "epoch": 0.8027232425585814,
      "grad_norm": 24.04501190800807,
      "learning_rate": 1.0022522522522524e-05,
      "loss": 0.1336,
      "step": 5070
    },
    {
      "epoch": 0.8043065231158961,
      "grad_norm": 22.4196107578433,
      "learning_rate": 9.942084942084942e-06,
      "loss": 0.2154,
      "step": 5080
    },
    {
      "epoch": 0.805889803673211,
      "grad_norm": 2.557980343037016,
      "learning_rate": 9.861647361647362e-06,
      "loss": 0.1424,
      "step": 5090
    },
    {
      "epoch": 0.8074730842305257,
      "grad_norm": 6.357924987292864,
      "learning_rate": 9.781209781209782e-06,
      "loss": 0.0613,
      "step": 5100
    },
    {
      "epoch": 0.8090563647878404,
      "grad_norm": 13.470705815254552,
      "learning_rate": 9.700772200772201e-06,
      "loss": 0.1986,
      "step": 5110
    },
    {
      "epoch": 0.8106396453451552,
      "grad_norm": 12.909286326591182,
      "learning_rate": 9.620334620334621e-06,
      "loss": 0.1682,
      "step": 5120
    },
    {
      "epoch": 0.8122229259024699,
      "grad_norm": 20.127462485215318,
      "learning_rate": 9.53989703989704e-06,
      "loss": 0.1785,
      "step": 5130
    },
    {
      "epoch": 0.8138062064597846,
      "grad_norm": 11.461578538437601,
      "learning_rate": 9.45945945945946e-06,
      "loss": 0.1207,
      "step": 5140
    },
    {
      "epoch": 0.8153894870170995,
      "grad_norm": 12.267411917010106,
      "learning_rate": 9.379021879021879e-06,
      "loss": 0.183,
      "step": 5150
    },
    {
      "epoch": 0.8169727675744142,
      "grad_norm": 3.7404179540456792,
      "learning_rate": 9.2985842985843e-06,
      "loss": 0.2251,
      "step": 5160
    },
    {
      "epoch": 0.818556048131729,
      "grad_norm": 20.18446350881469,
      "learning_rate": 9.218146718146718e-06,
      "loss": 0.1673,
      "step": 5170
    },
    {
      "epoch": 0.8201393286890437,
      "grad_norm": 4.627781006098417,
      "learning_rate": 9.137709137709138e-06,
      "loss": 0.2452,
      "step": 5180
    },
    {
      "epoch": 0.8217226092463584,
      "grad_norm": 2.2204267586523883,
      "learning_rate": 9.057271557271558e-06,
      "loss": 0.1152,
      "step": 5190
    },
    {
      "epoch": 0.8233058898036733,
      "grad_norm": 24.260927235619647,
      "learning_rate": 8.976833976833977e-06,
      "loss": 0.1649,
      "step": 5200
    },
    {
      "epoch": 0.824889170360988,
      "grad_norm": 4.756009165698075,
      "learning_rate": 8.896396396396395e-06,
      "loss": 0.171,
      "step": 5210
    },
    {
      "epoch": 0.8264724509183027,
      "grad_norm": 4.941030471445301,
      "learning_rate": 8.815958815958817e-06,
      "loss": 0.1441,
      "step": 5220
    },
    {
      "epoch": 0.8280557314756175,
      "grad_norm": 0.335476814478689,
      "learning_rate": 8.735521235521237e-06,
      "loss": 0.1668,
      "step": 5230
    },
    {
      "epoch": 0.8296390120329322,
      "grad_norm": 3.4603014634944333,
      "learning_rate": 8.655083655083655e-06,
      "loss": 0.2239,
      "step": 5240
    },
    {
      "epoch": 0.831222292590247,
      "grad_norm": 6.122793306153087,
      "learning_rate": 8.574646074646076e-06,
      "loss": 0.3147,
      "step": 5250
    },
    {
      "epoch": 0.8328055731475618,
      "grad_norm": 6.982021677779608,
      "learning_rate": 8.494208494208494e-06,
      "loss": 0.1912,
      "step": 5260
    },
    {
      "epoch": 0.8343888537048765,
      "grad_norm": 5.5685940053820895,
      "learning_rate": 8.413770913770914e-06,
      "loss": 0.1625,
      "step": 5270
    },
    {
      "epoch": 0.8359721342621913,
      "grad_norm": 7.29267059681114,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.1904,
      "step": 5280
    },
    {
      "epoch": 0.837555414819506,
      "grad_norm": 0.08346421207519768,
      "learning_rate": 8.252895752895753e-06,
      "loss": 0.2514,
      "step": 5290
    },
    {
      "epoch": 0.8391386953768207,
      "grad_norm": 9.098682232696229,
      "learning_rate": 8.172458172458172e-06,
      "loss": 0.1445,
      "step": 5300
    },
    {
      "epoch": 0.8407219759341356,
      "grad_norm": 5.175449760905919,
      "learning_rate": 8.092020592020593e-06,
      "loss": 0.1996,
      "step": 5310
    },
    {
      "epoch": 0.8423052564914503,
      "grad_norm": 3.8162975471500893,
      "learning_rate": 8.011583011583013e-06,
      "loss": 0.053,
      "step": 5320
    },
    {
      "epoch": 0.843888537048765,
      "grad_norm": 7.254452620612187,
      "learning_rate": 7.93114543114543e-06,
      "loss": 0.1425,
      "step": 5330
    },
    {
      "epoch": 0.8454718176060798,
      "grad_norm": 0.7174169368713109,
      "learning_rate": 7.850707850707852e-06,
      "loss": 0.0627,
      "step": 5340
    },
    {
      "epoch": 0.8470550981633945,
      "grad_norm": 8.047314441126025,
      "learning_rate": 7.77027027027027e-06,
      "loss": 0.1537,
      "step": 5350
    },
    {
      "epoch": 0.8486383787207094,
      "grad_norm": 0.2085759816120692,
      "learning_rate": 7.68983268983269e-06,
      "loss": 0.1441,
      "step": 5360
    },
    {
      "epoch": 0.8502216592780241,
      "grad_norm": 5.102162347786372,
      "learning_rate": 7.609395109395109e-06,
      "loss": 0.2306,
      "step": 5370
    },
    {
      "epoch": 0.8518049398353388,
      "grad_norm": 2.872398194317555,
      "learning_rate": 7.52895752895753e-06,
      "loss": 0.1928,
      "step": 5380
    },
    {
      "epoch": 0.8533882203926536,
      "grad_norm": 7.409411821792731,
      "learning_rate": 7.4485199485199485e-06,
      "loss": 0.1999,
      "step": 5390
    },
    {
      "epoch": 0.8549715009499683,
      "grad_norm": 4.0886249639039995,
      "learning_rate": 7.368082368082368e-06,
      "loss": 0.1139,
      "step": 5400
    },
    {
      "epoch": 0.856554781507283,
      "grad_norm": 0.6409305448633665,
      "learning_rate": 7.287644787644787e-06,
      "loss": 0.2199,
      "step": 5410
    },
    {
      "epoch": 0.8581380620645979,
      "grad_norm": 10.58506864803868,
      "learning_rate": 7.207207207207208e-06,
      "loss": 0.1182,
      "step": 5420
    },
    {
      "epoch": 0.8597213426219126,
      "grad_norm": 2.1913783977730916,
      "learning_rate": 7.1267696267696275e-06,
      "loss": 0.132,
      "step": 5430
    },
    {
      "epoch": 0.8613046231792274,
      "grad_norm": 3.1460160629725724,
      "learning_rate": 7.046332046332046e-06,
      "loss": 0.1016,
      "step": 5440
    },
    {
      "epoch": 0.8628879037365421,
      "grad_norm": 12.255744677003133,
      "learning_rate": 6.965894465894467e-06,
      "loss": 0.2122,
      "step": 5450
    },
    {
      "epoch": 0.8644711842938568,
      "grad_norm": 4.495298472711756,
      "learning_rate": 6.885456885456885e-06,
      "loss": 0.1811,
      "step": 5460
    },
    {
      "epoch": 0.8660544648511717,
      "grad_norm": 6.783654696313659,
      "learning_rate": 6.805019305019306e-06,
      "loss": 0.1475,
      "step": 5470
    },
    {
      "epoch": 0.8676377454084864,
      "grad_norm": 3.4204741096916376,
      "learning_rate": 6.724581724581725e-06,
      "loss": 0.1652,
      "step": 5480
    },
    {
      "epoch": 0.8692210259658011,
      "grad_norm": 2.6701357350512,
      "learning_rate": 6.644144144144144e-06,
      "loss": 0.2366,
      "step": 5490
    },
    {
      "epoch": 0.8708043065231159,
      "grad_norm": 5.039201790710509,
      "learning_rate": 6.563706563706563e-06,
      "loss": 0.149,
      "step": 5500
    },
    {
      "epoch": 0.8708043065231159,
      "eval_loss": 0.1927265077829361,
      "eval_runtime": 303.6247,
      "eval_samples_per_second": 9.831,
      "eval_steps_per_second": 1.64,
      "step": 5500
    },
    {
      "epoch": 0.8723875870804306,
      "grad_norm": 7.747247268577305,
      "learning_rate": 6.483268983268984e-06,
      "loss": 0.1618,
      "step": 5510
    },
    {
      "epoch": 0.8739708676377455,
      "grad_norm": 5.420543672102631,
      "learning_rate": 6.402831402831404e-06,
      "loss": 0.2136,
      "step": 5520
    },
    {
      "epoch": 0.8755541481950602,
      "grad_norm": 5.693205937040459,
      "learning_rate": 6.3223938223938225e-06,
      "loss": 0.1804,
      "step": 5530
    },
    {
      "epoch": 0.8771374287523749,
      "grad_norm": 13.365082959147047,
      "learning_rate": 6.241956241956242e-06,
      "loss": 0.1021,
      "step": 5540
    },
    {
      "epoch": 0.8787207093096897,
      "grad_norm": 8.814965302328195,
      "learning_rate": 6.161518661518661e-06,
      "loss": 0.1476,
      "step": 5550
    },
    {
      "epoch": 0.8803039898670044,
      "grad_norm": 0.16968047873932837,
      "learning_rate": 6.081081081081082e-06,
      "loss": 0.1131,
      "step": 5560
    },
    {
      "epoch": 0.8818872704243191,
      "grad_norm": 2.189856322814146,
      "learning_rate": 6.0006435006435015e-06,
      "loss": 0.0912,
      "step": 5570
    },
    {
      "epoch": 0.883470550981634,
      "grad_norm": 0.6296832574365403,
      "learning_rate": 5.9202059202059204e-06,
      "loss": 0.1194,
      "step": 5580
    },
    {
      "epoch": 0.8850538315389487,
      "grad_norm": 9.608061711579273,
      "learning_rate": 5.83976833976834e-06,
      "loss": 0.2482,
      "step": 5590
    },
    {
      "epoch": 0.8866371120962635,
      "grad_norm": 14.445984828357421,
      "learning_rate": 5.75933075933076e-06,
      "loss": 0.1923,
      "step": 5600
    },
    {
      "epoch": 0.8882203926535782,
      "grad_norm": 0.24770276538348973,
      "learning_rate": 5.678893178893179e-06,
      "loss": 0.1129,
      "step": 5610
    },
    {
      "epoch": 0.8898036732108929,
      "grad_norm": 3.355035578486487,
      "learning_rate": 5.598455598455599e-06,
      "loss": 0.2162,
      "step": 5620
    },
    {
      "epoch": 0.8913869537682078,
      "grad_norm": 6.706555464614541,
      "learning_rate": 5.518018018018018e-06,
      "loss": 0.1655,
      "step": 5630
    },
    {
      "epoch": 0.8929702343255225,
      "grad_norm": 0.9520962901385004,
      "learning_rate": 5.437580437580437e-06,
      "loss": 0.1909,
      "step": 5640
    },
    {
      "epoch": 0.8945535148828372,
      "grad_norm": 1.3782427436890847,
      "learning_rate": 5.357142857142857e-06,
      "loss": 0.1551,
      "step": 5650
    },
    {
      "epoch": 0.896136795440152,
      "grad_norm": 11.607393447350768,
      "learning_rate": 5.276705276705278e-06,
      "loss": 0.0653,
      "step": 5660
    },
    {
      "epoch": 0.8977200759974667,
      "grad_norm": 19.324966110851186,
      "learning_rate": 5.1962676962676965e-06,
      "loss": 0.1163,
      "step": 5670
    },
    {
      "epoch": 0.8993033565547816,
      "grad_norm": 0.1975357642114341,
      "learning_rate": 5.115830115830116e-06,
      "loss": 0.1181,
      "step": 5680
    },
    {
      "epoch": 0.9008866371120963,
      "grad_norm": 6.126483348363353,
      "learning_rate": 5.035392535392536e-06,
      "loss": 0.1181,
      "step": 5690
    },
    {
      "epoch": 0.902469917669411,
      "grad_norm": 9.895725182728643,
      "learning_rate": 4.954954954954955e-06,
      "loss": 0.1641,
      "step": 5700
    },
    {
      "epoch": 0.9040531982267258,
      "grad_norm": 3.688096466962542,
      "learning_rate": 4.874517374517375e-06,
      "loss": 0.1253,
      "step": 5710
    },
    {
      "epoch": 0.9056364787840405,
      "grad_norm": 2.9548999760411863,
      "learning_rate": 4.7940797940797945e-06,
      "loss": 0.1974,
      "step": 5720
    },
    {
      "epoch": 0.9072197593413552,
      "grad_norm": 4.213500875771471,
      "learning_rate": 4.713642213642213e-06,
      "loss": 0.1111,
      "step": 5730
    },
    {
      "epoch": 0.9088030398986701,
      "grad_norm": 4.9722789971906565,
      "learning_rate": 4.633204633204633e-06,
      "loss": 0.1651,
      "step": 5740
    },
    {
      "epoch": 0.9103863204559848,
      "grad_norm": 4.553831042841626,
      "learning_rate": 4.552767052767053e-06,
      "loss": 0.2171,
      "step": 5750
    },
    {
      "epoch": 0.9119696010132996,
      "grad_norm": 10.539008206170378,
      "learning_rate": 4.472329472329473e-06,
      "loss": 0.1826,
      "step": 5760
    },
    {
      "epoch": 0.9135528815706143,
      "grad_norm": 0.3684429255984719,
      "learning_rate": 4.391891891891892e-06,
      "loss": 0.1296,
      "step": 5770
    },
    {
      "epoch": 0.915136162127929,
      "grad_norm": 8.501296000693438,
      "learning_rate": 4.311454311454312e-06,
      "loss": 0.1208,
      "step": 5780
    },
    {
      "epoch": 0.9167194426852439,
      "grad_norm": 6.920984628559708,
      "learning_rate": 4.231016731016731e-06,
      "loss": 0.1232,
      "step": 5790
    },
    {
      "epoch": 0.9183027232425586,
      "grad_norm": 1.198779096996096,
      "learning_rate": 4.150579150579151e-06,
      "loss": 0.1377,
      "step": 5800
    },
    {
      "epoch": 0.9198860037998733,
      "grad_norm": 7.069250610865253,
      "learning_rate": 4.0701415701415706e-06,
      "loss": 0.1964,
      "step": 5810
    },
    {
      "epoch": 0.9214692843571881,
      "grad_norm": 4.277839583133458,
      "learning_rate": 3.9897039897039895e-06,
      "loss": 0.1444,
      "step": 5820
    },
    {
      "epoch": 0.9230525649145028,
      "grad_norm": 0.09327100038527683,
      "learning_rate": 3.909266409266409e-06,
      "loss": 0.1648,
      "step": 5830
    },
    {
      "epoch": 0.9246358454718177,
      "grad_norm": 12.948697316990279,
      "learning_rate": 3.828828828828829e-06,
      "loss": 0.1815,
      "step": 5840
    },
    {
      "epoch": 0.9262191260291324,
      "grad_norm": 1.653990373737963,
      "learning_rate": 3.7483912483912483e-06,
      "loss": 0.1298,
      "step": 5850
    },
    {
      "epoch": 0.9278024065864471,
      "grad_norm": 0.636248291890188,
      "learning_rate": 3.6679536679536685e-06,
      "loss": 0.1283,
      "step": 5860
    },
    {
      "epoch": 0.9293856871437619,
      "grad_norm": 11.159935094172921,
      "learning_rate": 3.587516087516088e-06,
      "loss": 0.2087,
      "step": 5870
    },
    {
      "epoch": 0.9309689677010766,
      "grad_norm": 4.399955853327448,
      "learning_rate": 3.5070785070785076e-06,
      "loss": 0.1644,
      "step": 5880
    },
    {
      "epoch": 0.9325522482583913,
      "grad_norm": 9.107167416494043,
      "learning_rate": 3.426640926640927e-06,
      "loss": 0.1686,
      "step": 5890
    },
    {
      "epoch": 0.9341355288157062,
      "grad_norm": 6.732084730099022,
      "learning_rate": 3.3462033462033462e-06,
      "loss": 0.2049,
      "step": 5900
    },
    {
      "epoch": 0.9357188093730209,
      "grad_norm": 8.31541357391642,
      "learning_rate": 3.265765765765766e-06,
      "loss": 0.1245,
      "step": 5910
    },
    {
      "epoch": 0.9373020899303357,
      "grad_norm": 11.390861435517687,
      "learning_rate": 3.1853281853281853e-06,
      "loss": 0.1117,
      "step": 5920
    },
    {
      "epoch": 0.9388853704876504,
      "grad_norm": 7.309448648891464,
      "learning_rate": 3.104890604890605e-06,
      "loss": 0.0704,
      "step": 5930
    },
    {
      "epoch": 0.9404686510449651,
      "grad_norm": 12.953336449382393,
      "learning_rate": 3.024453024453025e-06,
      "loss": 0.1269,
      "step": 5940
    },
    {
      "epoch": 0.94205193160228,
      "grad_norm": 9.337620794901397,
      "learning_rate": 2.944015444015444e-06,
      "loss": 0.1801,
      "step": 5950
    },
    {
      "epoch": 0.9436352121595947,
      "grad_norm": 0.9888658566120315,
      "learning_rate": 2.8635778635778635e-06,
      "loss": 0.2132,
      "step": 5960
    },
    {
      "epoch": 0.9452184927169094,
      "grad_norm": 4.058228110033541,
      "learning_rate": 2.7831402831402833e-06,
      "loss": 0.2827,
      "step": 5970
    },
    {
      "epoch": 0.9468017732742242,
      "grad_norm": 0.192936386452425,
      "learning_rate": 2.702702702702703e-06,
      "loss": 0.235,
      "step": 5980
    },
    {
      "epoch": 0.9483850538315389,
      "grad_norm": 9.998849802626713,
      "learning_rate": 2.6222651222651223e-06,
      "loss": 0.1421,
      "step": 5990
    },
    {
      "epoch": 0.9499683343888538,
      "grad_norm": 6.922718143132639,
      "learning_rate": 2.541827541827542e-06,
      "loss": 0.183,
      "step": 6000
    },
    {
      "epoch": 0.9499683343888538,
      "eval_loss": 0.2037293016910553,
      "eval_runtime": 308.4315,
      "eval_samples_per_second": 9.678,
      "eval_steps_per_second": 1.615,
      "step": 6000
    },
    {
      "epoch": 0.9515516149461685,
      "grad_norm": 6.2207776315200585,
      "learning_rate": 2.4613899613899614e-06,
      "loss": 0.1403,
      "step": 6010
    },
    {
      "epoch": 0.9531348955034832,
      "grad_norm": 0.2794791473822789,
      "learning_rate": 2.3809523809523808e-06,
      "loss": 0.1005,
      "step": 6020
    },
    {
      "epoch": 0.954718176060798,
      "grad_norm": 3.535565869958158,
      "learning_rate": 2.300514800514801e-06,
      "loss": 0.1657,
      "step": 6030
    },
    {
      "epoch": 0.9563014566181127,
      "grad_norm": 7.0415763472985216,
      "learning_rate": 2.2200772200772203e-06,
      "loss": 0.2352,
      "step": 6040
    },
    {
      "epoch": 0.9578847371754274,
      "grad_norm": 6.866297815039372,
      "learning_rate": 2.1396396396396396e-06,
      "loss": 0.0976,
      "step": 6050
    },
    {
      "epoch": 0.9594680177327423,
      "grad_norm": 9.647511500351479,
      "learning_rate": 2.0592020592020594e-06,
      "loss": 0.2381,
      "step": 6060
    },
    {
      "epoch": 0.961051298290057,
      "grad_norm": 8.318569176225466,
      "learning_rate": 1.9787644787644787e-06,
      "loss": 0.1454,
      "step": 6070
    },
    {
      "epoch": 0.9626345788473718,
      "grad_norm": 2.8499582454902033,
      "learning_rate": 1.8983268983268987e-06,
      "loss": 0.2552,
      "step": 6080
    },
    {
      "epoch": 0.9642178594046865,
      "grad_norm": 7.824560758797597,
      "learning_rate": 1.817889317889318e-06,
      "loss": 0.1656,
      "step": 6090
    },
    {
      "epoch": 0.9658011399620012,
      "grad_norm": 12.031962108592978,
      "learning_rate": 1.7374517374517375e-06,
      "loss": 0.19,
      "step": 6100
    },
    {
      "epoch": 0.9673844205193161,
      "grad_norm": 0.21564986113263654,
      "learning_rate": 1.657014157014157e-06,
      "loss": 0.135,
      "step": 6110
    },
    {
      "epoch": 0.9689677010766308,
      "grad_norm": 0.19801576020091607,
      "learning_rate": 1.5765765765765764e-06,
      "loss": 0.0963,
      "step": 6120
    },
    {
      "epoch": 0.9705509816339455,
      "grad_norm": 14.565860998946304,
      "learning_rate": 1.4961389961389962e-06,
      "loss": 0.0939,
      "step": 6130
    },
    {
      "epoch": 0.9721342621912603,
      "grad_norm": 10.43544470372733,
      "learning_rate": 1.415701415701416e-06,
      "loss": 0.0997,
      "step": 6140
    },
    {
      "epoch": 0.973717542748575,
      "grad_norm": 19.181333464251043,
      "learning_rate": 1.3352638352638352e-06,
      "loss": 0.1552,
      "step": 6150
    },
    {
      "epoch": 0.9753008233058899,
      "grad_norm": 5.853002068103899,
      "learning_rate": 1.2548262548262548e-06,
      "loss": 0.1972,
      "step": 6160
    },
    {
      "epoch": 0.9768841038632046,
      "grad_norm": 4.4658135856813,
      "learning_rate": 1.1743886743886745e-06,
      "loss": 0.1714,
      "step": 6170
    },
    {
      "epoch": 0.9784673844205193,
      "grad_norm": 9.40206623499881,
      "learning_rate": 1.0939510939510939e-06,
      "loss": 0.1092,
      "step": 6180
    },
    {
      "epoch": 0.9800506649778341,
      "grad_norm": 9.389118194287928,
      "learning_rate": 1.0135135135135136e-06,
      "loss": 0.1769,
      "step": 6190
    },
    {
      "epoch": 0.9816339455351488,
      "grad_norm": 8.249406735445671,
      "learning_rate": 9.330759330759331e-07,
      "loss": 0.1597,
      "step": 6200
    },
    {
      "epoch": 0.9832172260924635,
      "grad_norm": 9.263242572871942,
      "learning_rate": 8.526383526383526e-07,
      "loss": 0.1238,
      "step": 6210
    },
    {
      "epoch": 0.9848005066497784,
      "grad_norm": 7.732940602469938,
      "learning_rate": 7.722007722007723e-07,
      "loss": 0.1788,
      "step": 6220
    },
    {
      "epoch": 0.9863837872070931,
      "grad_norm": 6.73814905893885,
      "learning_rate": 6.917631917631918e-07,
      "loss": 0.2113,
      "step": 6230
    },
    {
      "epoch": 0.9879670677644079,
      "grad_norm": 9.7249716319477,
      "learning_rate": 6.113256113256113e-07,
      "loss": 0.2035,
      "step": 6240
    },
    {
      "epoch": 0.9895503483217226,
      "grad_norm": 1.0763845354764674,
      "learning_rate": 5.308880308880309e-07,
      "loss": 0.1506,
      "step": 6250
    },
    {
      "epoch": 0.9911336288790373,
      "grad_norm": 0.36040794117606095,
      "learning_rate": 4.504504504504505e-07,
      "loss": 0.1242,
      "step": 6260
    },
    {
      "epoch": 0.9927169094363522,
      "grad_norm": 4.408494959117616,
      "learning_rate": 3.7001287001287003e-07,
      "loss": 0.1825,
      "step": 6270
    },
    {
      "epoch": 0.9943001899936669,
      "grad_norm": 2.852292821717348,
      "learning_rate": 2.8957528957528957e-07,
      "loss": 0.1529,
      "step": 6280
    },
    {
      "epoch": 0.9958834705509816,
      "grad_norm": 13.194225458480643,
      "learning_rate": 2.0913770913770914e-07,
      "loss": 0.2471,
      "step": 6290
    },
    {
      "epoch": 0.9974667511082964,
      "grad_norm": 0.9793148165422288,
      "learning_rate": 1.287001287001287e-07,
      "loss": 0.2116,
      "step": 6300
    },
    {
      "epoch": 0.9990500316656111,
      "grad_norm": 18.950950353138214,
      "learning_rate": 4.8262548262548266e-08,
      "loss": 0.1539,
      "step": 6310
    }
  ],
  "logging_steps": 10,
  "max_steps": 6316,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 486697973317632.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
